{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math as m\n",
    "import numpy as np\n",
    "import random as r\n",
    "import matplotlib.pyplot as plt\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.optim.lr_scheduler import MultiStepLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nflows.flows.base import Flow\n",
    "from nflows.distributions.uniform import BoxUniform\n",
    "from nflows.transforms.base import CompositeTransform\n",
    "from nflows.transforms.autoregressive import MaskedPiecewiseRationalQuadraticAutoregressiveTransform\n",
    "from nflows.transforms.autoregressive import MaskedPiecewiseQuadraticAutoregressiveTransform\n",
    "from nflows.transforms.permutations import ReversePermutation\n",
    "from nflows.transforms.permutations import RandomPermutation\n",
    "from nflows.transforms.splines.rational_quadratic import rational_quadratic_spline\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import time\n",
    "import os\n",
    "from copy import deepcopy\n",
    "import math as m\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorboard writer for loss logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU/CPU selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:1\")\n",
    "#device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_RQS_knots = 10   # Number of knots in RQS transform\n",
    "n_made_layers = 1  # Number of hidden layers in every made network\n",
    "n_made_units = 100 # Number of units in every layer of the made network\n",
    "n_flow_layers = 6  # Number of layers in the flow\n",
    "\n",
    "batch_size = 1024\n",
    "n_epochs = 800\n",
    "adam_lr = 0.001     # Learning rate for the ADAM optimizer (default: 0.001)\n",
    "\n",
    "n_train = int(1e6)  # Number of training events\n",
    "n_test = int(1e5)   # Number of testing events\n",
    "n_sample = int(1e5) # Number of samples for ess evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = np.genfromtxt(\"data/unweighted_samples.csv\", delimiter=',')\n",
    "if (n_train + n_test > samples.shape[0]):\n",
    "    raise Exception(\"Not enough training data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split to a train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_samples = torch.tensor(samples[:n_train], dtype=torch.float32, device=device)\n",
    "test_samples = torch.tensor(samples[n_train:n_train+n_test], dtype=torch.float32, device=device)\n",
    "\n",
    "del samples\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_dim = train_samples.shape[1]\n",
    "base_dist = BoxUniform(torch.zeros(event_dim), torch.ones(event_dim))\n",
    "\n",
    "transforms = []\n",
    "for _ in range(n_flow_layers):\n",
    "    transforms.append(RandomPermutation(features=event_dim))\n",
    "    transforms.append(MaskedPiecewiseRationalQuadraticAutoregressiveTransform(\n",
    "        features=event_dim, \n",
    "        hidden_features=n_made_units,\n",
    "        num_bins=n_RQS_knots,\n",
    "        num_blocks=n_made_layers-1,\n",
    "        tails=\"constrained\",\n",
    "        use_residual_blocks=False\n",
    "    ))\n",
    "transform = CompositeTransform(transforms)\n",
    "\n",
    "flow = Flow(transform, base_dist).to(device)\n",
    "optimizer = optim.Adam(flow.parameters(), lr=adam_lr)\n",
    "\n",
    "scheduler = MultiStepLR(optimizer, milestones=[350, 425, 500, 575, 650, 725, 800], gamma=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch =  0 batch =  0 / 977 loss =  0.36800092458724976\n",
      "epoch =  0 batch =  25 / 977 loss =  -4.81019204797653\n",
      "epoch =  0 batch =  50 / 977 loss =  -7.429467955932896\n",
      "epoch =  0 batch =  75 / 977 loss =  -9.656738750048373\n",
      "epoch =  0 batch =  100 / 977 loss =  -11.553332369958998\n",
      "epoch =  0 batch =  125 / 977 loss =  -13.018490877298134\n",
      "epoch =  0 batch =  150 / 977 loss =  -14.256637354461562\n",
      "epoch =  0 batch =  175 / 977 loss =  -15.289999546567826\n",
      "epoch =  0 batch =  200 / 977 loss =  -16.13614581169477\n",
      "epoch =  0 batch =  225 / 977 loss =  -16.82193415717478\n",
      "epoch =  0 batch =  250 / 977 loss =  -17.384208729958168\n",
      "epoch =  0 batch =  275 / 977 loss =  -17.858309729753646\n",
      "epoch =  0 batch =  300 / 977 loss =  -18.262923184769907\n",
      "epoch =  0 batch =  325 / 977 loss =  -18.609695450248548\n",
      "epoch =  0 batch =  350 / 977 loss =  -18.9011194314967\n",
      "epoch =  0 batch =  375 / 977 loss =  -19.167159768772585\n",
      "epoch =  0 batch =  400 / 977 loss =  -19.396337840585357\n",
      "epoch =  0 batch =  425 / 977 loss =  -19.604230319635146\n",
      "epoch =  0 batch =  450 / 977 loss =  -19.782676382465283\n",
      "epoch =  0 batch =  475 / 977 loss =  -19.94579167999016\n",
      "epoch =  0 batch =  500 / 977 loss =  -20.091012294867095\n",
      "epoch =  0 batch =  525 / 977 loss =  -20.225947774153486\n",
      "epoch =  0 batch =  550 / 977 loss =  -20.352399295314267\n",
      "epoch =  0 batch =  575 / 977 loss =  -20.469761393731474\n",
      "epoch =  0 batch =  600 / 977 loss =  -20.579148191555774\n",
      "epoch =  0 batch =  625 / 977 loss =  -20.680464231715618\n",
      "epoch =  0 batch =  650 / 977 loss =  -20.772088971349508\n",
      "epoch =  0 batch =  675 / 977 loss =  -20.858114416584296\n",
      "epoch =  0 batch =  700 / 977 loss =  -20.935275894577774\n",
      "epoch =  0 batch =  725 / 977 loss =  -21.007968554955717\n",
      "epoch =  0 batch =  750 / 977 loss =  -21.078613354089118\n",
      "epoch =  0 batch =  775 / 977 loss =  -21.14332635545165\n",
      "epoch =  0 batch =  800 / 977 loss =  -21.202691557237\n",
      "epoch =  0 batch =  825 / 977 loss =  -21.263289065233327\n",
      "epoch =  0 batch =  850 / 977 loss =  -21.320364228549376\n",
      "epoch =  0 batch =  875 / 977 loss =  -21.37252302187153\n",
      "epoch =  0 batch =  900 / 977 loss =  -21.423412938344914\n",
      "epoch =  0 batch =  925 / 977 loss =  -21.470101953180407\n",
      "epoch =  0 batch =  950 / 977 loss =  -21.514835934643386\n",
      "epoch =  0 batch =  975 / 977 loss =  -21.55607880076365\n",
      "Validation loss =  -23.209867477416992\n",
      "Effective sample size =  0.235792\n",
      "epoch =  1 batch =  0 / 977 loss =  -23.158639907836914\n",
      "epoch =  1 batch =  25 / 977 loss =  -23.24459354694073\n",
      "epoch =  1 batch =  50 / 977 loss =  -23.226586173562442\n",
      "epoch =  1 batch =  75 / 977 loss =  -23.23490315989444\n",
      "epoch =  1 batch =  100 / 977 loss =  -23.228314107007314\n",
      "epoch =  1 batch =  125 / 977 loss =  -23.22819396427699\n",
      "epoch =  1 batch =  150 / 977 loss =  -23.224363137554647\n",
      "epoch =  1 batch =  175 / 977 loss =  -23.223646705800842\n",
      "epoch =  1 batch =  200 / 977 loss =  -23.226747693114024\n",
      "epoch =  1 batch =  225 / 977 loss =  -23.225634482054588\n",
      "epoch =  1 batch =  250 / 977 loss =  -23.23340583132558\n",
      "epoch =  1 batch =  275 / 977 loss =  -23.22342039882273\n",
      "epoch =  1 batch =  300 / 977 loss =  -23.219325791165673\n",
      "epoch =  1 batch =  325 / 977 loss =  -23.2203181799204\n",
      "epoch =  1 batch =  350 / 977 loss =  -23.22374641114151\n",
      "epoch =  1 batch =  375 / 977 loss =  -23.229599927334075\n",
      "epoch =  1 batch =  400 / 977 loss =  -23.23306332443123\n",
      "epoch =  1 batch =  425 / 977 loss =  -23.23216425309159\n",
      "epoch =  1 batch =  450 / 977 loss =  -23.23300765940461\n",
      "epoch =  1 batch =  475 / 977 loss =  -23.232627820567924\n",
      "epoch =  1 batch =  500 / 977 loss =  -23.235406414953296\n",
      "epoch =  1 batch =  525 / 977 loss =  -23.23782826920426\n",
      "epoch =  1 batch =  550 / 977 loss =  -23.24189984690256\n",
      "epoch =  1 batch =  575 / 977 loss =  -23.238697439432148\n",
      "epoch =  1 batch =  600 / 977 loss =  -23.242382211415432\n",
      "epoch =  1 batch =  625 / 977 loss =  -23.244807410925723\n",
      "epoch =  1 batch =  650 / 977 loss =  -23.24861864303848\n",
      "epoch =  1 batch =  675 / 977 loss =  -23.250652417628743\n",
      "epoch =  1 batch =  700 / 977 loss =  -23.250598722449737\n",
      "epoch =  1 batch =  725 / 977 loss =  -23.25191032525266\n",
      "epoch =  1 batch =  750 / 977 loss =  -23.25415998832206\n",
      "epoch =  1 batch =  775 / 977 loss =  -23.25529244757191\n",
      "epoch =  1 batch =  800 / 977 loss =  -23.256749468647445\n",
      "epoch =  1 batch =  825 / 977 loss =  -23.258168608455343\n",
      "epoch =  1 batch =  850 / 977 loss =  -23.259637061633466\n",
      "epoch =  1 batch =  875 / 977 loss =  -23.26101495577321\n",
      "epoch =  1 batch =  900 / 977 loss =  -23.26156684375895\n",
      "epoch =  1 batch =  925 / 977 loss =  -23.262855816093435\n",
      "epoch =  1 batch =  950 / 977 loss =  -23.26295476807155\n",
      "epoch =  1 batch =  975 / 977 loss =  -23.263307706254434\n",
      "Validation loss =  -23.328022003173828\n",
      "Effective sample size =  0.297898\n",
      "epoch =  2 batch =  0 / 977 loss =  -23.386028289794922\n",
      "epoch =  2 batch =  25 / 977 loss =  -23.309255893413837\n",
      "epoch =  2 batch =  50 / 977 loss =  -23.336017982632512\n",
      "epoch =  2 batch =  75 / 977 loss =  -23.30636423512509\n",
      "epoch =  2 batch =  100 / 977 loss =  -23.315624879138305\n",
      "epoch =  2 batch =  125 / 977 loss =  -23.316638885982453\n",
      "epoch =  2 batch =  150 / 977 loss =  -23.318417050191112\n",
      "epoch =  2 batch =  175 / 977 loss =  -23.324830206957742\n",
      "epoch =  2 batch =  200 / 977 loss =  -23.312896842387193\n",
      "epoch =  2 batch =  225 / 977 loss =  -23.31739758179252\n",
      "epoch =  2 batch =  250 / 977 loss =  -23.320134972196183\n",
      "epoch =  2 batch =  275 / 977 loss =  -23.327722120976105\n",
      "epoch =  2 batch =  300 / 977 loss =  -23.33207560694495\n",
      "epoch =  2 batch =  325 / 977 loss =  -23.319083734524032\n",
      "epoch =  2 batch =  350 / 977 loss =  -23.319478624566667\n",
      "epoch =  2 batch =  375 / 977 loss =  -23.31753775414\n",
      "epoch =  2 batch =  400 / 977 loss =  -23.321032873710195\n",
      "epoch =  2 batch =  425 / 977 loss =  -23.319434819646844\n",
      "epoch =  2 batch =  450 / 977 loss =  -23.322212405321075\n",
      "epoch =  2 batch =  475 / 977 loss =  -23.32663162215417\n",
      "epoch =  2 batch =  500 / 977 loss =  -23.329911843031468\n",
      "epoch =  2 batch =  525 / 977 loss =  -23.33055152820544\n",
      "epoch =  2 batch =  550 / 977 loss =  -23.334717610354005\n",
      "epoch =  2 batch =  575 / 977 loss =  -23.33687220679389\n",
      "epoch =  2 batch =  600 / 977 loss =  -23.33573539086467\n",
      "epoch =  2 batch =  625 / 977 loss =  -23.33832202094812\n",
      "epoch =  2 batch =  650 / 977 loss =  -23.33980376892558\n",
      "epoch =  2 batch =  675 / 977 loss =  -23.341426076268302\n",
      "epoch =  2 batch =  700 / 977 loss =  -23.343816359951227\n",
      "epoch =  2 batch =  725 / 977 loss =  -23.34606551073143\n",
      "epoch =  2 batch =  750 / 977 loss =  -23.3486511646987\n",
      "epoch =  2 batch =  775 / 977 loss =  -23.349667969438222\n",
      "epoch =  2 batch =  800 / 977 loss =  -23.349813889921386\n",
      "epoch =  2 batch =  825 / 977 loss =  -23.35162204807088\n",
      "epoch =  2 batch =  850 / 977 loss =  -23.352792939344113\n",
      "epoch =  2 batch =  875 / 977 loss =  -23.352670972205736\n",
      "epoch =  2 batch =  900 / 977 loss =  -23.35232631374279\n",
      "epoch =  2 batch =  925 / 977 loss =  -23.35532294287795\n",
      "epoch =  2 batch =  950 / 977 loss =  -23.35562853005908\n",
      "epoch =  2 batch =  975 / 977 loss =  -23.356375238934504\n",
      "Validation loss =  -23.41173553466797\n",
      "Effective sample size =  0.329975\n",
      "epoch =  3 batch =  0 / 977 loss =  -23.490556716918945\n",
      "epoch =  3 batch =  25 / 977 loss =  -23.40578996218168\n",
      "epoch =  3 batch =  50 / 977 loss =  -23.388815748925303\n",
      "epoch =  3 batch =  75 / 977 loss =  -23.390461193887813\n",
      "epoch =  3 batch =  100 / 977 loss =  -23.389091699430264\n",
      "epoch =  3 batch =  125 / 977 loss =  -23.384320728362557\n",
      "epoch =  3 batch =  150 / 977 loss =  -23.395960245700866\n",
      "epoch =  3 batch =  175 / 977 loss =  -23.401272947138015\n",
      "epoch =  3 batch =  200 / 977 loss =  -23.402993045636087\n",
      "epoch =  3 batch =  225 / 977 loss =  -23.40102917325181\n",
      "epoch =  3 batch =  250 / 977 loss =  -23.40084746919306\n",
      "epoch =  3 batch =  275 / 977 loss =  -23.398458819458458\n",
      "epoch =  3 batch =  300 / 977 loss =  -23.40001585950884\n",
      "epoch =  3 batch =  325 / 977 loss =  -23.403309898142442\n",
      "epoch =  3 batch =  350 / 977 loss =  -23.408238375628446\n",
      "epoch =  3 batch =  375 / 977 loss =  -23.4080447744816\n",
      "epoch =  3 batch =  400 / 977 loss =  -23.404414098459\n",
      "epoch =  3 batch =  425 / 977 loss =  -23.40519608242412\n",
      "epoch =  3 batch =  450 / 977 loss =  -23.40462586937882\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch =  3 batch =  475 / 977 loss =  -23.405365010269556\n",
      "epoch =  3 batch =  500 / 977 loss =  -23.407192241645866\n",
      "epoch =  3 batch =  525 / 977 loss =  -23.407611176088288\n",
      "epoch =  3 batch =  550 / 977 loss =  -23.409256749923355\n",
      "epoch =  3 batch =  575 / 977 loss =  -23.409335338407104\n",
      "epoch =  3 batch =  600 / 977 loss =  -23.409225086205815\n",
      "epoch =  3 batch =  625 / 977 loss =  -23.409449327487163\n",
      "epoch =  3 batch =  650 / 977 loss =  -23.4092820251043\n",
      "epoch =  3 batch =  675 / 977 loss =  -23.407976731746164\n",
      "epoch =  3 batch =  700 / 977 loss =  -23.409137366671715\n",
      "epoch =  3 batch =  725 / 977 loss =  -23.40938885743954\n",
      "epoch =  3 batch =  750 / 977 loss =  -23.410999828902455\n",
      "epoch =  3 batch =  775 / 977 loss =  -23.411625835084433\n",
      "epoch =  3 batch =  800 / 977 loss =  -23.412218939201374\n",
      "epoch =  3 batch =  825 / 977 loss =  -23.409809632105063\n",
      "epoch =  3 batch =  850 / 977 loss =  -23.411027950909958\n",
      "epoch =  3 batch =  875 / 977 loss =  -23.411486893484046\n",
      "epoch =  3 batch =  900 / 977 loss =  -23.41218903273775\n",
      "epoch =  3 batch =  925 / 977 loss =  -23.411429870720823\n",
      "epoch =  3 batch =  950 / 977 loss =  -23.4123609925921\n",
      "epoch =  3 batch =  975 / 977 loss =  -23.41309489578498\n",
      "Validation loss =  -23.38010597229004\n",
      "Effective sample size =  0.33051\n",
      "epoch =  4 batch =  0 / 977 loss =  -23.25585174560547\n",
      "epoch =  4 batch =  25 / 977 loss =  -23.391870278578537\n",
      "epoch =  4 batch =  50 / 977 loss =  -23.42051621979358\n",
      "epoch =  4 batch =  75 / 977 loss =  -23.429829572376452\n",
      "epoch =  4 batch =  100 / 977 loss =  -23.437538165857298\n",
      "epoch =  4 batch =  125 / 977 loss =  -23.442100646003844\n",
      "epoch =  4 batch =  150 / 977 loss =  -23.445378297212105\n",
      "epoch =  4 batch =  175 / 977 loss =  -23.440394520759583\n",
      "epoch =  4 batch =  200 / 977 loss =  -23.43272130406318\n",
      "epoch =  4 batch =  225 / 977 loss =  -23.437267556654668\n",
      "epoch =  4 batch =  250 / 977 loss =  -23.439066791914374\n",
      "epoch =  4 batch =  275 / 977 loss =  -23.44058839134548\n",
      "epoch =  4 batch =  300 / 977 loss =  -23.44041183066131\n",
      "epoch =  4 batch =  325 / 977 loss =  -23.43961452998998\n",
      "epoch =  4 batch =  350 / 977 loss =  -23.441868605437108\n",
      "epoch =  4 batch =  375 / 977 loss =  -23.4438577509941\n",
      "epoch =  4 batch =  400 / 977 loss =  -23.444478351279095\n",
      "epoch =  4 batch =  425 / 977 loss =  -23.44669399351022\n",
      "epoch =  4 batch =  450 / 977 loss =  -23.44479946550932\n",
      "epoch =  4 batch =  475 / 977 loss =  -23.443859905755826\n",
      "epoch =  4 batch =  500 / 977 loss =  -23.44479429126976\n",
      "epoch =  4 batch =  525 / 977 loss =  -23.441059188697732\n",
      "epoch =  4 batch =  550 / 977 loss =  -23.440130015683046\n",
      "epoch =  4 batch =  575 / 977 loss =  -23.442100044753815\n",
      "epoch =  4 batch =  600 / 977 loss =  -23.442737534914954\n",
      "epoch =  4 batch =  625 / 977 loss =  -23.443756904845806\n",
      "epoch =  4 batch =  650 / 977 loss =  -23.443636596843767\n",
      "epoch =  4 batch =  675 / 977 loss =  -23.444766600456465\n",
      "epoch =  4 batch =  700 / 977 loss =  -23.446615741528394\n",
      "epoch =  4 batch =  725 / 977 loss =  -23.447444766020975\n",
      "epoch =  4 batch =  750 / 977 loss =  -23.446854582480526\n",
      "epoch =  4 batch =  775 / 977 loss =  -23.448032209553674\n",
      "epoch =  4 batch =  800 / 977 loss =  -23.448180092705627\n",
      "epoch =  4 batch =  825 / 977 loss =  -23.44377502228966\n",
      "epoch =  4 batch =  850 / 977 loss =  -23.44366971474277\n",
      "epoch =  4 batch =  875 / 977 loss =  -23.445175355972225\n",
      "epoch =  4 batch =  900 / 977 loss =  -23.44547472624615\n",
      "epoch =  4 batch =  925 / 977 loss =  -23.446111852097978\n",
      "epoch =  4 batch =  950 / 977 loss =  -23.446836634013184\n",
      "epoch =  4 batch =  975 / 977 loss =  -23.44703841404837\n",
      "Validation loss =  -23.453990936279297\n",
      "Effective sample size =  0.364971\n",
      "epoch =  5 batch =  0 / 977 loss =  -23.523937225341797\n",
      "epoch =  5 batch =  25 / 977 loss =  -23.475608312166653\n",
      "epoch =  5 batch =  50 / 977 loss =  -23.509251127056046\n",
      "epoch =  5 batch =  75 / 977 loss =  -23.511925345972966\n",
      "epoch =  5 batch =  100 / 977 loss =  -23.5003177340668\n",
      "epoch =  5 batch =  125 / 977 loss =  -23.502041831849112\n",
      "epoch =  5 batch =  150 / 977 loss =  -23.491896294600128\n",
      "epoch =  5 batch =  175 / 977 loss =  -23.487690069458708\n",
      "epoch =  5 batch =  200 / 977 loss =  -23.482287658387754\n",
      "epoch =  5 batch =  225 / 977 loss =  -23.480934387814685\n",
      "epoch =  5 batch =  250 / 977 loss =  -23.479248723185872\n",
      "epoch =  5 batch =  275 / 977 loss =  -23.47497771442801\n",
      "epoch =  5 batch =  300 / 977 loss =  -23.475222723824636\n",
      "epoch =  5 batch =  325 / 977 loss =  -23.47416593984592\n",
      "epoch =  5 batch =  350 / 977 loss =  -23.475520071480677\n",
      "epoch =  5 batch =  375 / 977 loss =  -23.47480557319965\n",
      "epoch =  5 batch =  400 / 977 loss =  -23.475985001447484\n",
      "epoch =  5 batch =  425 / 977 loss =  -23.47611717439033\n",
      "epoch =  5 batch =  450 / 977 loss =  -23.474203765260135\n",
      "epoch =  5 batch =  475 / 977 loss =  -23.47504261161098\n",
      "epoch =  5 batch =  500 / 977 loss =  -23.47528625914674\n",
      "epoch =  5 batch =  525 / 977 loss =  -23.475785327954885\n",
      "epoch =  5 batch =  550 / 977 loss =  -23.476056273749425\n",
      "epoch =  5 batch =  575 / 977 loss =  -23.475667744874947\n",
      "epoch =  5 batch =  600 / 977 loss =  -23.476181036620684\n",
      "epoch =  5 batch =  625 / 977 loss =  -23.474200565594067\n",
      "epoch =  5 batch =  650 / 977 loss =  -23.476129095308973\n",
      "epoch =  5 batch =  675 / 977 loss =  -23.479257544116862\n",
      "epoch =  5 batch =  700 / 977 loss =  -23.47969296791413\n",
      "epoch =  5 batch =  725 / 977 loss =  -23.478879626460632\n",
      "epoch =  5 batch =  750 / 977 loss =  -23.47724816008667\n",
      "epoch =  5 batch =  775 / 977 loss =  -23.47668566654637\n",
      "epoch =  5 batch =  800 / 977 loss =  -23.478486795699244\n",
      "epoch =  5 batch =  825 / 977 loss =  -23.480321556257557\n",
      "epoch =  5 batch =  850 / 977 loss =  -23.48043429445295\n",
      "epoch =  5 batch =  875 / 977 loss =  -23.479696504601595\n",
      "epoch =  5 batch =  900 / 977 loss =  -23.48060691316966\n",
      "epoch =  5 batch =  925 / 977 loss =  -23.48098091636311\n",
      "epoch =  5 batch =  950 / 977 loss =  -23.48207415190655\n",
      "epoch =  5 batch =  975 / 977 loss =  -23.481652001865566\n",
      "Validation loss =  -23.49917984008789\n",
      "Effective sample size =  0.37291\n",
      "epoch =  6 batch =  0 / 977 loss =  -23.515716552734375\n",
      "epoch =  6 batch =  25 / 977 loss =  -23.416667277996357\n",
      "epoch =  6 batch =  50 / 977 loss =  -23.445810317993164\n",
      "epoch =  6 batch =  75 / 977 loss =  -23.466311028129176\n",
      "epoch =  6 batch =  100 / 977 loss =  -23.468360069954745\n",
      "epoch =  6 batch =  125 / 977 loss =  -23.47085380554199\n",
      "epoch =  6 batch =  150 / 977 loss =  -23.47812147329975\n",
      "epoch =  6 batch =  175 / 977 loss =  -23.47795913436197\n",
      "epoch =  6 batch =  200 / 977 loss =  -23.481466188952705\n",
      "epoch =  6 batch =  225 / 977 loss =  -23.4824802601232\n",
      "epoch =  6 batch =  250 / 977 loss =  -23.484357400719396\n",
      "epoch =  6 batch =  275 / 977 loss =  -23.484326721965406\n",
      "epoch =  6 batch =  300 / 977 loss =  -23.488604890943762\n",
      "epoch =  6 batch =  325 / 977 loss =  -23.490434605651103\n",
      "epoch =  6 batch =  350 / 977 loss =  -23.48953680163434\n",
      "epoch =  6 batch =  375 / 977 loss =  -23.490483847070237\n",
      "epoch =  6 batch =  400 / 977 loss =  -23.48876477001313\n",
      "epoch =  6 batch =  425 / 977 loss =  -23.49205330951672\n",
      "epoch =  6 batch =  450 / 977 loss =  -23.490273849927128\n",
      "epoch =  6 batch =  475 / 977 loss =  -23.489468225911878\n",
      "epoch =  6 batch =  500 / 977 loss =  -23.490303998935715\n",
      "epoch =  6 batch =  525 / 977 loss =  -23.49335200161081\n",
      "epoch =  6 batch =  550 / 977 loss =  -23.493909122723192\n",
      "epoch =  6 batch =  575 / 977 loss =  -23.496871987978608\n",
      "epoch =  6 batch =  600 / 977 loss =  -23.498600307597886\n",
      "epoch =  6 batch =  625 / 977 loss =  -23.49837142286209\n",
      "epoch =  6 batch =  650 / 977 loss =  -23.499279587682672\n",
      "epoch =  6 batch =  675 / 977 loss =  -23.50103615868021\n",
      "epoch =  6 batch =  700 / 977 loss =  -23.501362644146585\n",
      "epoch =  6 batch =  725 / 977 loss =  -23.501847792591278\n",
      "epoch =  6 batch =  750 / 977 loss =  -23.502838053493782\n",
      "epoch =  6 batch =  775 / 977 loss =  -23.501766249076613\n",
      "epoch =  6 batch =  800 / 977 loss =  -23.502648207132292\n",
      "epoch =  6 batch =  825 / 977 loss =  -23.50249527614862\n",
      "epoch =  6 batch =  850 / 977 loss =  -23.502517487271557\n",
      "epoch =  6 batch =  875 / 977 loss =  -23.503442442036114\n",
      "epoch =  6 batch =  900 / 977 loss =  -23.50406414925325\n",
      "epoch =  6 batch =  925 / 977 loss =  -23.504177577552223\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch =  6 batch =  950 / 977 loss =  -23.504544654228464\n",
      "epoch =  6 batch =  975 / 977 loss =  -23.503706087831596\n",
      "Validation loss =  -23.51233673095703\n",
      "Effective sample size =  0.385979\n",
      "epoch =  7 batch =  0 / 977 loss =  -23.685314178466797\n",
      "epoch =  7 batch =  25 / 977 loss =  -23.513135029719425\n",
      "epoch =  7 batch =  50 / 977 loss =  -23.506691053801887\n",
      "epoch =  7 batch =  75 / 977 loss =  -23.50863308655588\n",
      "epoch =  7 batch =  100 / 977 loss =  -23.51628041031337\n",
      "epoch =  7 batch =  125 / 977 loss =  -23.51639723399329\n",
      "epoch =  7 batch =  150 / 977 loss =  -23.51824761700157\n",
      "epoch =  7 batch =  175 / 977 loss =  -23.517819957299672\n",
      "epoch =  7 batch =  200 / 977 loss =  -23.51580271554824\n",
      "epoch =  7 batch =  225 / 977 loss =  -23.512810226035334\n",
      "epoch =  7 batch =  250 / 977 loss =  -23.508142805669415\n",
      "epoch =  7 batch =  275 / 977 loss =  -23.507923540861714\n",
      "epoch =  7 batch =  300 / 977 loss =  -23.509312195635324\n",
      "epoch =  7 batch =  325 / 977 loss =  -23.513172974615753\n",
      "epoch =  7 batch =  350 / 977 loss =  -23.512131851283243\n",
      "epoch =  7 batch =  375 / 977 loss =  -23.51513568391192\n",
      "epoch =  7 batch =  400 / 977 loss =  -23.51716152390935\n",
      "epoch =  7 batch =  425 / 977 loss =  -23.51525108803047\n",
      "epoch =  7 batch =  450 / 977 loss =  -23.515631111128112\n",
      "epoch =  7 batch =  475 / 977 loss =  -23.51385122186998\n",
      "epoch =  7 batch =  500 / 977 loss =  -23.512336913697027\n",
      "epoch =  7 batch =  525 / 977 loss =  -23.513305065749723\n",
      "epoch =  7 batch =  550 / 977 loss =  -23.514248461991606\n",
      "epoch =  7 batch =  575 / 977 loss =  -23.51390307148297\n",
      "epoch =  7 batch =  600 / 977 loss =  -23.513805408446043\n",
      "epoch =  7 batch =  625 / 977 loss =  -23.513435372910177\n",
      "epoch =  7 batch =  650 / 977 loss =  -23.514472249466156\n",
      "epoch =  7 batch =  675 / 977 loss =  -23.516603227197773\n",
      "epoch =  7 batch =  700 / 977 loss =  -23.517502582022207\n",
      "epoch =  7 batch =  725 / 977 loss =  -23.516951534702113\n",
      "epoch =  7 batch =  750 / 977 loss =  -23.51662541832652\n",
      "epoch =  7 batch =  775 / 977 loss =  -23.51570121529177\n",
      "epoch =  7 batch =  800 / 977 loss =  -23.514418915118775\n",
      "epoch =  7 batch =  825 / 977 loss =  -23.513658345755893\n",
      "epoch =  7 batch =  850 / 977 loss =  -23.516433121875096\n",
      "epoch =  7 batch =  875 / 977 loss =  -23.517373363721326\n",
      "epoch =  7 batch =  900 / 977 loss =  -23.51793003611507\n",
      "epoch =  7 batch =  925 / 977 loss =  -23.518102956899565\n",
      "epoch =  7 batch =  950 / 977 loss =  -23.51770963578571\n",
      "epoch =  7 batch =  975 / 977 loss =  -23.518043649001207\n",
      "Validation loss =  -23.533946990966797\n",
      "Effective sample size =  0.401099\n",
      "epoch =  8 batch =  0 / 977 loss =  -23.71156883239746\n",
      "epoch =  8 batch =  25 / 977 loss =  -23.588715846721943\n",
      "epoch =  8 batch =  50 / 977 loss =  -23.56297706155216\n",
      "epoch =  8 batch =  75 / 977 loss =  -23.564351157138223\n",
      "epoch =  8 batch =  100 / 977 loss =  -23.549859131916914\n",
      "epoch =  8 batch =  125 / 977 loss =  -23.541102318536666\n",
      "epoch =  8 batch =  150 / 977 loss =  -23.53605720065288\n",
      "epoch =  8 batch =  175 / 977 loss =  -23.52904291586443\n",
      "epoch =  8 batch =  200 / 977 loss =  -23.52239225397063\n",
      "epoch =  8 batch =  225 / 977 loss =  -23.516188376772725\n",
      "epoch =  8 batch =  250 / 977 loss =  -23.51739810472466\n",
      "epoch =  8 batch =  275 / 977 loss =  -23.517504761184473\n",
      "epoch =  8 batch =  300 / 977 loss =  -23.521187620701582\n",
      "epoch =  8 batch =  325 / 977 loss =  -23.520269212547248\n",
      "epoch =  8 batch =  350 / 977 loss =  -23.52096020190464\n",
      "epoch =  8 batch =  375 / 977 loss =  -23.519318550191024\n",
      "epoch =  8 batch =  400 / 977 loss =  -23.520737845404184\n",
      "epoch =  8 batch =  425 / 977 loss =  -23.522142034181403\n",
      "epoch =  8 batch =  450 / 977 loss =  -23.52242060828367\n",
      "epoch =  8 batch =  475 / 977 loss =  -23.520132966402194\n",
      "epoch =  8 batch =  500 / 977 loss =  -23.521649926008575\n",
      "epoch =  8 batch =  525 / 977 loss =  -23.522741567952547\n",
      "epoch =  8 batch =  550 / 977 loss =  -23.525697967750837\n",
      "epoch =  8 batch =  575 / 977 loss =  -23.526880244414006\n",
      "epoch =  8 batch =  600 / 977 loss =  -23.528552383829073\n",
      "epoch =  8 batch =  625 / 977 loss =  -23.528662124000036\n",
      "epoch =  8 batch =  650 / 977 loss =  -23.529291903002107\n",
      "epoch =  8 batch =  675 / 977 loss =  -23.52956990236363\n",
      "epoch =  8 batch =  700 / 977 loss =  -23.528485601536737\n",
      "epoch =  8 batch =  725 / 977 loss =  -23.528341779367334\n",
      "epoch =  8 batch =  750 / 977 loss =  -23.529391107165555\n",
      "epoch =  8 batch =  775 / 977 loss =  -23.530591859030977\n",
      "epoch =  8 batch =  800 / 977 loss =  -23.530072803949754\n",
      "epoch =  8 batch =  825 / 977 loss =  -23.529077294375078\n",
      "epoch =  8 batch =  850 / 977 loss =  -23.527830980079024\n",
      "epoch =  8 batch =  875 / 977 loss =  -23.527746925615293\n",
      "epoch =  8 batch =  900 / 977 loss =  -23.52811547257131\n",
      "epoch =  8 batch =  925 / 977 loss =  -23.52900582101382\n",
      "epoch =  8 batch =  950 / 977 loss =  -23.52901874706698\n",
      "epoch =  8 batch =  975 / 977 loss =  -23.52941850169761\n",
      "Validation loss =  -23.544158935546875\n",
      "Effective sample size =  0.410112\n",
      "epoch =  9 batch =  0 / 977 loss =  -23.61385154724121\n",
      "epoch =  9 batch =  25 / 977 loss =  -23.566618405855625\n",
      "epoch =  9 batch =  50 / 977 loss =  -23.565904243319643\n",
      "epoch =  9 batch =  75 / 977 loss =  -23.566713006872885\n",
      "epoch =  9 batch =  100 / 977 loss =  -23.571056422620718\n",
      "epoch =  9 batch =  125 / 977 loss =  -23.5660978498913\n",
      "epoch =  9 batch =  150 / 977 loss =  -23.561850920418237\n",
      "epoch =  9 batch =  175 / 977 loss =  -23.55530285835266\n",
      "epoch =  9 batch =  200 / 977 loss =  -23.553361494149733\n",
      "epoch =  9 batch =  225 / 977 loss =  -23.555870284021427\n",
      "epoch =  9 batch =  250 / 977 loss =  -23.555008443703215\n",
      "epoch =  9 batch =  275 / 977 loss =  -23.5561793645223\n",
      "epoch =  9 batch =  300 / 977 loss =  -23.556351100883614\n",
      "epoch =  9 batch =  325 / 977 loss =  -23.554478528309453\n",
      "epoch =  9 batch =  350 / 977 loss =  -23.55654786590836\n",
      "epoch =  9 batch =  375 / 977 loss =  -23.556724406303235\n",
      "epoch =  9 batch =  400 / 977 loss =  -23.555902319358758\n",
      "epoch =  9 batch =  425 / 977 loss =  -23.555957574799578\n",
      "epoch =  9 batch =  450 / 977 loss =  -23.554132782963578\n",
      "epoch =  9 batch =  475 / 977 loss =  -23.552928844419842\n",
      "epoch =  9 batch =  500 / 977 loss =  -23.55055753056874\n",
      "epoch =  9 batch =  525 / 977 loss =  -23.548474235679706\n",
      "epoch =  9 batch =  550 / 977 loss =  -23.548725339332197\n",
      "epoch =  9 batch =  575 / 977 loss =  -23.546271800994862\n",
      "epoch =  9 batch =  600 / 977 loss =  -23.54603782628419\n",
      "epoch =  9 batch =  625 / 977 loss =  -23.5468427060892\n",
      "epoch =  9 batch =  650 / 977 loss =  -23.54620305953487\n",
      "epoch =  9 batch =  675 / 977 loss =  -23.546519220228035\n",
      "epoch =  9 batch =  700 / 977 loss =  -23.545852919618017\n",
      "epoch =  9 batch =  725 / 977 loss =  -23.546346020764236\n",
      "epoch =  9 batch =  750 / 977 loss =  -23.546127814586256\n",
      "epoch =  9 batch =  775 / 977 loss =  -23.54566837340287\n",
      "epoch =  9 batch =  800 / 977 loss =  -23.54449783639516\n",
      "epoch =  9 batch =  825 / 977 loss =  -23.544778652976277\n",
      "epoch =  9 batch =  850 / 977 loss =  -23.543890158522153\n",
      "epoch =  9 batch =  875 / 977 loss =  -23.544919131553346\n",
      "epoch =  9 batch =  900 / 977 loss =  -23.54456549717505\n",
      "epoch =  9 batch =  925 / 977 loss =  -23.543724704767158\n",
      "epoch =  9 batch =  950 / 977 loss =  -23.54407557779307\n",
      "epoch =  9 batch =  975 / 977 loss =  -23.54422206761408\n",
      "Validation loss =  -23.54515266418457\n",
      "Effective sample size =  0.42207\n",
      "epoch =  10 batch =  0 / 977 loss =  -23.355358123779297\n",
      "epoch =  10 batch =  25 / 977 loss =  -23.53031510573167\n",
      "epoch =  10 batch =  50 / 977 loss =  -23.531696020388136\n",
      "epoch =  10 batch =  75 / 977 loss =  -23.538790200885973\n",
      "epoch =  10 batch =  100 / 977 loss =  -23.536018881467307\n",
      "epoch =  10 batch =  125 / 977 loss =  -23.541201924520823\n",
      "epoch =  10 batch =  150 / 977 loss =  -23.544712774011472\n",
      "epoch =  10 batch =  175 / 977 loss =  -23.54104900360107\n",
      "epoch =  10 batch =  200 / 977 loss =  -23.537677821828353\n",
      "epoch =  10 batch =  225 / 977 loss =  -23.540615360293764\n",
      "epoch =  10 batch =  250 / 977 loss =  -23.541722552234905\n",
      "epoch =  10 batch =  275 / 977 loss =  -23.541115325430162\n",
      "epoch =  10 batch =  300 / 977 loss =  -23.543872630477345\n",
      "epoch =  10 batch =  325 / 977 loss =  -23.54887137968847\n",
      "epoch =  10 batch =  350 / 977 loss =  -23.54941622416179\n",
      "epoch =  10 batch =  375 / 977 loss =  -23.551835947848385\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch =  10 batch =  400 / 977 loss =  -23.550535073601402\n",
      "epoch =  10 batch =  425 / 977 loss =  -23.551118613408768\n",
      "epoch =  10 batch =  450 / 977 loss =  -23.550273463889926\n",
      "epoch =  10 batch =  475 / 977 loss =  -23.551137996320968\n",
      "epoch =  10 batch =  500 / 977 loss =  -23.55113951174799\n",
      "epoch =  10 batch =  525 / 977 loss =  -23.551414156141394\n",
      "epoch =  10 batch =  550 / 977 loss =  -23.55144124455115\n",
      "epoch =  10 batch =  575 / 977 loss =  -23.551177521546695\n",
      "epoch =  10 batch =  600 / 977 loss =  -23.55071445471437\n",
      "epoch =  10 batch =  625 / 977 loss =  -23.550067575594877\n",
      "epoch =  10 batch =  650 / 977 loss =  -23.5494300238731\n",
      "epoch =  10 batch =  675 / 977 loss =  -23.549393989630723\n",
      "epoch =  10 batch =  700 / 977 loss =  -23.549039522353347\n",
      "epoch =  10 batch =  725 / 977 loss =  -23.548361660035212\n",
      "epoch =  10 batch =  750 / 977 loss =  -23.54870398987469\n",
      "epoch =  10 batch =  775 / 977 loss =  -23.548067916299903\n",
      "epoch =  10 batch =  800 / 977 loss =  -23.547802126214172\n",
      "epoch =  10 batch =  825 / 977 loss =  -23.547962126373978\n",
      "epoch =  10 batch =  850 / 977 loss =  -23.548422507477724\n",
      "epoch =  10 batch =  875 / 977 loss =  -23.547317167395345\n",
      "epoch =  10 batch =  900 / 977 loss =  -23.546220798471282\n",
      "epoch =  10 batch =  925 / 977 loss =  -23.54674909645231\n",
      "epoch =  10 batch =  950 / 977 loss =  -23.54672258058183\n",
      "epoch =  10 batch =  975 / 977 loss =  -23.547838959537586\n",
      "Validation loss =  -23.54278564453125\n",
      "Effective sample size =  0.405461\n",
      "epoch =  11 batch =  0 / 977 loss =  -23.613019943237305\n",
      "epoch =  11 batch =  25 / 977 loss =  -23.539632210364708\n",
      "epoch =  11 batch =  50 / 977 loss =  -23.535403232948454\n",
      "epoch =  11 batch =  75 / 977 loss =  -23.540635585784912\n",
      "epoch =  11 batch =  100 / 977 loss =  -23.554965066437674\n",
      "epoch =  11 batch =  125 / 977 loss =  -23.559585238259935\n",
      "epoch =  11 batch =  150 / 977 loss =  -23.552471855618304\n",
      "epoch =  11 batch =  175 / 977 loss =  -23.556576999751005\n",
      "epoch =  11 batch =  200 / 977 loss =  -23.55645503333552\n",
      "epoch =  11 batch =  225 / 977 loss =  -23.55879277254628\n",
      "epoch =  11 batch =  250 / 977 loss =  -23.55874105658664\n",
      "epoch =  11 batch =  275 / 977 loss =  -23.558615746705428\n",
      "epoch =  11 batch =  300 / 977 loss =  -23.559710398068848\n",
      "epoch =  11 batch =  325 / 977 loss =  -23.558330395470353\n",
      "epoch =  11 batch =  350 / 977 loss =  -23.556726651313966\n",
      "epoch =  11 batch =  375 / 977 loss =  -23.55752860738875\n",
      "epoch =  11 batch =  400 / 977 loss =  -23.556992766268525\n",
      "epoch =  11 batch =  425 / 977 loss =  -23.557283047779055\n",
      "epoch =  11 batch =  450 / 977 loss =  -23.558789547161087\n",
      "epoch =  11 batch =  475 / 977 loss =  -23.55717218623441\n",
      "epoch =  11 batch =  500 / 977 loss =  -23.557738378376296\n",
      "epoch =  11 batch =  525 / 977 loss =  -23.556318700086926\n",
      "epoch =  11 batch =  550 / 977 loss =  -23.555702171394913\n",
      "epoch =  11 batch =  575 / 977 loss =  -23.552399294243923\n",
      "epoch =  11 batch =  600 / 977 loss =  -23.55293772819634\n",
      "epoch =  11 batch =  625 / 977 loss =  -23.551916896344768\n",
      "epoch =  11 batch =  650 / 977 loss =  -23.550959190099114\n",
      "epoch =  11 batch =  675 / 977 loss =  -23.551362472173032\n",
      "epoch =  11 batch =  700 / 977 loss =  -23.552336041155282\n",
      "epoch =  11 batch =  725 / 977 loss =  -23.552839967501722\n",
      "epoch =  11 batch =  750 / 977 loss =  -23.55222704820087\n",
      "epoch =  11 batch =  775 / 977 loss =  -23.551731773258485\n",
      "epoch =  11 batch =  800 / 977 loss =  -23.55224074317275\n",
      "epoch =  11 batch =  825 / 977 loss =  -23.55164087540301\n",
      "epoch =  11 batch =  850 / 977 loss =  -23.552849105046022\n",
      "epoch =  11 batch =  875 / 977 loss =  -23.55184259806594\n",
      "epoch =  11 batch =  900 / 977 loss =  -23.55182801817154\n",
      "epoch =  11 batch =  925 / 977 loss =  -23.552214941762177\n",
      "epoch =  11 batch =  950 / 977 loss =  -23.55395101473033\n",
      "epoch =  11 batch =  975 / 977 loss =  -23.553981143920147\n",
      "Validation loss =  -23.54287338256836\n",
      "Effective sample size =  0.420735\n",
      "epoch =  12 batch =  0 / 977 loss =  -23.662446975708008\n",
      "epoch =  12 batch =  25 / 977 loss =  -23.57204136481652\n",
      "epoch =  12 batch =  50 / 977 loss =  -23.57351729449104\n",
      "epoch =  12 batch =  75 / 977 loss =  -23.583583982367266\n",
      "epoch =  12 batch =  100 / 977 loss =  -23.57814163736778\n",
      "epoch =  12 batch =  125 / 977 loss =  -23.57073011852446\n",
      "epoch =  12 batch =  150 / 977 loss =  -23.56700851743585\n",
      "epoch =  12 batch =  175 / 977 loss =  -23.562486702745613\n",
      "epoch =  12 batch =  200 / 977 loss =  -23.566100637711102\n",
      "epoch =  12 batch =  225 / 977 loss =  -23.564272222265732\n",
      "epoch =  12 batch =  250 / 977 loss =  -23.565760973440224\n",
      "epoch =  12 batch =  275 / 977 loss =  -23.56561449299688\n",
      "epoch =  12 batch =  300 / 977 loss =  -23.56616251492422\n",
      "epoch =  12 batch =  325 / 977 loss =  -23.565025054604003\n",
      "epoch =  12 batch =  350 / 977 loss =  -23.565912969431658\n",
      "epoch =  12 batch =  375 / 977 loss =  -23.568431052755813\n",
      "epoch =  12 batch =  400 / 977 loss =  -23.565696411893857\n",
      "epoch =  12 batch =  425 / 977 loss =  -23.56531022747918\n",
      "epoch =  12 batch =  450 / 977 loss =  -23.564320579072067\n",
      "epoch =  12 batch =  475 / 977 loss =  -23.566630283323665\n",
      "epoch =  12 batch =  500 / 977 loss =  -23.56715059185219\n",
      "epoch =  12 batch =  525 / 977 loss =  -23.56870405030342\n",
      "epoch =  12 batch =  550 / 977 loss =  -23.56818698322276\n",
      "epoch =  12 batch =  575 / 977 loss =  -23.569347328609904\n",
      "epoch =  12 batch =  600 / 977 loss =  -23.570040675844016\n",
      "epoch =  12 batch =  625 / 977 loss =  -23.570038405470196\n",
      "epoch =  12 batch =  650 / 977 loss =  -23.568835869362836\n",
      "epoch =  12 batch =  675 / 977 loss =  -23.567373416832925\n",
      "epoch =  12 batch =  700 / 977 loss =  -23.565289651106166\n",
      "epoch =  12 batch =  725 / 977 loss =  -23.56561581425103\n",
      "epoch =  12 batch =  750 / 977 loss =  -23.566842801720114\n",
      "epoch =  12 batch =  775 / 977 loss =  -23.56700042351006\n",
      "epoch =  12 batch =  800 / 977 loss =  -23.56806672199836\n",
      "epoch =  12 batch =  825 / 977 loss =  -23.567115421156625\n",
      "epoch =  12 batch =  850 / 977 loss =  -23.566791619593342\n",
      "epoch =  12 batch =  875 / 977 loss =  -23.56612758549382\n",
      "epoch =  12 batch =  900 / 977 loss =  -23.566367857464154\n",
      "epoch =  12 batch =  925 / 977 loss =  -23.566467068880225\n",
      "epoch =  12 batch =  950 / 977 loss =  -23.565104940837625\n",
      "epoch =  12 batch =  975 / 977 loss =  -23.564922598541767\n",
      "Validation loss =  -23.541717529296875\n"
     ]
    }
   ],
   "source": [
    "data_size = train_samples.shape[0]\n",
    "n_batches = m.ceil(data_size/batch_size)\n",
    "\n",
    "data_size_validation = test_samples.shape[0]\n",
    "n_batches_validate = m.ceil(data_size_validation/batch_size)\n",
    "\n",
    "best_validation_loss = np.inf\n",
    "best_ess = 0\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    \n",
    "    permutation = torch.randperm(data_size, device=device)    \n",
    "\n",
    "    # Loop over batches\n",
    "    cum_loss = 0\n",
    "    for batch in range(n_batches):\n",
    "        # Set up the batch\n",
    "        batch_begin = batch*batch_size\n",
    "        batch_end   = min( (batch+1)*batch_size, data_size-1 )\n",
    "        indices = permutation[batch_begin:batch_end]\n",
    "        samples_batch = train_samples[indices]\n",
    "        \n",
    "        # Take a step\n",
    "        optimizer.zero_grad()\n",
    "        loss = -(flow.log_prob(inputs=samples_batch)).mean()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Compute cumulative loss\n",
    "        cum_loss = (cum_loss*batch + loss.item())/(batch+1)\n",
    "\n",
    "        if batch%25 == 0:\n",
    "            print(\"epoch = \", epoch, \"batch = \", batch, \"/\", n_batches, \"loss = \", cum_loss)\n",
    "    \n",
    "    writer.add_scalar(\"Loss_train\", cum_loss, epoch)\n",
    "    scheduler.step()\n",
    "\n",
    "\n",
    "    # ---------- Compute validation loss -----------\n",
    "    validation_loss = 0\n",
    "    for batch in range(n_batches_validate):\n",
    "        batch_begin = batch*batch_size\n",
    "        batch_end = min( (batch+1)*batch_size, data_size_validation-1 )\n",
    "        samples_batch = test_samples[batch_begin:batch_end]\n",
    "    \n",
    "        with torch.no_grad():\n",
    "            validation_loss = (validation_loss*batch - (flow.log_prob(samples_batch)).mean())/(batch+1)\n",
    "\n",
    "    print(\"Validation loss = \", validation_loss.item())\n",
    "    writer.add_scalar(\"Loss_test\", validation_loss.item(), epoch)\n",
    "\n",
    "    if validation_loss < best_validation_loss:\n",
    "        torch.save(flow, \"flow_model_unweighted_best_validation.pt\")\n",
    "        best_validation_loss = validation_loss\n",
    "\n",
    "    \n",
    "    # ---------- Compute effective sample size ----------\n",
    "    # generate samples and evaluate llhs\n",
    "    with torch.no_grad():\n",
    "        samples = flow.sample(n_sample)\n",
    "        llhs = flow.log_prob(samples)\n",
    "\n",
    "    # Store files\n",
    "    np.savetxt(\"/tmp/samples_file.csv\", samples.cpu().numpy(), delimiter=',')\n",
    "    np.savetxt(\"/tmp/llhs_file.csv\", np.exp(llhs.cpu().numpy()), delimiter=',')\n",
    "\n",
    "    # Run the evaluator\n",
    "    cmd = os.path.abspath(os.getcwd())+'/ME_VEGAS/compute_metrics_from_likelihoods /tmp/samples_file.csv /tmp/llhs_file.csv'\n",
    "    b = subprocess.run(cmd, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE).stdout\n",
    "    lines = b.decode('ascii').split(\"\\n\")\n",
    "\n",
    "    ess = float(lines[2].split(' ')[-1])\n",
    "    \n",
    "    print(\"Effective sample size = \", ess)\n",
    "    writer.add_scalar(\"Effective_sample_size\", ess, epoch)\n",
    "\n",
    "    if ess > best_ess:\n",
    "        torch.save(flow, \"flow_model_unweighted_best_ess.pt\")\n",
    "        best_ess = ess\n",
    "        \n",
    "torch.save(flow, \"flow_model_unweighted_final.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
