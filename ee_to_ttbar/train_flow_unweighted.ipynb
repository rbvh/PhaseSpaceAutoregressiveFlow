{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math as m\n",
    "import numpy as np\n",
    "import random as r\n",
    "import matplotlib.pyplot as plt\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.optim.lr_scheduler import MultiStepLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nflows.flows.base import Flow\n",
    "from nflows.distributions.uniform import BoxUniform\n",
    "from nflows.transforms.base import CompositeTransform\n",
    "from nflows.transforms.autoregressive import MaskedPiecewiseRationalQuadraticAutoregressiveTransform\n",
    "from nflows.transforms.autoregressive import MaskedPiecewiseQuadraticAutoregressiveTransform\n",
    "from nflows.transforms.permutations import ReversePermutation\n",
    "from nflows.transforms.permutations import RandomPermutation\n",
    "from nflows.transforms.splines.rational_quadratic import rational_quadratic_spline\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import time\n",
    "import os\n",
    "from copy import deepcopy\n",
    "import math as m\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorboard writer for loss logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU/CPU selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:1\")\n",
    "#device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_RQS_knots = 5   # Number of knots in RQS transform\n",
    "n_made_layers = 0  # Number of hidden layers in every made network\n",
    "n_made_units = 10 # Number of units in every layer of the made network\n",
    "n_flow_layers = 6  # Number of layers in the flow\n",
    "\n",
    "batch_size = 1024\n",
    "n_epochs = 800\n",
    "adam_lr = 0.001     # Learning rate for the ADAM optimizer (default: 0.001)\n",
    "\n",
    "n_train = int(1e6)  # Number of training events\n",
    "n_test = int(1e5)   # Number of testing events\n",
    "n_sample = int(1e6) # Number of samples for ess evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = np.genfromtxt(\"data/unweighted_samples.csv\", delimiter=',')\n",
    "if (n_train + n_test > samples.shape[0]):\n",
    "    raise Exception(\"Not enough training data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split to a train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_samples = torch.tensor(samples[:n_train], dtype=torch.float32, device=device)\n",
    "test_samples = torch.tensor(samples[n_train:n_train+n_test], dtype=torch.float32, device=device)\n",
    "\n",
    "del samples\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_dim = train_samples.shape[1]\n",
    "base_dist = BoxUniform(torch.zeros(event_dim), torch.ones(event_dim))\n",
    "\n",
    "transforms = []\n",
    "for _ in range(n_flow_layers):\n",
    "    transforms.append(RandomPermutation(features=event_dim))\n",
    "    transforms.append(MaskedPiecewiseRationalQuadraticAutoregressiveTransform(\n",
    "        features=event_dim, \n",
    "        hidden_features=n_made_units,\n",
    "        num_bins=n_RQS_knots,\n",
    "        num_blocks=n_made_layers-1,\n",
    "        tails=\"constrained\",\n",
    "        use_residual_blocks=False\n",
    "    ))\n",
    "transform = CompositeTransform(transforms)\n",
    "\n",
    "flow = Flow(transform, base_dist).to(device)\n",
    "optimizer = optim.Adam(flow.parameters(), lr=adam_lr)\n",
    "\n",
    "scheduler = MultiStepLR(optimizer, milestones=[350, 425, 500, 575, 650, 725, 800], gamma=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch =  0 batch =  0 / 977 loss =  0.36687445640563965\n",
      "epoch =  0 batch =  25 / 977 loss =  -2.0629490261467605\n",
      "epoch =  0 batch =  50 / 977 loss =  -3.618684484239887\n",
      "epoch =  0 batch =  75 / 977 loss =  -5.101591120130921\n",
      "epoch =  0 batch =  100 / 977 loss =  -6.667597164390701\n",
      "epoch =  0 batch =  125 / 977 loss =  -7.950408336011663\n",
      "epoch =  0 batch =  150 / 977 loss =  -9.043609794648676\n",
      "epoch =  0 batch =  175 / 977 loss =  -10.07322311828929\n",
      "epoch =  0 batch =  200 / 977 loss =  -11.037217718044031\n",
      "epoch =  0 batch =  225 / 977 loss =  -11.898104333409433\n",
      "epoch =  0 batch =  250 / 977 loss =  -12.648688003984821\n",
      "epoch =  0 batch =  275 / 977 loss =  -13.305771851156289\n",
      "epoch =  0 batch =  300 / 977 loss =  -13.882847493792891\n",
      "epoch =  0 batch =  325 / 977 loss =  -14.40396438431612\n",
      "epoch =  0 batch =  350 / 977 loss =  -14.872637476443058\n",
      "epoch =  0 batch =  375 / 977 loss =  -15.303768905652491\n",
      "epoch =  0 batch =  400 / 977 loss =  -15.702826970328864\n",
      "epoch =  0 batch =  425 / 977 loss =  -16.08064773001931\n",
      "epoch =  0 batch =  450 / 977 loss =  -16.439500480510304\n",
      "epoch =  0 batch =  475 / 977 loss =  -16.77231810832036\n",
      "epoch =  0 batch =  500 / 977 loss =  -17.078494627393045\n",
      "epoch =  0 batch =  525 / 977 loss =  -17.359173040043828\n",
      "epoch =  0 batch =  550 / 977 loss =  -17.618148503916338\n",
      "epoch =  0 batch =  575 / 977 loss =  -17.854824173432362\n",
      "epoch =  0 batch =  600 / 977 loss =  -18.074274038973456\n",
      "epoch =  0 batch =  625 / 977 loss =  -18.27624886300856\n",
      "epoch =  0 batch =  650 / 977 loss =  -18.465461166647096\n",
      "epoch =  0 batch =  675 / 977 loss =  -18.64102275101965\n",
      "epoch =  0 batch =  700 / 977 loss =  -18.806105213449708\n",
      "epoch =  0 batch =  725 / 977 loss =  -18.959134870047176\n",
      "epoch =  0 batch =  750 / 977 loss =  -19.10238635624337\n",
      "epoch =  0 batch =  775 / 977 loss =  -19.237736090912122\n",
      "epoch =  0 batch =  800 / 977 loss =  -19.36552339759697\n",
      "epoch =  0 batch =  825 / 977 loss =  -19.484828455729943\n",
      "epoch =  0 batch =  850 / 977 loss =  -19.598334569952403\n",
      "epoch =  0 batch =  875 / 977 loss =  -19.70549937773956\n",
      "epoch =  0 batch =  900 / 977 loss =  -19.807141684839195\n",
      "epoch =  0 batch =  925 / 977 loss =  -19.903758138394068\n",
      "epoch =  0 batch =  950 / 977 loss =  -19.99468466138897\n",
      "epoch =  0 batch =  975 / 977 loss =  -20.08147184456867\n",
      "Validation loss =  -23.401180267333984\n",
      "Effective sample size =  0.320812\n",
      "epoch =  1 batch =  0 / 977 loss =  -23.38227081298828\n",
      "epoch =  1 batch =  25 / 977 loss =  -23.422381914578953\n",
      "epoch =  1 batch =  50 / 977 loss =  -23.44329381456562\n",
      "epoch =  1 batch =  75 / 977 loss =  -23.440167828610075\n",
      "epoch =  1 batch =  100 / 977 loss =  -23.446229556999597\n",
      "epoch =  1 batch =  125 / 977 loss =  -23.444826731606145\n",
      "epoch =  1 batch =  150 / 977 loss =  -23.454629822282616\n",
      "epoch =  1 batch =  175 / 977 loss =  -23.453428235920992\n",
      "epoch =  1 batch =  200 / 977 loss =  -23.456517034502173\n",
      "epoch =  1 batch =  225 / 977 loss =  -23.459031206316652\n",
      "epoch =  1 batch =  250 / 977 loss =  -23.460665075902444\n",
      "epoch =  1 batch =  275 / 977 loss =  -23.459851313328397\n",
      "epoch =  1 batch =  300 / 977 loss =  -23.46229171119259\n",
      "epoch =  1 batch =  325 / 977 loss =  -23.465921086036353\n",
      "epoch =  1 batch =  350 / 977 loss =  -23.46960914916122\n",
      "epoch =  1 batch =  375 / 977 loss =  -23.46983459148\n",
      "epoch =  1 batch =  400 / 977 loss =  -23.473277132410054\n",
      "epoch =  1 batch =  425 / 977 loss =  -23.47640593622771\n",
      "epoch =  1 batch =  450 / 977 loss =  -23.478888860562943\n",
      "epoch =  1 batch =  475 / 977 loss =  -23.485050562049153\n",
      "epoch =  1 batch =  500 / 977 loss =  -23.490685560032272\n",
      "epoch =  1 batch =  525 / 977 loss =  -23.493051684854596\n",
      "epoch =  1 batch =  550 / 977 loss =  -23.49445585330471\n",
      "epoch =  1 batch =  575 / 977 loss =  -23.497361169921025\n",
      "epoch =  1 batch =  600 / 977 loss =  -23.50060063074908\n",
      "epoch =  1 batch =  625 / 977 loss =  -23.505058794356756\n",
      "epoch =  1 batch =  650 / 977 loss =  -23.5087212915611\n",
      "epoch =  1 batch =  675 / 977 loss =  -23.510892543567003\n",
      "epoch =  1 batch =  700 / 977 loss =  -23.512298880562124\n",
      "epoch =  1 batch =  725 / 977 loss =  -23.514856314856157\n",
      "epoch =  1 batch =  750 / 977 loss =  -23.516829857654802\n",
      "epoch =  1 batch =  775 / 977 loss =  -23.517755555123397\n",
      "epoch =  1 batch =  800 / 977 loss =  -23.519827124777805\n",
      "epoch =  1 batch =  825 / 977 loss =  -23.522266348684095\n",
      "epoch =  1 batch =  850 / 977 loss =  -23.52424106306531\n",
      "epoch =  1 batch =  875 / 977 loss =  -23.526305270521608\n",
      "epoch =  1 batch =  900 / 977 loss =  -23.528476880207972\n",
      "epoch =  1 batch =  925 / 977 loss =  -23.53063342792684\n",
      "epoch =  1 batch =  950 / 977 loss =  -23.53181323744396\n",
      "epoch =  1 batch =  975 / 977 loss =  -23.53319702969223\n",
      "Validation loss =  -23.62066650390625\n",
      "Effective sample size =  0.450136\n",
      "epoch =  2 batch =  0 / 977 loss =  -23.77979850769043\n",
      "epoch =  2 batch =  25 / 977 loss =  -23.606034719027004\n",
      "epoch =  2 batch =  50 / 977 loss =  -23.60979356952742\n",
      "epoch =  2 batch =  75 / 977 loss =  -23.61224490717838\n",
      "epoch =  2 batch =  100 / 977 loss =  -23.61294028782609\n",
      "epoch =  2 batch =  125 / 977 loss =  -23.621039330013218\n",
      "epoch =  2 batch =  150 / 977 loss =  -23.613961541889513\n",
      "epoch =  2 batch =  175 / 977 loss =  -23.61661247773604\n",
      "epoch =  2 batch =  200 / 977 loss =  -23.622556098064972\n",
      "epoch =  2 batch =  225 / 977 loss =  -23.6255646005141\n",
      "epoch =  2 batch =  250 / 977 loss =  -23.626312711799287\n",
      "epoch =  2 batch =  275 / 977 loss =  -23.62560290184574\n",
      "epoch =  2 batch =  300 / 977 loss =  -23.624859534228758\n",
      "epoch =  2 batch =  325 / 977 loss =  -23.623581862888443\n",
      "epoch =  2 batch =  350 / 977 loss =  -23.62570174670965\n",
      "epoch =  2 batch =  375 / 977 loss =  -23.627420141341823\n",
      "epoch =  2 batch =  400 / 977 loss =  -23.628870662013775\n",
      "epoch =  2 batch =  425 / 977 loss =  -23.63225154697614\n",
      "epoch =  2 batch =  450 / 977 loss =  -23.63305743993517\n",
      "epoch =  2 batch =  475 / 977 loss =  -23.635914510037708\n",
      "epoch =  2 batch =  500 / 977 loss =  -23.63474340686302\n",
      "epoch =  2 batch =  525 / 977 loss =  -23.63287001417616\n",
      "epoch =  2 batch =  550 / 977 loss =  -23.63275770266994\n",
      "epoch =  2 batch =  575 / 977 loss =  -23.633861356311364\n",
      "epoch =  2 batch =  600 / 977 loss =  -23.63450027186541\n",
      "epoch =  2 batch =  625 / 977 loss =  -23.634866598695993\n",
      "epoch =  2 batch =  650 / 977 loss =  -23.635049802367046\n",
      "epoch =  2 batch =  675 / 977 loss =  -23.63478113772602\n",
      "epoch =  2 batch =  700 / 977 loss =  -23.63561282246328\n",
      "epoch =  2 batch =  725 / 977 loss =  -23.637057380571193\n",
      "epoch =  2 batch =  750 / 977 loss =  -23.63862511829118\n",
      "epoch =  2 batch =  775 / 977 loss =  -23.639099988740753\n",
      "epoch =  2 batch =  800 / 977 loss =  -23.64059599210857\n",
      "epoch =  2 batch =  825 / 977 loss =  -23.642234111813607\n",
      "epoch =  2 batch =  850 / 977 loss =  -23.643514279052887\n",
      "epoch =  2 batch =  875 / 977 loss =  -23.643112250114694\n",
      "epoch =  2 batch =  900 / 977 loss =  -23.644775710280552\n",
      "epoch =  2 batch =  925 / 977 loss =  -23.64465837087282\n",
      "epoch =  2 batch =  950 / 977 loss =  -23.64568890031079\n",
      "epoch =  2 batch =  975 / 977 loss =  -23.64646882307335\n",
      "Validation loss =  -23.684843063354492\n",
      "Effective sample size =  0.519697\n",
      "epoch =  3 batch =  0 / 977 loss =  -23.79697036743164\n",
      "epoch =  3 batch =  25 / 977 loss =  -23.64234440143292\n",
      "epoch =  3 batch =  50 / 977 loss =  -23.666369382072894\n",
      "epoch =  3 batch =  75 / 977 loss =  -23.670383704336064\n",
      "epoch =  3 batch =  100 / 977 loss =  -23.674084295140634\n",
      "epoch =  3 batch =  125 / 977 loss =  -23.676404665386865\n",
      "epoch =  3 batch =  150 / 977 loss =  -23.68046520561572\n",
      "epoch =  3 batch =  175 / 977 loss =  -23.678339860656056\n",
      "epoch =  3 batch =  200 / 977 loss =  -23.681548246696824\n",
      "epoch =  3 batch =  225 / 977 loss =  -23.680229144813747\n",
      "epoch =  3 batch =  250 / 977 loss =  -23.683763374845352\n",
      "epoch =  3 batch =  275 / 977 loss =  -23.68553148490796\n",
      "epoch =  3 batch =  300 / 977 loss =  -23.68631331231507\n",
      "epoch =  3 batch =  325 / 977 loss =  -23.685019920208713\n",
      "epoch =  3 batch =  350 / 977 loss =  -23.68813255505685\n",
      "epoch =  3 batch =  375 / 977 loss =  -23.687990979945415\n",
      "epoch =  3 batch =  400 / 977 loss =  -23.68716463483778\n",
      "epoch =  3 batch =  425 / 977 loss =  -23.690401256364286\n",
      "epoch =  3 batch =  450 / 977 loss =  -23.69168074326611\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch =  3 batch =  475 / 977 loss =  -23.69041650034801\n",
      "epoch =  3 batch =  500 / 977 loss =  -23.690577920087566\n",
      "epoch =  3 batch =  525 / 977 loss =  -23.692342384686494\n",
      "epoch =  3 batch =  550 / 977 loss =  -23.69088866965958\n",
      "epoch =  3 batch =  575 / 977 loss =  -23.690294189585586\n",
      "epoch =  3 batch =  600 / 977 loss =  -23.69194695318797\n",
      "epoch =  3 batch =  625 / 977 loss =  -23.690567613790584\n",
      "epoch =  3 batch =  650 / 977 loss =  -23.689800069079418\n",
      "epoch =  3 batch =  675 / 977 loss =  -23.68904068625184\n",
      "epoch =  3 batch =  700 / 977 loss =  -23.68867304389725\n",
      "epoch =  3 batch =  725 / 977 loss =  -23.68964217845402\n",
      "epoch =  3 batch =  750 / 977 loss =  -23.690529809334624\n",
      "epoch =  3 batch =  775 / 977 loss =  -23.69125203496402\n",
      "epoch =  3 batch =  800 / 977 loss =  -23.6910340336527\n",
      "epoch =  3 batch =  825 / 977 loss =  -23.69153913400941\n",
      "epoch =  3 batch =  850 / 977 loss =  -23.69215629747976\n",
      "epoch =  3 batch =  875 / 977 loss =  -23.69311002182634\n",
      "epoch =  3 batch =  900 / 977 loss =  -23.693529969447198\n",
      "epoch =  3 batch =  925 / 977 loss =  -23.694209570503645\n",
      "epoch =  3 batch =  950 / 977 loss =  -23.694761342430716\n",
      "epoch =  3 batch =  975 / 977 loss =  -23.69517656818765\n",
      "Validation loss =  -23.71769905090332\n",
      "Effective sample size =  0.540515\n",
      "epoch =  4 batch =  0 / 977 loss =  -23.604286193847656\n",
      "epoch =  4 batch =  25 / 977 loss =  -23.69720297593337\n",
      "epoch =  4 batch =  50 / 977 loss =  -23.689759759341968\n",
      "epoch =  4 batch =  75 / 977 loss =  -23.684605899610016\n",
      "epoch =  4 batch =  100 / 977 loss =  -23.698740590917012\n",
      "epoch =  4 batch =  125 / 977 loss =  -23.70534583500454\n",
      "epoch =  4 batch =  150 / 977 loss =  -23.710613806516136\n",
      "epoch =  4 batch =  175 / 977 loss =  -23.716853445226505\n",
      "epoch =  4 batch =  200 / 977 loss =  -23.72053862804205\n",
      "epoch =  4 batch =  225 / 977 loss =  -23.7205534572095\n",
      "epoch =  4 batch =  250 / 977 loss =  -23.713494129864824\n",
      "epoch =  4 batch =  275 / 977 loss =  -23.71324358815733\n",
      "epoch =  4 batch =  300 / 977 loss =  -23.71441724530091\n",
      "epoch =  4 batch =  325 / 977 loss =  -23.716604355654113\n",
      "epoch =  4 batch =  350 / 977 loss =  -23.717391869960686\n",
      "epoch =  4 batch =  375 / 977 loss =  -23.716179208552585\n",
      "epoch =  4 batch =  400 / 977 loss =  -23.714658351907705\n",
      "epoch =  4 batch =  425 / 977 loss =  -23.713354433086558\n",
      "epoch =  4 batch =  450 / 977 loss =  -23.713670620632804\n",
      "epoch =  4 batch =  475 / 977 loss =  -23.71431139136563\n",
      "epoch =  4 batch =  500 / 977 loss =  -23.714242478330693\n",
      "epoch =  4 batch =  525 / 977 loss =  -23.714811078495853\n",
      "epoch =  4 batch =  550 / 977 loss =  -23.714915772315155\n",
      "epoch =  4 batch =  575 / 977 loss =  -23.71594678031074\n",
      "epoch =  4 batch =  600 / 977 loss =  -23.717507963767673\n",
      "epoch =  4 batch =  625 / 977 loss =  -23.7182839518538\n",
      "epoch =  4 batch =  650 / 977 loss =  -23.719583429316053\n",
      "epoch =  4 batch =  675 / 977 loss =  -23.72132791428877\n",
      "epoch =  4 batch =  700 / 977 loss =  -23.7221414753782\n",
      "epoch =  4 batch =  725 / 977 loss =  -23.72237275651665\n",
      "epoch =  4 batch =  750 / 977 loss =  -23.722729928007784\n",
      "epoch =  4 batch =  775 / 977 loss =  -23.722510033047087\n",
      "epoch =  4 batch =  800 / 977 loss =  -23.72395870480199\n",
      "epoch =  4 batch =  825 / 977 loss =  -23.723843172733787\n",
      "epoch =  4 batch =  850 / 977 loss =  -23.7252707363716\n",
      "epoch =  4 batch =  875 / 977 loss =  -23.724605190155177\n",
      "epoch =  4 batch =  900 / 977 loss =  -23.723979270418535\n",
      "epoch =  4 batch =  925 / 977 loss =  -23.725180529106265\n",
      "epoch =  4 batch =  950 / 977 loss =  -23.724987990723307\n",
      "epoch =  4 batch =  975 / 977 loss =  -23.724739397158395\n",
      "Validation loss =  -23.732234954833984\n",
      "Effective sample size =  0.553508\n",
      "epoch =  5 batch =  0 / 977 loss =  -23.842655181884766\n",
      "epoch =  5 batch =  25 / 977 loss =  -23.748027581434982\n",
      "epoch =  5 batch =  50 / 977 loss =  -23.72651762120864\n",
      "epoch =  5 batch =  75 / 977 loss =  -23.730291667737458\n",
      "epoch =  5 batch =  100 / 977 loss =  -23.737339907353466\n",
      "epoch =  5 batch =  125 / 977 loss =  -23.738717775496227\n",
      "epoch =  5 batch =  150 / 977 loss =  -23.738896628878752\n",
      "epoch =  5 batch =  175 / 977 loss =  -23.73689662326466\n",
      "epoch =  5 batch =  200 / 977 loss =  -23.74624128958479\n",
      "epoch =  5 batch =  225 / 977 loss =  -23.744516642747726\n",
      "epoch =  5 batch =  250 / 977 loss =  -23.745273628082884\n",
      "epoch =  5 batch =  275 / 977 loss =  -23.744527961896814\n",
      "epoch =  5 batch =  300 / 977 loss =  -23.745185953438096\n",
      "epoch =  5 batch =  325 / 977 loss =  -23.744200150659495\n",
      "epoch =  5 batch =  350 / 977 loss =  -23.745466351848744\n",
      "epoch =  5 batch =  375 / 977 loss =  -23.746365486307365\n",
      "epoch =  5 batch =  400 / 977 loss =  -23.74554645509793\n",
      "epoch =  5 batch =  425 / 977 loss =  -23.743338455056936\n",
      "epoch =  5 batch =  450 / 977 loss =  -23.743450431231665\n",
      "epoch =  5 batch =  475 / 977 loss =  -23.74413840910969\n",
      "epoch =  5 batch =  500 / 977 loss =  -23.744439096507925\n",
      "epoch =  5 batch =  525 / 977 loss =  -23.746941573719575\n",
      "epoch =  5 batch =  550 / 977 loss =  -23.74518477202762\n",
      "epoch =  5 batch =  575 / 977 loss =  -23.744027237097438\n",
      "epoch =  5 batch =  600 / 977 loss =  -23.743969071526312\n",
      "epoch =  5 batch =  625 / 977 loss =  -23.744848772359756\n",
      "epoch =  5 batch =  650 / 977 loss =  -23.74452565159484\n",
      "epoch =  5 batch =  675 / 977 loss =  -23.744509237052426\n",
      "epoch =  5 batch =  700 / 977 loss =  -23.745487651199156\n",
      "epoch =  5 batch =  725 / 977 loss =  -23.744731233139678\n",
      "epoch =  5 batch =  750 / 977 loss =  -23.743644109896124\n",
      "epoch =  5 batch =  775 / 977 loss =  -23.743752572954325\n",
      "epoch =  5 batch =  800 / 977 loss =  -23.744647286804437\n",
      "epoch =  5 batch =  825 / 977 loss =  -23.744865214276263\n",
      "epoch =  5 batch =  850 / 977 loss =  -23.74442070043186\n",
      "epoch =  5 batch =  875 / 977 loss =  -23.744732460474868\n",
      "epoch =  5 batch =  900 / 977 loss =  -23.745340103843773\n",
      "epoch =  5 batch =  925 / 977 loss =  -23.744751194898313\n",
      "epoch =  5 batch =  950 / 977 loss =  -23.744650737469637\n",
      "epoch =  5 batch =  975 / 977 loss =  -23.744453787803657\n",
      "Validation loss =  -23.73809814453125\n",
      "Effective sample size =  0.558147\n",
      "epoch =  6 batch =  0 / 977 loss =  -23.85015106201172\n",
      "epoch =  6 batch =  25 / 977 loss =  -23.752012692964993\n",
      "epoch =  6 batch =  50 / 977 loss =  -23.746119742299996\n",
      "epoch =  6 batch =  75 / 977 loss =  -23.75065592715615\n",
      "epoch =  6 batch =  100 / 977 loss =  -23.751822348868497\n",
      "epoch =  6 batch =  125 / 977 loss =  -23.761987822396417\n",
      "epoch =  6 batch =  150 / 977 loss =  -23.76074574956832\n",
      "epoch =  6 batch =  175 / 977 loss =  -23.761281360279444\n",
      "epoch =  6 batch =  200 / 977 loss =  -23.762102886218944\n",
      "epoch =  6 batch =  225 / 977 loss =  -23.763952213051056\n",
      "epoch =  6 batch =  250 / 977 loss =  -23.757140436970392\n",
      "epoch =  6 batch =  275 / 977 loss =  -23.755256645921357\n",
      "epoch =  6 batch =  300 / 977 loss =  -23.75280570350217\n",
      "epoch =  6 batch =  325 / 977 loss =  -23.751490826987055\n",
      "epoch =  6 batch =  350 / 977 loss =  -23.750213394817123\n",
      "epoch =  6 batch =  375 / 977 loss =  -23.750792751920983\n",
      "epoch =  6 batch =  400 / 977 loss =  -23.751159620403946\n",
      "epoch =  6 batch =  425 / 977 loss =  -23.751983718692976\n",
      "epoch =  6 batch =  450 / 977 loss =  -23.755720857506052\n",
      "epoch =  6 batch =  475 / 977 loss =  -23.75416513651359\n",
      "epoch =  6 batch =  500 / 977 loss =  -23.755047906658607\n",
      "epoch =  6 batch =  525 / 977 loss =  -23.754106086469875\n",
      "epoch =  6 batch =  550 / 977 loss =  -23.754294019861792\n",
      "epoch =  6 batch =  575 / 977 loss =  -23.754112243652337\n",
      "epoch =  6 batch =  600 / 977 loss =  -23.7536516427597\n",
      "epoch =  6 batch =  625 / 977 loss =  -23.752018785324328\n",
      "epoch =  6 batch =  650 / 977 loss =  -23.75314829719412\n",
      "epoch =  6 batch =  675 / 977 loss =  -23.754438521593954\n",
      "epoch =  6 batch =  700 / 977 loss =  -23.754616085710918\n",
      "epoch =  6 batch =  725 / 977 loss =  -23.754866029933762\n",
      "epoch =  6 batch =  750 / 977 loss =  -23.753851734369608\n",
      "epoch =  6 batch =  775 / 977 loss =  -23.753701743391343\n",
      "epoch =  6 batch =  800 / 977 loss =  -23.754411635476227\n",
      "epoch =  6 batch =  825 / 977 loss =  -23.754832658005657\n",
      "epoch =  6 batch =  850 / 977 loss =  -23.7553169057736\n",
      "epoch =  6 batch =  875 / 977 loss =  -23.75584032764171\n",
      "epoch =  6 batch =  900 / 977 loss =  -23.756763282547226\n",
      "epoch =  6 batch =  925 / 977 loss =  -23.758277044440426\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch =  6 batch =  950 / 977 loss =  -23.759752676690017\n",
      "epoch =  6 batch =  975 / 977 loss =  -23.759892115827444\n",
      "Validation loss =  -23.76146697998047\n",
      "Effective sample size =  0.588077\n",
      "epoch =  7 batch =  0 / 977 loss =  -23.683998107910156\n",
      "epoch =  7 batch =  25 / 977 loss =  -23.7843258197491\n",
      "epoch =  7 batch =  50 / 977 loss =  -23.795803331861308\n",
      "epoch =  7 batch =  75 / 977 loss =  -23.801229803185716\n",
      "epoch =  7 batch =  100 / 977 loss =  -23.797364659828716\n",
      "epoch =  7 batch =  125 / 977 loss =  -23.790553214058043\n",
      "epoch =  7 batch =  150 / 977 loss =  -23.78041722127144\n",
      "epoch =  7 batch =  175 / 977 loss =  -23.782222997058522\n",
      "epoch =  7 batch =  200 / 977 loss =  -23.775672694343832\n",
      "epoch =  7 batch =  225 / 977 loss =  -23.774108355024218\n",
      "epoch =  7 batch =  250 / 977 loss =  -23.771767863239425\n",
      "epoch =  7 batch =  275 / 977 loss =  -23.770421283832494\n",
      "epoch =  7 batch =  300 / 977 loss =  -23.77311010772604\n",
      "epoch =  7 batch =  325 / 977 loss =  -23.773515718846237\n",
      "epoch =  7 batch =  350 / 977 loss =  -23.769056657101014\n",
      "epoch =  7 batch =  375 / 977 loss =  -23.771252829977808\n",
      "epoch =  7 batch =  400 / 977 loss =  -23.77325890367465\n",
      "epoch =  7 batch =  425 / 977 loss =  -23.77620384950593\n",
      "epoch =  7 batch =  450 / 977 loss =  -23.77539671498233\n",
      "epoch =  7 batch =  475 / 977 loss =  -23.77383616792054\n",
      "epoch =  7 batch =  500 / 977 loss =  -23.776155681191327\n",
      "epoch =  7 batch =  525 / 977 loss =  -23.774672968759283\n",
      "epoch =  7 batch =  550 / 977 loss =  -23.7746042885062\n",
      "epoch =  7 batch =  575 / 977 loss =  -23.773925224939976\n",
      "epoch =  7 batch =  600 / 977 loss =  -23.774104446817343\n",
      "epoch =  7 batch =  625 / 977 loss =  -23.774555465283854\n",
      "epoch =  7 batch =  650 / 977 loss =  -23.774257809335722\n",
      "epoch =  7 batch =  675 / 977 loss =  -23.77431581993779\n",
      "epoch =  7 batch =  700 / 977 loss =  -23.773070573466637\n",
      "epoch =  7 batch =  725 / 977 loss =  -23.772582298467952\n",
      "epoch =  7 batch =  750 / 977 loss =  -23.772506348143867\n",
      "epoch =  7 batch =  775 / 977 loss =  -23.771397278480908\n",
      "epoch =  7 batch =  800 / 977 loss =  -23.772138978955734\n",
      "epoch =  7 batch =  825 / 977 loss =  -23.773195864790562\n",
      "epoch =  7 batch =  850 / 977 loss =  -23.773271457569006\n",
      "epoch =  7 batch =  875 / 977 loss =  -23.773379672063527\n",
      "epoch =  7 batch =  900 / 977 loss =  -23.772861565389842\n",
      "epoch =  7 batch =  925 / 977 loss =  -23.77306249177738\n",
      "epoch =  7 batch =  950 / 977 loss =  -23.774032530599076\n",
      "epoch =  7 batch =  975 / 977 loss =  -23.77319489737025\n",
      "Validation loss =  -23.76506233215332\n",
      "Effective sample size =  0.59181\n",
      "epoch =  8 batch =  0 / 977 loss =  -24.061019897460938\n",
      "epoch =  8 batch =  25 / 977 loss =  -23.82179700411283\n",
      "epoch =  8 batch =  50 / 977 loss =  -23.80490400276932\n",
      "epoch =  8 batch =  75 / 977 loss =  -23.787484947003815\n",
      "epoch =  8 batch =  100 / 977 loss =  -23.789786933672314\n",
      "epoch =  8 batch =  125 / 977 loss =  -23.788200802273224\n",
      "epoch =  8 batch =  150 / 977 loss =  -23.79056664018442\n",
      "epoch =  8 batch =  175 / 977 loss =  -23.79110429503701\n",
      "epoch =  8 batch =  200 / 977 loss =  -23.79193446410829\n",
      "epoch =  8 batch =  225 / 977 loss =  -23.794286651948912\n",
      "epoch =  8 batch =  250 / 977 loss =  -23.788624478526323\n",
      "epoch =  8 batch =  275 / 977 loss =  -23.790315780086793\n",
      "epoch =  8 batch =  300 / 977 loss =  -23.787066241039394\n",
      "epoch =  8 batch =  325 / 977 loss =  -23.78807159142991\n",
      "epoch =  8 batch =  350 / 977 loss =  -23.78397071599281\n",
      "epoch =  8 batch =  375 / 977 loss =  -23.785267134930226\n",
      "epoch =  8 batch =  400 / 977 loss =  -23.78544267097911\n",
      "epoch =  8 batch =  425 / 977 loss =  -23.785302591995453\n",
      "epoch =  8 batch =  450 / 977 loss =  -23.783139044852586\n",
      "epoch =  8 batch =  475 / 977 loss =  -23.783491879952056\n",
      "epoch =  8 batch =  500 / 977 loss =  -23.782379987948907\n",
      "epoch =  8 batch =  525 / 977 loss =  -23.78313095034755\n",
      "epoch =  8 batch =  550 / 977 loss =  -23.78053728508646\n",
      "epoch =  8 batch =  575 / 977 loss =  -23.781478818919922\n",
      "epoch =  8 batch =  600 / 977 loss =  -23.78085395698738\n",
      "epoch =  8 batch =  625 / 977 loss =  -23.78142373630414\n",
      "epoch =  8 batch =  650 / 977 loss =  -23.782928419918882\n",
      "epoch =  8 batch =  675 / 977 loss =  -23.78326186343764\n",
      "epoch =  8 batch =  700 / 977 loss =  -23.78199923973792\n",
      "epoch =  8 batch =  725 / 977 loss =  -23.780558197294724\n",
      "epoch =  8 batch =  750 / 977 loss =  -23.78040220512056\n",
      "epoch =  8 batch =  775 / 977 loss =  -23.780178419093506\n",
      "epoch =  8 batch =  800 / 977 loss =  -23.779704871397943\n",
      "epoch =  8 batch =  825 / 977 loss =  -23.781368936811184\n",
      "epoch =  8 batch =  850 / 977 loss =  -23.780177958003232\n",
      "epoch =  8 batch =  875 / 977 loss =  -23.78066018727273\n",
      "epoch =  8 batch =  900 / 977 loss =  -23.78104475997265\n",
      "epoch =  8 batch =  925 / 977 loss =  -23.780344532581445\n",
      "epoch =  8 batch =  950 / 977 loss =  -23.779986587107253\n",
      "epoch =  8 batch =  975 / 977 loss =  -23.780076636642715\n",
      "Validation loss =  -23.788549423217773\n",
      "Effective sample size =  0.618526\n",
      "epoch =  9 batch =  0 / 977 loss =  -23.674705505371094\n",
      "epoch =  9 batch =  25 / 977 loss =  -23.76201769021841\n",
      "epoch =  9 batch =  50 / 977 loss =  -23.781331081016397\n",
      "epoch =  9 batch =  75 / 977 loss =  -23.791766342363868\n",
      "epoch =  9 batch =  100 / 977 loss =  -23.784542008201683\n",
      "epoch =  9 batch =  125 / 977 loss =  -23.790549641563786\n",
      "epoch =  9 batch =  150 / 977 loss =  -23.794739300052072\n",
      "epoch =  9 batch =  175 / 977 loss =  -23.786852804097272\n",
      "epoch =  9 batch =  200 / 977 loss =  -23.788929944014676\n",
      "epoch =  9 batch =  225 / 977 loss =  -23.790256491804552\n",
      "epoch =  9 batch =  250 / 977 loss =  -23.78832133927669\n",
      "epoch =  9 batch =  275 / 977 loss =  -23.78395687324414\n",
      "epoch =  9 batch =  300 / 977 loss =  -23.7817649271005\n",
      "epoch =  9 batch =  325 / 977 loss =  -23.78476678813162\n",
      "epoch =  9 batch =  350 / 977 loss =  -23.78374576296902\n",
      "epoch =  9 batch =  375 / 977 loss =  -23.7863657778882\n",
      "epoch =  9 batch =  400 / 977 loss =  -23.7873347275275\n",
      "epoch =  9 batch =  425 / 977 loss =  -23.786827436635196\n",
      "epoch =  9 batch =  450 / 977 loss =  -23.787353837040737\n",
      "epoch =  9 batch =  475 / 977 loss =  -23.78807002155721\n",
      "epoch =  9 batch =  500 / 977 loss =  -23.787881839775043\n",
      "epoch =  9 batch =  525 / 977 loss =  -23.78591484896584\n",
      "epoch =  9 batch =  550 / 977 loss =  -23.78569658698274\n",
      "epoch =  9 batch =  575 / 977 loss =  -23.786378357145523\n",
      "epoch =  9 batch =  600 / 977 loss =  -23.785995343758938\n",
      "epoch =  9 batch =  625 / 977 loss =  -23.784305618213015\n",
      "epoch =  9 batch =  650 / 977 loss =  -23.78512134639898\n",
      "epoch =  9 batch =  675 / 977 loss =  -23.785468262328205\n",
      "epoch =  9 batch =  700 / 977 loss =  -23.787039126887308\n",
      "epoch =  9 batch =  725 / 977 loss =  -23.788844384437756\n",
      "epoch =  9 batch =  750 / 977 loss =  -23.78907496760911\n",
      "epoch =  9 batch =  775 / 977 loss =  -23.78781617302256\n",
      "epoch =  9 batch =  800 / 977 loss =  -23.78892157765364\n",
      "epoch =  9 batch =  825 / 977 loss =  -23.788987887107723\n",
      "epoch =  9 batch =  850 / 977 loss =  -23.789541558289223\n",
      "epoch =  9 batch =  875 / 977 loss =  -23.791241817822744\n",
      "epoch =  9 batch =  900 / 977 loss =  -23.791895731969365\n",
      "epoch =  9 batch =  925 / 977 loss =  -23.790195586614427\n",
      "epoch =  9 batch =  950 / 977 loss =  -23.790260016103403\n",
      "epoch =  9 batch =  975 / 977 loss =  -23.78950841700445\n",
      "Validation loss =  -23.758432388305664\n",
      "Effective sample size =  0.582004\n",
      "epoch =  10 batch =  0 / 977 loss =  -23.78212547302246\n",
      "epoch =  10 batch =  25 / 977 loss =  -23.75899131481464\n",
      "epoch =  10 batch =  50 / 977 loss =  -23.7737377391142\n",
      "epoch =  10 batch =  75 / 977 loss =  -23.7817860402559\n",
      "epoch =  10 batch =  100 / 977 loss =  -23.79481787728791\n",
      "epoch =  10 batch =  125 / 977 loss =  -23.794069017682755\n",
      "epoch =  10 batch =  150 / 977 loss =  -23.79351548959088\n",
      "epoch =  10 batch =  175 / 977 loss =  -23.797869443893443\n",
      "epoch =  10 batch =  200 / 977 loss =  -23.797116369750377\n",
      "epoch =  10 batch =  225 / 977 loss =  -23.801964709189093\n",
      "epoch =  10 batch =  250 / 977 loss =  -23.800688830979798\n",
      "epoch =  10 batch =  275 / 977 loss =  -23.80291862764221\n",
      "epoch =  10 batch =  300 / 977 loss =  -23.797001829179028\n",
      "epoch =  10 batch =  325 / 977 loss =  -23.793168184947387\n",
      "epoch =  10 batch =  350 / 977 loss =  -23.795731878688194\n",
      "epoch =  10 batch =  375 / 977 loss =  -23.796058441730256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch =  10 batch =  400 / 977 loss =  -23.795546771879504\n",
      "epoch =  10 batch =  425 / 977 loss =  -23.794366518656414\n",
      "epoch =  10 batch =  450 / 977 loss =  -23.79383095616512\n",
      "epoch =  10 batch =  475 / 977 loss =  -23.794841209379566\n",
      "epoch =  10 batch =  500 / 977 loss =  -23.795906413339093\n",
      "epoch =  10 batch =  525 / 977 loss =  -23.79535579681397\n",
      "epoch =  10 batch =  550 / 977 loss =  -23.79637775663456\n",
      "epoch =  10 batch =  575 / 977 loss =  -23.79573469029533\n",
      "epoch =  10 batch =  600 / 977 loss =  -23.79641585580125\n",
      "epoch =  10 batch =  625 / 977 loss =  -23.79745897165122\n",
      "epoch =  10 batch =  650 / 977 loss =  -23.79727296492289\n",
      "epoch =  10 batch =  675 / 977 loss =  -23.798857054061454\n",
      "epoch =  10 batch =  700 / 977 loss =  -23.79937880457555\n",
      "epoch =  10 batch =  725 / 977 loss =  -23.80007571753722\n",
      "epoch =  10 batch =  750 / 977 loss =  -23.80014764961011\n",
      "epoch =  10 batch =  775 / 977 loss =  -23.79868963084272\n",
      "epoch =  10 batch =  800 / 977 loss =  -23.79919515983593\n",
      "epoch =  10 batch =  825 / 977 loss =  -23.799932290509037\n",
      "epoch =  10 batch =  850 / 977 loss =  -23.798211999841655\n",
      "epoch =  10 batch =  875 / 977 loss =  -23.79776803979048\n",
      "epoch =  10 batch =  900 / 977 loss =  -23.79811456280201\n",
      "epoch =  10 batch =  925 / 977 loss =  -23.797399442602714\n",
      "epoch =  10 batch =  950 / 977 loss =  -23.79661181597305\n",
      "epoch =  10 batch =  975 / 977 loss =  -23.797432160768366\n",
      "Validation loss =  -23.78790283203125\n",
      "Effective sample size =  0.325821\n",
      "epoch =  11 batch =  0 / 977 loss =  -23.572906494140625\n",
      "epoch =  11 batch =  25 / 977 loss =  -23.77571223332332\n",
      "epoch =  11 batch =  50 / 977 loss =  -23.77138500587613\n",
      "epoch =  11 batch =  75 / 977 loss =  -23.778401876750745\n",
      "epoch =  11 batch =  100 / 977 loss =  -23.78033464261801\n",
      "epoch =  11 batch =  125 / 977 loss =  -23.7857600318061\n",
      "epoch =  11 batch =  150 / 977 loss =  -23.787913177187082\n",
      "epoch =  11 batch =  175 / 977 loss =  -23.797178105874494\n",
      "epoch =  11 batch =  200 / 977 loss =  -23.79687734385628\n",
      "epoch =  11 batch =  225 / 977 loss =  -23.79460117880222\n",
      "epoch =  11 batch =  250 / 977 loss =  -23.79114864546939\n",
      "epoch =  11 batch =  275 / 977 loss =  -23.793183782826297\n",
      "epoch =  11 batch =  300 / 977 loss =  -23.793925991882123\n",
      "epoch =  11 batch =  325 / 977 loss =  -23.795501872805737\n",
      "epoch =  11 batch =  350 / 977 loss =  -23.794125961781912\n",
      "epoch =  11 batch =  375 / 977 loss =  -23.79583732625272\n",
      "epoch =  11 batch =  400 / 977 loss =  -23.79665305311246\n",
      "epoch =  11 batch =  425 / 977 loss =  -23.79942893981934\n",
      "epoch =  11 batch =  450 / 977 loss =  -23.800097108151594\n",
      "epoch =  11 batch =  475 / 977 loss =  -23.801505906241285\n",
      "epoch =  11 batch =  500 / 977 loss =  -23.8003339900704\n",
      "epoch =  11 batch =  525 / 977 loss =  -23.799410439262825\n",
      "epoch =  11 batch =  550 / 977 loss =  -23.79884404149549\n",
      "epoch =  11 batch =  575 / 977 loss =  -23.79818289809756\n",
      "epoch =  11 batch =  600 / 977 loss =  -23.798752653023563\n",
      "epoch =  11 batch =  625 / 977 loss =  -23.799043981411966\n",
      "epoch =  11 batch =  650 / 977 loss =  -23.798279166038494\n",
      "epoch =  11 batch =  675 / 977 loss =  -23.798509625993532\n",
      "epoch =  11 batch =  700 / 977 loss =  -23.799501223162807\n",
      "epoch =  11 batch =  725 / 977 loss =  -23.799933888038645\n",
      "epoch =  11 batch =  750 / 977 loss =  -23.80042339736389\n",
      "epoch =  11 batch =  775 / 977 loss =  -23.80193682552612\n",
      "epoch =  11 batch =  800 / 977 loss =  -23.80234754279013\n",
      "epoch =  11 batch =  825 / 977 loss =  -23.802670968358214\n",
      "epoch =  11 batch =  850 / 977 loss =  -23.802250697385823\n",
      "epoch =  11 batch =  875 / 977 loss =  -23.80264371932913\n",
      "epoch =  11 batch =  900 / 977 loss =  -23.802055293262065\n",
      "epoch =  11 batch =  925 / 977 loss =  -23.80341733763593\n",
      "epoch =  11 batch =  950 / 977 loss =  -23.803675494108784\n",
      "epoch =  11 batch =  975 / 977 loss =  -23.802470899019077\n",
      "Validation loss =  -23.802518844604492\n",
      "Effective sample size =  0.62833\n",
      "epoch =  12 batch =  0 / 977 loss =  -23.707534790039062\n",
      "epoch =  12 batch =  25 / 977 loss =  -23.80722764822153\n",
      "epoch =  12 batch =  50 / 977 loss =  -23.837173200121114\n",
      "epoch =  12 batch =  75 / 977 loss =  -23.817645549774173\n",
      "epoch =  12 batch =  100 / 977 loss =  -23.808193886634147\n",
      "epoch =  12 batch =  125 / 977 loss =  -23.797707466852096\n",
      "epoch =  12 batch =  150 / 977 loss =  -23.79637649990865\n",
      "epoch =  12 batch =  175 / 977 loss =  -23.800385876135394\n",
      "epoch =  12 batch =  200 / 977 loss =  -23.801718963319388\n",
      "epoch =  12 batch =  225 / 977 loss =  -23.805129270637984\n",
      "epoch =  12 batch =  250 / 977 loss =  -23.80583180279371\n",
      "epoch =  12 batch =  275 / 977 loss =  -23.804919636767846\n",
      "epoch =  12 batch =  300 / 977 loss =  -23.801451559478664\n",
      "epoch =  12 batch =  325 / 977 loss =  -23.801757572618737\n",
      "epoch =  12 batch =  350 / 977 loss =  -23.797373910235542\n",
      "epoch =  12 batch =  375 / 977 loss =  -23.79850783246629\n",
      "epoch =  12 batch =  400 / 977 loss =  -23.800585634987847\n",
      "epoch =  12 batch =  425 / 977 loss =  -23.80022030593084\n",
      "epoch =  12 batch =  450 / 977 loss =  -23.799825621814264\n",
      "epoch =  12 batch =  475 / 977 loss =  -23.799646361535338\n",
      "epoch =  12 batch =  500 / 977 loss =  -23.798818279883104\n",
      "epoch =  12 batch =  525 / 977 loss =  -23.800732039680046\n",
      "epoch =  12 batch =  550 / 977 loss =  -23.801510296802554\n",
      "epoch =  12 batch =  575 / 977 loss =  -23.80220198631287\n",
      "epoch =  12 batch =  600 / 977 loss =  -23.802138752231187\n",
      "epoch =  12 batch =  625 / 977 loss =  -23.803446565573203\n",
      "epoch =  12 batch =  650 / 977 loss =  -23.803677739086226\n",
      "epoch =  12 batch =  675 / 977 loss =  -23.804217809756114\n",
      "epoch =  12 batch =  700 / 977 loss =  -23.80337605768874\n",
      "epoch =  12 batch =  725 / 977 loss =  -23.804315524981355\n",
      "epoch =  12 batch =  750 / 977 loss =  -23.804205230326836\n",
      "epoch =  12 batch =  775 / 977 loss =  -23.80562148634919\n",
      "epoch =  12 batch =  800 / 977 loss =  -23.80401272005801\n",
      "epoch =  12 batch =  825 / 977 loss =  -23.805215244431746\n",
      "epoch =  12 batch =  850 / 977 loss =  -23.805023081294227\n",
      "epoch =  12 batch =  875 / 977 loss =  -23.80452664910929\n",
      "epoch =  12 batch =  900 / 977 loss =  -23.806256259321227\n",
      "epoch =  12 batch =  925 / 977 loss =  -23.806466965644447\n",
      "epoch =  12 batch =  950 / 977 loss =  -23.80588488974906\n",
      "epoch =  12 batch =  975 / 977 loss =  -23.806582140140836\n",
      "Validation loss =  -23.809528350830078\n",
      "Effective sample size =  0.627634\n",
      "epoch =  13 batch =  0 / 977 loss =  -23.695560455322266\n",
      "epoch =  13 batch =  25 / 977 loss =  -23.844535314119778\n",
      "epoch =  13 batch =  50 / 977 loss =  -23.843320248173733\n",
      "epoch =  13 batch =  75 / 977 loss =  -23.84132739117271\n",
      "epoch =  13 batch =  100 / 977 loss =  -23.83225582613803\n",
      "epoch =  13 batch =  125 / 977 loss =  -23.828966231573194\n",
      "epoch =  13 batch =  150 / 977 loss =  -23.829391530017975\n",
      "epoch =  13 batch =  175 / 977 loss =  -23.828765110536054\n",
      "epoch =  13 batch =  200 / 977 loss =  -23.830801816722055\n",
      "epoch =  13 batch =  225 / 977 loss =  -23.83069186927998\n",
      "epoch =  13 batch =  250 / 977 loss =  -23.832630818583574\n",
      "epoch =  13 batch =  275 / 977 loss =  -23.828993272090305\n",
      "epoch =  13 batch =  300 / 977 loss =  -23.830571526308773\n",
      "epoch =  13 batch =  325 / 977 loss =  -23.82915458796213\n",
      "epoch =  13 batch =  350 / 977 loss =  -23.825132940569475\n",
      "epoch =  13 batch =  375 / 977 loss =  -23.822071476185556\n",
      "epoch =  13 batch =  400 / 977 loss =  -23.82188353693097\n",
      "epoch =  13 batch =  425 / 977 loss =  -23.822089575825707\n",
      "epoch =  13 batch =  450 / 977 loss =  -23.81931954106839\n",
      "epoch =  13 batch =  475 / 977 loss =  -23.81871897432983\n",
      "epoch =  13 batch =  500 / 977 loss =  -23.817112056557036\n",
      "epoch =  13 batch =  525 / 977 loss =  -23.81683947559544\n",
      "epoch =  13 batch =  550 / 977 loss =  -23.81656100139859\n",
      "epoch =  13 batch =  575 / 977 loss =  -23.816219713952794\n",
      "epoch =  13 batch =  600 / 977 loss =  -23.817141696339615\n",
      "epoch =  13 batch =  625 / 977 loss =  -23.81624014309036\n",
      "epoch =  13 batch =  650 / 977 loss =  -23.816222262638853\n",
      "epoch =  13 batch =  675 / 977 loss =  -23.815933473011423\n",
      "epoch =  13 batch =  700 / 977 loss =  -23.815342975240952\n",
      "epoch =  13 batch =  725 / 977 loss =  -23.815016441765547\n",
      "epoch =  13 batch =  750 / 977 loss =  -23.81487221851169\n",
      "epoch =  13 batch =  775 / 977 loss =  -23.814991299639026\n",
      "epoch =  13 batch =  800 / 977 loss =  -23.814923716246245\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch =  13 batch =  825 / 977 loss =  -23.813917402493733\n",
      "epoch =  13 batch =  850 / 977 loss =  -23.815979178727847\n",
      "epoch =  13 batch =  875 / 977 loss =  -23.814537727669478\n",
      "epoch =  13 batch =  900 / 977 loss =  -23.814293593598244\n",
      "epoch =  13 batch =  925 / 977 loss =  -23.813726647626233\n",
      "epoch =  13 batch =  950 / 977 loss =  -23.81303695574417\n",
      "epoch =  13 batch =  975 / 977 loss =  -23.81292539541837\n",
      "Validation loss =  -23.799545288085938\n",
      "Effective sample size =  0.609028\n",
      "epoch =  14 batch =  0 / 977 loss =  -23.822444915771484\n",
      "epoch =  14 batch =  25 / 977 loss =  -23.824701969440166\n",
      "epoch =  14 batch =  50 / 977 loss =  -23.843042897243127\n",
      "epoch =  14 batch =  75 / 977 loss =  -23.8301887512207\n",
      "epoch =  14 batch =  100 / 977 loss =  -23.8123352692859\n",
      "epoch =  14 batch =  125 / 977 loss =  -23.813177063351585\n",
      "epoch =  14 batch =  150 / 977 loss =  -23.80861771185667\n",
      "epoch =  14 batch =  175 / 977 loss =  -23.810181303457792\n",
      "epoch =  14 batch =  200 / 977 loss =  -23.814329014488724\n",
      "epoch =  14 batch =  225 / 977 loss =  -23.8134574468157\n",
      "epoch =  14 batch =  250 / 977 loss =  -23.816119798151153\n",
      "epoch =  14 batch =  275 / 977 loss =  -23.816896562990948\n",
      "epoch =  14 batch =  300 / 977 loss =  -23.81747440959133\n",
      "epoch =  14 batch =  325 / 977 loss =  -23.81792871206085\n",
      "epoch =  14 batch =  350 / 977 loss =  -23.817472447017657\n",
      "epoch =  14 batch =  375 / 977 loss =  -23.818407007988462\n",
      "epoch =  14 batch =  400 / 977 loss =  -23.818788951769136\n",
      "epoch =  14 batch =  425 / 977 loss =  -23.81796227934215\n",
      "epoch =  14 batch =  450 / 977 loss =  -23.817486743969294\n",
      "epoch =  14 batch =  475 / 977 loss =  -23.81851888303997\n",
      "epoch =  14 batch =  500 / 977 loss =  -23.81770641456345\n",
      "epoch =  14 batch =  525 / 977 loss =  -23.818724954989474\n",
      "epoch =  14 batch =  550 / 977 loss =  -23.817522675502108\n",
      "epoch =  14 batch =  575 / 977 loss =  -23.817279385195846\n",
      "epoch =  14 batch =  600 / 977 loss =  -23.817673103979942\n",
      "epoch =  14 batch =  625 / 977 loss =  -23.818747215758506\n",
      "epoch =  14 batch =  650 / 977 loss =  -23.819400511945283\n",
      "epoch =  14 batch =  675 / 977 loss =  -23.819951133615188\n",
      "epoch =  14 batch =  700 / 977 loss =  -23.818719608127328\n",
      "epoch =  14 batch =  725 / 977 loss =  -23.818795214671425\n",
      "epoch =  14 batch =  750 / 977 loss =  -23.819009803741515\n",
      "epoch =  14 batch =  775 / 977 loss =  -23.818614158433757\n",
      "epoch =  14 batch =  800 / 977 loss =  -23.817655444294047\n",
      "epoch =  14 batch =  825 / 977 loss =  -23.818681298964844\n",
      "epoch =  14 batch =  850 / 977 loss =  -23.818704340628834\n",
      "epoch =  14 batch =  875 / 977 loss =  -23.819676427536375\n",
      "epoch =  14 batch =  900 / 977 loss =  -23.81972413269451\n",
      "epoch =  14 batch =  925 / 977 loss =  -23.818511909336575\n",
      "epoch =  14 batch =  950 / 977 loss =  -23.81819846376888\n",
      "epoch =  14 batch =  975 / 977 loss =  -23.81767483031165\n",
      "Validation loss =  -23.81256103515625\n",
      "Effective sample size =  0.642147\n",
      "epoch =  15 batch =  0 / 977 loss =  -23.60780143737793\n",
      "epoch =  15 batch =  25 / 977 loss =  -23.820451222933254\n",
      "epoch =  15 batch =  50 / 977 loss =  -23.822898490756167\n",
      "epoch =  15 batch =  75 / 977 loss =  -23.82067512211047\n",
      "epoch =  15 batch =  100 / 977 loss =  -23.833712700569983\n",
      "epoch =  15 batch =  125 / 977 loss =  -23.82916000911168\n",
      "epoch =  15 batch =  150 / 977 loss =  -23.83422681037954\n",
      "epoch =  15 batch =  175 / 977 loss =  -23.83293501897292\n",
      "epoch =  15 batch =  200 / 977 loss =  -23.833055600598083\n",
      "epoch =  15 batch =  225 / 977 loss =  -23.827020721097963\n",
      "epoch =  15 batch =  250 / 977 loss =  -23.823028290889177\n",
      "epoch =  15 batch =  275 / 977 loss =  -23.82405528469362\n",
      "epoch =  15 batch =  300 / 977 loss =  -23.824774783315053\n",
      "epoch =  15 batch =  325 / 977 loss =  -23.8229926056657\n",
      "epoch =  15 batch =  350 / 977 loss =  -23.822388380001737\n",
      "epoch =  15 batch =  375 / 977 loss =  -23.822021022756033\n",
      "epoch =  15 batch =  400 / 977 loss =  -23.82227455291366\n",
      "epoch =  15 batch =  425 / 977 loss =  -23.82117214561067\n",
      "epoch =  15 batch =  450 / 977 loss =  -23.823885374217223\n",
      "epoch =  15 batch =  475 / 977 loss =  -23.823915425468883\n",
      "epoch =  15 batch =  500 / 977 loss =  -23.82404528787273\n",
      "epoch =  15 batch =  525 / 977 loss =  -23.823886004690877\n",
      "epoch =  15 batch =  550 / 977 loss =  -23.824664494952348\n",
      "epoch =  15 batch =  575 / 977 loss =  -23.823231822914547\n",
      "epoch =  15 batch =  600 / 977 loss =  -23.824134740972276\n",
      "epoch =  15 batch =  625 / 977 loss =  -23.82394262624625\n",
      "epoch =  15 batch =  650 / 977 loss =  -23.82390464688959\n",
      "epoch =  15 batch =  675 / 977 loss =  -23.82234676631949\n",
      "epoch =  15 batch =  700 / 977 loss =  -23.82246896849888\n",
      "epoch =  15 batch =  725 / 977 loss =  -23.821552108470392\n",
      "epoch =  15 batch =  750 / 977 loss =  -23.82204140613621\n",
      "epoch =  15 batch =  775 / 977 loss =  -23.821796159154353\n",
      "epoch =  15 batch =  800 / 977 loss =  -23.820736893405023\n",
      "epoch =  15 batch =  825 / 977 loss =  -23.821205824974367\n",
      "epoch =  15 batch =  850 / 977 loss =  -23.82143344498128\n",
      "epoch =  15 batch =  875 / 977 loss =  -23.821409954872298\n",
      "epoch =  15 batch =  900 / 977 loss =  -23.821708446337556\n",
      "epoch =  15 batch =  925 / 977 loss =  -23.820983771371523\n",
      "epoch =  15 batch =  950 / 977 loss =  -23.820545836327323\n",
      "epoch =  15 batch =  975 / 977 loss =  -23.82023207867731\n",
      "Validation loss =  -23.82393455505371\n"
     ]
    }
   ],
   "source": [
    "data_size = train_samples.shape[0]\n",
    "n_batches = m.ceil(data_size/batch_size)\n",
    "\n",
    "data_size_validation = test_samples.shape[0]\n",
    "n_batches_validate = m.ceil(data_size_validation/batch_size)\n",
    "\n",
    "best_validation_loss = np.inf\n",
    "best_ess = 0\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    \n",
    "    permutation = torch.randperm(data_size, device=device)    \n",
    "\n",
    "    # Loop over batches\n",
    "    cum_loss = 0\n",
    "    for batch in range(n_batches):\n",
    "        # Set up the batch\n",
    "        batch_begin = batch*batch_size\n",
    "        batch_end   = min( (batch+1)*batch_size, data_size-1 )\n",
    "        indices = permutation[batch_begin:batch_end]\n",
    "        samples_batch = train_samples[indices]\n",
    "        \n",
    "        # Take a step\n",
    "        optimizer.zero_grad()\n",
    "        loss = -(flow.log_prob(inputs=samples_batch)).mean()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Compute cumulative loss\n",
    "        cum_loss = (cum_loss*batch + loss.item())/(batch+1)\n",
    "\n",
    "        if batch%25 == 0:\n",
    "            print(\"epoch = \", epoch, \"batch = \", batch, \"/\", n_batches, \"loss = \", cum_loss)\n",
    "    \n",
    "    writer.add_scalar(\"Loss_train\", cum_loss, epoch)\n",
    "    scheduler.step()\n",
    "\n",
    "\n",
    "    # ---------- Compute validation loss -----------\n",
    "    validation_loss = 0\n",
    "    for batch in range(n_batches_validate):\n",
    "        batch_begin = batch*batch_size\n",
    "        batch_end = min( (batch+1)*batch_size, data_size_validation-1 )\n",
    "        samples_batch = test_samples[batch_begin:batch_end]\n",
    "    \n",
    "        with torch.no_grad():\n",
    "            validation_loss = (validation_loss*batch - (flow.log_prob(samples_batch)).mean())/(batch+1)\n",
    "\n",
    "    print(\"Validation loss = \", validation_loss.item())\n",
    "    writer.add_scalar(\"Loss_test\", validation_loss.item(), epoch)\n",
    "\n",
    "    if validation_loss < best_validation_loss:\n",
    "        torch.save(flow, \"flow_model_unweighted_best_validation.pt\")\n",
    "        best_validation_loss = validation_loss\n",
    "\n",
    "    \n",
    "    # ---------- Compute effective sample size ----------\n",
    "    # generate samples and evaluate llhs\n",
    "    with torch.no_grad():\n",
    "        samples = flow.sample(n_sample)\n",
    "        llhs = flow.log_prob(samples)\n",
    "\n",
    "    # Store files\n",
    "    np.savetxt(\"/tmp/samples_file.csv\", samples.cpu().numpy(), delimiter=',')\n",
    "    np.savetxt(\"/tmp/llhs_file.csv\", np.exp(llhs.cpu().numpy()), delimiter=',')\n",
    "\n",
    "    # Run the evaluator\n",
    "    cmd = os.path.abspath(os.getcwd())+'/ME_VEGAS/compute_metrics_from_likelihoods /tmp/samples_file.csv /tmp/llhs_file.csv'\n",
    "    b = subprocess.run(cmd, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE).stdout\n",
    "    lines = b.decode('ascii').split(\"\\n\")\n",
    "\n",
    "    ess = float(lines[2].split(' ')[-1])\n",
    "    \n",
    "    print(\"Effective sample size = \", ess)\n",
    "    writer.add_scalar(\"Effective_sample_size\", ess, epoch)\n",
    "\n",
    "    if ess > best_ess:\n",
    "        torch.save(flow, \"flow_model_unweighted_best_ess.pt\")\n",
    "        best_ess = ess\n",
    "        \n",
    "torch.save(flow, \"flow_model_unweighted_final.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
