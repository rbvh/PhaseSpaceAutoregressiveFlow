{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math as m\n",
    "import numpy as np\n",
    "import random as r\n",
    "import matplotlib.pyplot as plt\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.optim.lr_scheduler import MultiStepLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nflows.flows.base import Flow\n",
    "from nflows.distributions.uniform import BoxUniform\n",
    "from nflows.transforms.base import CompositeTransform\n",
    "from nflows.transforms.autoregressive import MaskedPiecewiseRationalQuadraticAutoregressiveTransform\n",
    "from nflows.transforms.autoregressive import MaskedPiecewiseQuadraticAutoregressiveTransform\n",
    "from nflows.transforms.permutations import ReversePermutation\n",
    "from nflows.transforms.permutations import RandomPermutation\n",
    "from nflows.transforms.splines.rational_quadratic import rational_quadratic_spline\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import time\n",
    "import os\n",
    "from copy import deepcopy\n",
    "import math as m\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorboard writer for loss logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU/CPU selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:1\")\n",
    "#device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_RQS_knots = 10    # Number of knots in RQS transform\n",
    "n_made_layers = 1   # Number of hidden layers in every made network\n",
    "n_made_units = 100  # Number of units in every layer of the made network\n",
    "n_flow_layers = 6   # Number of layers in the flow\n",
    "\n",
    "batch_size = 1024\n",
    "n_epochs = 800\n",
    "adam_lr = 0.001     # Learning rate for the ADAM optimizer (default: 0.001)\n",
    "\n",
    "n_train = int(1e6)  # Number of training events\n",
    "n_test = int(1e5)   # Number of testing events\n",
    "n_sample = int(1e6) # Number of samples for ess evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = np.genfromtxt(\"data/unweighted_samples.csv\", delimiter=',')\n",
    "if (n_train + n_test > samples.shape[0]):\n",
    "    raise Exception(\"Not enough training data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split to a train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_samples = torch.tensor(samples[:n_train], dtype=torch.float32, device=device)\n",
    "test_samples = torch.tensor(samples[n_train:n_train+n_test], dtype=torch.float32, device=device)\n",
    "\n",
    "del samples\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_dim = train_samples.shape[1]\n",
    "base_dist = BoxUniform(torch.zeros(event_dim), torch.ones(event_dim))\n",
    "\n",
    "transforms = []\n",
    "for _ in range(n_flow_layers):\n",
    "    transforms.append(RandomPermutation(features=event_dim))\n",
    "    transforms.append(MaskedPiecewiseRationalQuadraticAutoregressiveTransform(\n",
    "        features=event_dim, \n",
    "        hidden_features=n_made_units,\n",
    "        num_bins=n_RQS_knots,\n",
    "        num_blocks=n_made_layers-1,\n",
    "        tails=\"constrained\",\n",
    "        use_residual_blocks=False\n",
    "    ))\n",
    "transform = CompositeTransform(transforms)\n",
    "\n",
    "flow = Flow(transform, base_dist).to(device)\n",
    "optimizer = optim.Adam(flow.parameters(), lr=adam_lr)\n",
    "\n",
    "scheduler = MultiStepLR(optimizer, milestones=[350, 425, 500, 575, 650, 725, 800], gamma=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch =  0 batch =  0 / 977 loss =  0.9905954599380493\n",
      "epoch =  0 batch =  25 / 977 loss =  -4.413204820110248\n",
      "epoch =  0 batch =  50 / 977 loss =  -7.775111200178371\n",
      "epoch =  0 batch =  75 / 977 loss =  -10.390722363795104\n",
      "epoch =  0 batch =  100 / 977 loss =  -12.426124167619363\n",
      "epoch =  0 batch =  125 / 977 loss =  -13.950181560620427\n",
      "epoch =  0 batch =  150 / 977 loss =  -15.001956138192421\n",
      "epoch =  0 batch =  175 / 977 loss =  -15.896110247989945\n",
      "epoch =  0 batch =  200 / 977 loss =  -16.643949314581217\n",
      "epoch =  0 batch =  225 / 977 loss =  -17.24221851169007\n",
      "epoch =  0 batch =  250 / 977 loss =  -17.744203754036544\n",
      "epoch =  0 batch =  275 / 977 loss =  -18.15789103540389\n",
      "epoch =  0 batch =  300 / 977 loss =  -18.510145437974867\n",
      "epoch =  0 batch =  325 / 977 loss =  -18.810105876962826\n",
      "epoch =  0 batch =  350 / 977 loss =  -19.075499257725525\n",
      "epoch =  0 batch =  375 / 977 loss =  -19.311095220215144\n",
      "epoch =  0 batch =  400 / 977 loss =  -19.520692932561147\n",
      "epoch =  0 batch =  425 / 977 loss =  -19.703979440907926\n",
      "epoch =  0 batch =  450 / 977 loss =  -19.870214312343542\n",
      "epoch =  0 batch =  475 / 977 loss =  -20.01344774769886\n",
      "epoch =  0 batch =  500 / 977 loss =  -20.14973345981863\n",
      "epoch =  0 batch =  525 / 977 loss =  -20.272351553401574\n",
      "epoch =  0 batch =  550 / 977 loss =  -20.383770132832872\n",
      "epoch =  0 batch =  575 / 977 loss =  -20.491005452298044\n",
      "epoch =  0 batch =  600 / 977 loss =  -20.59093007088303\n",
      "epoch =  0 batch =  625 / 977 loss =  -20.68056772173213\n",
      "epoch =  0 batch =  650 / 977 loss =  -20.763331246403506\n",
      "epoch =  0 batch =  675 / 977 loss =  -20.840883355301166\n",
      "epoch =  0 batch =  700 / 977 loss =  -20.9147837187101\n",
      "epoch =  0 batch =  725 / 977 loss =  -20.984561474978424\n",
      "epoch =  0 batch =  750 / 977 loss =  -21.050399050215745\n",
      "epoch =  0 batch =  775 / 977 loss =  -21.111395937995496\n",
      "epoch =  0 batch =  800 / 977 loss =  -21.171411868003414\n",
      "epoch =  0 batch =  825 / 977 loss =  -21.22984289383339\n",
      "epoch =  0 batch =  850 / 977 loss =  -21.28817960949117\n",
      "epoch =  0 batch =  875 / 977 loss =  -21.344732235657833\n",
      "epoch =  0 batch =  900 / 977 loss =  -21.398163031360806\n",
      "epoch =  0 batch =  925 / 977 loss =  -21.450920719918877\n",
      "epoch =  0 batch =  950 / 977 loss =  -21.503176562887628\n",
      "epoch =  0 batch =  975 / 977 loss =  -21.554575528369323\n",
      "Validation loss =  -23.491588592529297\n",
      "Effective sample size =  0.06299\n",
      "epoch =  1 batch =  0 / 977 loss =  -23.366743087768555\n",
      "epoch =  1 batch =  25 / 977 loss =  -23.542750652019794\n",
      "epoch =  1 batch =  50 / 977 loss =  -23.519904566746128\n",
      "epoch =  1 batch =  75 / 977 loss =  -23.50890784514577\n",
      "epoch =  1 batch =  100 / 977 loss =  -23.52800425916614\n",
      "epoch =  1 batch =  125 / 977 loss =  -23.528874245900944\n",
      "epoch =  1 batch =  150 / 977 loss =  -23.522748391359833\n",
      "epoch =  1 batch =  175 / 977 loss =  -23.525570620190003\n",
      "epoch =  1 batch =  200 / 977 loss =  -23.53450835877982\n",
      "epoch =  1 batch =  225 / 977 loss =  -23.537126718369198\n",
      "epoch =  1 batch =  250 / 977 loss =  -23.543430563938088\n",
      "epoch =  1 batch =  275 / 977 loss =  -23.550731299580008\n",
      "epoch =  1 batch =  300 / 977 loss =  -23.55918102327772\n",
      "epoch =  1 batch =  325 / 977 loss =  -23.559511892634678\n",
      "epoch =  1 batch =  350 / 977 loss =  -23.559236091765943\n",
      "epoch =  1 batch =  375 / 977 loss =  -23.560201441988053\n",
      "epoch =  1 batch =  400 / 977 loss =  -23.559607484394196\n",
      "epoch =  1 batch =  425 / 977 loss =  -23.563014120003444\n",
      "epoch =  1 batch =  450 / 977 loss =  -23.564736634823294\n",
      "epoch =  1 batch =  475 / 977 loss =  -23.56483500344414\n",
      "epoch =  1 batch =  500 / 977 loss =  -23.57000354759233\n",
      "epoch =  1 batch =  525 / 977 loss =  -23.572989761149486\n",
      "epoch =  1 batch =  550 / 977 loss =  -23.576713136233355\n",
      "epoch =  1 batch =  575 / 977 loss =  -23.57948329051336\n",
      "epoch =  1 batch =  600 / 977 loss =  -23.58030599127594\n",
      "epoch =  1 batch =  625 / 977 loss =  -23.58190464287902\n",
      "epoch =  1 batch =  650 / 977 loss =  -23.58338285701067\n",
      "epoch =  1 batch =  675 / 977 loss =  -23.583328749301177\n",
      "epoch =  1 batch =  700 / 977 loss =  -23.582785624070112\n",
      "epoch =  1 batch =  725 / 977 loss =  -23.586368219254766\n",
      "epoch =  1 batch =  750 / 977 loss =  -23.590034042947625\n",
      "epoch =  1 batch =  775 / 977 loss =  -23.593234138390457\n",
      "epoch =  1 batch =  800 / 977 loss =  -23.594127119257212\n",
      "epoch =  1 batch =  825 / 977 loss =  -23.597012210411833\n",
      "epoch =  1 batch =  850 / 977 loss =  -23.598676571694725\n",
      "epoch =  1 batch =  875 / 977 loss =  -23.60015318491688\n",
      "epoch =  1 batch =  900 / 977 loss =  -23.601930048833548\n",
      "epoch =  1 batch =  925 / 977 loss =  -23.60257207652148\n",
      "epoch =  1 batch =  950 / 977 loss =  -23.603573138280126\n",
      "epoch =  1 batch =  975 / 977 loss =  -23.604339200942245\n",
      "Validation loss =  -23.61977767944336\n",
      "Effective sample size =  0.0925664\n",
      "epoch =  2 batch =  0 / 977 loss =  -23.792221069335938\n",
      "epoch =  2 batch =  25 / 977 loss =  -23.676429235018215\n",
      "epoch =  2 batch =  50 / 977 loss =  -23.693726894902248\n",
      "epoch =  2 batch =  75 / 977 loss =  -23.70688639189067\n",
      "epoch =  2 batch =  100 / 977 loss =  -23.711028712810844\n",
      "epoch =  2 batch =  125 / 977 loss =  -23.704623192075687\n",
      "epoch =  2 batch =  150 / 977 loss =  -23.684081008102705\n",
      "epoch =  2 batch =  175 / 977 loss =  -23.68128809061916\n",
      "epoch =  2 batch =  200 / 977 loss =  -23.682806574883138\n",
      "epoch =  2 batch =  225 / 977 loss =  -23.683463974336597\n",
      "epoch =  2 batch =  250 / 977 loss =  -23.682147516197407\n",
      "epoch =  2 batch =  275 / 977 loss =  -23.679350127344538\n",
      "epoch =  2 batch =  300 / 977 loss =  -23.677846464999888\n",
      "epoch =  2 batch =  325 / 977 loss =  -23.674070691769835\n",
      "epoch =  2 batch =  350 / 977 loss =  -23.675781255434035\n",
      "epoch =  2 batch =  375 / 977 loss =  -23.676190645136728\n",
      "epoch =  2 batch =  400 / 977 loss =  -23.672931352458388\n",
      "epoch =  2 batch =  425 / 977 loss =  -23.671912041068634\n",
      "epoch =  2 batch =  450 / 977 loss =  -23.671348288423996\n",
      "epoch =  2 batch =  475 / 977 loss =  -23.67025094473061\n",
      "epoch =  2 batch =  500 / 977 loss =  -23.67202056001522\n",
      "epoch =  2 batch =  525 / 977 loss =  -23.671033482134565\n",
      "epoch =  2 batch =  550 / 977 loss =  -23.6707737917476\n",
      "epoch =  2 batch =  575 / 977 loss =  -23.672239449289112\n",
      "epoch =  2 batch =  600 / 977 loss =  -23.67328192826714\n",
      "epoch =  2 batch =  625 / 977 loss =  -23.673081888558386\n",
      "epoch =  2 batch =  650 / 977 loss =  -23.67465818788966\n",
      "epoch =  2 batch =  675 / 977 loss =  -23.675507483397713\n",
      "epoch =  2 batch =  700 / 977 loss =  -23.674190396078966\n",
      "epoch =  2 batch =  725 / 977 loss =  -23.67370952522129\n",
      "epoch =  2 batch =  750 / 977 loss =  -23.677211055425435\n",
      "epoch =  2 batch =  775 / 977 loss =  -23.678569877270558\n",
      "epoch =  2 batch =  800 / 977 loss =  -23.678802847415753\n",
      "epoch =  2 batch =  825 / 977 loss =  -23.680181108433153\n",
      "epoch =  2 batch =  850 / 977 loss =  -23.680889766168637\n",
      "epoch =  2 batch =  875 / 977 loss =  -23.681924915749175\n",
      "epoch =  2 batch =  900 / 977 loss =  -23.682180324219956\n",
      "epoch =  2 batch =  925 / 977 loss =  -23.682005307586856\n",
      "epoch =  2 batch =  950 / 977 loss =  -23.68152890370846\n",
      "epoch =  2 batch =  975 / 977 loss =  -23.683382816002005\n",
      "Validation loss =  -23.757770538330078\n",
      "Effective sample size =  0.101514\n",
      "epoch =  3 batch =  0 / 977 loss =  -23.756732940673828\n",
      "epoch =  3 batch =  25 / 977 loss =  -23.731450080871582\n",
      "epoch =  3 batch =  50 / 977 loss =  -23.748901404586494\n",
      "epoch =  3 batch =  75 / 977 loss =  -23.739771968440007\n",
      "epoch =  3 batch =  100 / 977 loss =  -23.723001744487494\n",
      "epoch =  3 batch =  125 / 977 loss =  -23.72140746646457\n",
      "epoch =  3 batch =  150 / 977 loss =  -23.719273573515427\n",
      "epoch =  3 batch =  175 / 977 loss =  -23.7132700031454\n",
      "epoch =  3 batch =  200 / 977 loss =  -23.715520298896152\n",
      "epoch =  3 batch =  225 / 977 loss =  -23.717673107586084\n",
      "epoch =  3 batch =  250 / 977 loss =  -23.72077168316481\n",
      "epoch =  3 batch =  275 / 977 loss =  -23.721372576727394\n",
      "epoch =  3 batch =  300 / 977 loss =  -23.71904499903075\n",
      "epoch =  3 batch =  325 / 977 loss =  -23.71917117885286\n",
      "epoch =  3 batch =  350 / 977 loss =  -23.719554183829544\n",
      "epoch =  3 batch =  375 / 977 loss =  -23.719461928022668\n",
      "epoch =  3 batch =  400 / 977 loss =  -23.71852355348202\n",
      "epoch =  3 batch =  425 / 977 loss =  -23.717947579325646\n",
      "epoch =  3 batch =  450 / 977 loss =  -23.71947867061505\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch =  3 batch =  475 / 977 loss =  -23.721113689807282\n",
      "epoch =  3 batch =  500 / 977 loss =  -23.722407670316105\n",
      "epoch =  3 batch =  525 / 977 loss =  -23.72374713738155\n",
      "epoch =  3 batch =  550 / 977 loss =  -23.724775612029756\n",
      "epoch =  3 batch =  575 / 977 loss =  -23.727274947696262\n",
      "epoch =  3 batch =  600 / 977 loss =  -23.728943756535124\n",
      "epoch =  3 batch =  625 / 977 loss =  -23.730755492140297\n",
      "epoch =  3 batch =  650 / 977 loss =  -23.72966955334358\n",
      "epoch =  3 batch =  675 / 977 loss =  -23.731213964654128\n",
      "epoch =  3 batch =  700 / 977 loss =  -23.730921365735174\n",
      "epoch =  3 batch =  725 / 977 loss =  -23.73303329057928\n",
      "epoch =  3 batch =  750 / 977 loss =  -23.733697538210752\n",
      "epoch =  3 batch =  775 / 977 loss =  -23.73369000867468\n",
      "epoch =  3 batch =  800 / 977 loss =  -23.734240756945646\n",
      "epoch =  3 batch =  825 / 977 loss =  -23.735525396776527\n",
      "epoch =  3 batch =  850 / 977 loss =  -23.735651639317496\n",
      "epoch =  3 batch =  875 / 977 loss =  -23.736875388175914\n",
      "epoch =  3 batch =  900 / 977 loss =  -23.73684266034293\n",
      "epoch =  3 batch =  925 / 977 loss =  -23.737711611885732\n",
      "epoch =  3 batch =  950 / 977 loss =  -23.738467995676693\n",
      "epoch =  3 batch =  975 / 977 loss =  -23.7370126677341\n",
      "Validation loss =  -23.737346649169922\n",
      "Effective sample size =  0.0975477\n",
      "epoch =  4 batch =  0 / 977 loss =  -23.616344451904297\n",
      "epoch =  4 batch =  25 / 977 loss =  -23.75269911839412\n",
      "epoch =  4 batch =  50 / 977 loss =  -23.751571505677465\n",
      "epoch =  4 batch =  75 / 977 loss =  -23.74064513256675\n",
      "epoch =  4 batch =  100 / 977 loss =  -23.752477230411944\n",
      "epoch =  4 batch =  125 / 977 loss =  -23.76025348239475\n",
      "epoch =  4 batch =  150 / 977 loss =  -23.749540922657538\n",
      "epoch =  4 batch =  175 / 977 loss =  -23.74586441300131\n",
      "epoch =  4 batch =  200 / 977 loss =  -23.745938305831064\n",
      "epoch =  4 batch =  225 / 977 loss =  -23.743694541728594\n",
      "epoch =  4 batch =  250 / 977 loss =  -23.747362038053833\n",
      "epoch =  4 batch =  275 / 977 loss =  -23.74957289211991\n",
      "epoch =  4 batch =  300 / 977 loss =  -23.752124437858093\n",
      "epoch =  4 batch =  325 / 977 loss =  -23.754714731789804\n",
      "epoch =  4 batch =  350 / 977 loss =  -23.754643584248686\n",
      "epoch =  4 batch =  375 / 977 loss =  -23.756636543476834\n",
      "epoch =  4 batch =  400 / 977 loss =  -23.761073538192786\n",
      "epoch =  4 batch =  425 / 977 loss =  -23.76249256939955\n",
      "epoch =  4 batch =  450 / 977 loss =  -23.764075941098504\n",
      "epoch =  4 batch =  475 / 977 loss =  -23.76293431209917\n",
      "epoch =  4 batch =  500 / 977 loss =  -23.763060042482174\n",
      "epoch =  4 batch =  525 / 977 loss =  -23.763865768229554\n",
      "epoch =  4 batch =  550 / 977 loss =  -23.764223555687767\n",
      "epoch =  4 batch =  575 / 977 loss =  -23.766344832049466\n",
      "epoch =  4 batch =  600 / 977 loss =  -23.76451217473643\n",
      "epoch =  4 batch =  625 / 977 loss =  -23.765806061010384\n",
      "epoch =  4 batch =  650 / 977 loss =  -23.767836358323805\n",
      "epoch =  4 batch =  675 / 977 loss =  -23.768321265835734\n",
      "epoch =  4 batch =  700 / 977 loss =  -23.767949241714373\n",
      "epoch =  4 batch =  725 / 977 loss =  -23.769513534777097\n",
      "epoch =  4 batch =  750 / 977 loss =  -23.768683582107812\n",
      "epoch =  4 batch =  775 / 977 loss =  -23.768653409997217\n",
      "epoch =  4 batch =  800 / 977 loss =  -23.769337467188844\n",
      "epoch =  4 batch =  825 / 977 loss =  -23.771704733804704\n",
      "epoch =  4 batch =  850 / 977 loss =  -23.771951711275886\n",
      "epoch =  4 batch =  875 / 977 loss =  -23.77296205851586\n",
      "epoch =  4 batch =  900 / 977 loss =  -23.773242090968264\n",
      "epoch =  4 batch =  925 / 977 loss =  -23.773078772213243\n",
      "epoch =  4 batch =  950 / 977 loss =  -23.773529165049336\n",
      "epoch =  4 batch =  975 / 977 loss =  -23.77432851126937\n",
      "Validation loss =  -23.79682731628418\n",
      "Effective sample size =  0.100441\n",
      "epoch =  5 batch =  0 / 977 loss =  -23.780248641967773\n",
      "epoch =  5 batch =  25 / 977 loss =  -23.770640813387356\n",
      "epoch =  5 batch =  50 / 977 loss =  -23.773828992656632\n",
      "epoch =  5 batch =  75 / 977 loss =  -23.77966634850753\n",
      "epoch =  5 batch =  100 / 977 loss =  -23.784321548915145\n",
      "epoch =  5 batch =  125 / 977 loss =  -23.781227126954093\n",
      "epoch =  5 batch =  150 / 977 loss =  -23.770325755441434\n",
      "epoch =  5 batch =  175 / 977 loss =  -23.768251061439514\n",
      "epoch =  5 batch =  200 / 977 loss =  -23.769442382736585\n",
      "epoch =  5 batch =  225 / 977 loss =  -23.768024554294822\n",
      "epoch =  5 batch =  250 / 977 loss =  -23.77107722825738\n",
      "epoch =  5 batch =  275 / 977 loss =  -23.76945308325947\n",
      "epoch =  5 batch =  300 / 977 loss =  -23.77437047229653\n",
      "epoch =  5 batch =  325 / 977 loss =  -23.77700630141183\n",
      "epoch =  5 batch =  350 / 977 loss =  -23.779266422630386\n",
      "epoch =  5 batch =  375 / 977 loss =  -23.780114975381416\n",
      "epoch =  5 batch =  400 / 977 loss =  -23.779445453177672\n",
      "epoch =  5 batch =  425 / 977 loss =  -23.782384693342763\n",
      "epoch =  5 batch =  450 / 977 loss =  -23.782289932149485\n",
      "epoch =  5 batch =  475 / 977 loss =  -23.78248590581558\n",
      "epoch =  5 batch =  500 / 977 loss =  -23.784432127566163\n",
      "epoch =  5 batch =  525 / 977 loss =  -23.78372733040002\n",
      "epoch =  5 batch =  550 / 977 loss =  -23.783364619620276\n",
      "epoch =  5 batch =  575 / 977 loss =  -23.782322827312697\n",
      "epoch =  5 batch =  600 / 977 loss =  -23.783268619099402\n",
      "epoch =  5 batch =  625 / 977 loss =  -23.783332623612772\n",
      "epoch =  5 batch =  650 / 977 loss =  -23.784223893454197\n",
      "epoch =  5 batch =  675 / 977 loss =  -23.78610632969785\n",
      "epoch =  5 batch =  700 / 977 loss =  -23.786302601899997\n",
      "epoch =  5 batch =  725 / 977 loss =  -23.7855816701884\n",
      "epoch =  5 batch =  750 / 977 loss =  -23.78561003897068\n",
      "epoch =  5 batch =  775 / 977 loss =  -23.785359424414114\n",
      "epoch =  5 batch =  800 / 977 loss =  -23.783957461144016\n",
      "epoch =  5 batch =  825 / 977 loss =  -23.784092376653582\n",
      "epoch =  5 batch =  850 / 977 loss =  -23.784100170561363\n",
      "epoch =  5 batch =  875 / 977 loss =  -23.78311440716053\n",
      "epoch =  5 batch =  900 / 977 loss =  -23.781932445530373\n",
      "epoch =  5 batch =  925 / 977 loss =  -23.78142439469407\n",
      "epoch =  5 batch =  950 / 977 loss =  -23.781679564595365\n",
      "epoch =  5 batch =  975 / 977 loss =  -23.783191491345907\n",
      "Validation loss =  -23.760578155517578\n",
      "Effective sample size =  0.101902\n",
      "epoch =  6 batch =  0 / 977 loss =  -23.765514373779297\n",
      "epoch =  6 batch =  25 / 977 loss =  -23.82348816211407\n",
      "epoch =  6 batch =  50 / 977 loss =  -23.814995298198625\n",
      "epoch =  6 batch =  75 / 977 loss =  -23.820816943519993\n",
      "epoch =  6 batch =  100 / 977 loss =  -23.817687591703805\n",
      "epoch =  6 batch =  125 / 977 loss =  -23.814252323574486\n",
      "epoch =  6 batch =  150 / 977 loss =  -23.811319894348546\n",
      "epoch =  6 batch =  175 / 977 loss =  -23.805686007846486\n",
      "epoch =  6 batch =  200 / 977 loss =  -23.811857327893005\n",
      "epoch =  6 batch =  225 / 977 loss =  -23.813099962420168\n",
      "epoch =  6 batch =  250 / 977 loss =  -23.81307092795809\n",
      "epoch =  6 batch =  275 / 977 loss =  -23.813716100609817\n",
      "epoch =  6 batch =  300 / 977 loss =  -23.815477485276535\n",
      "epoch =  6 batch =  325 / 977 loss =  -23.81102684816701\n",
      "epoch =  6 batch =  350 / 977 loss =  -23.811236346209512\n",
      "epoch =  6 batch =  375 / 977 loss =  -23.812265051172155\n",
      "epoch =  6 batch =  400 / 977 loss =  -23.81238095480904\n",
      "epoch =  6 batch =  425 / 977 loss =  -23.810544667669323\n",
      "epoch =  6 batch =  450 / 977 loss =  -23.809589136466236\n",
      "epoch =  6 batch =  475 / 977 loss =  -23.809245834831444\n",
      "epoch =  6 batch =  500 / 977 loss =  -23.80772144066361\n",
      "epoch =  6 batch =  525 / 977 loss =  -23.806575626474835\n",
      "epoch =  6 batch =  550 / 977 loss =  -23.805800830820306\n",
      "epoch =  6 batch =  575 / 977 loss =  -23.80336879359352\n",
      "epoch =  6 batch =  600 / 977 loss =  -23.80463374513954\n",
      "epoch =  6 batch =  625 / 977 loss =  -23.80511182718004\n",
      "epoch =  6 batch =  650 / 977 loss =  -23.80673291899277\n",
      "epoch =  6 batch =  675 / 977 loss =  -23.808901414363344\n",
      "epoch =  6 batch =  700 / 977 loss =  -23.810697071222368\n",
      "epoch =  6 batch =  725 / 977 loss =  -23.811243784985923\n",
      "epoch =  6 batch =  750 / 977 loss =  -23.811057178380487\n",
      "epoch =  6 batch =  775 / 977 loss =  -23.809906293436423\n",
      "epoch =  6 batch =  800 / 977 loss =  -23.810303641615736\n",
      "epoch =  6 batch =  825 / 977 loss =  -23.810362968260094\n",
      "epoch =  6 batch =  850 / 977 loss =  -23.81048651895848\n",
      "epoch =  6 batch =  875 / 977 loss =  -23.81159767821499\n",
      "epoch =  6 batch =  900 / 977 loss =  -23.81148829867652\n",
      "epoch =  6 batch =  925 / 977 loss =  -23.813012357921888\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch =  6 batch =  950 / 977 loss =  -23.81213196996133\n",
      "epoch =  6 batch =  975 / 977 loss =  -23.812834255030896\n",
      "Validation loss =  -23.824975967407227\n",
      "Effective sample size =  0.104797\n",
      "epoch =  7 batch =  0 / 977 loss =  -23.71105194091797\n",
      "epoch =  7 batch =  25 / 977 loss =  -23.81760575221135\n",
      "epoch =  7 batch =  50 / 977 loss =  -23.82224973042806\n",
      "epoch =  7 batch =  75 / 977 loss =  -23.823848322818154\n",
      "epoch =  7 batch =  100 / 977 loss =  -23.820502158438806\n",
      "epoch =  7 batch =  125 / 977 loss =  -23.812936389257036\n",
      "epoch =  7 batch =  150 / 977 loss =  -23.813388748674203\n",
      "epoch =  7 batch =  175 / 977 loss =  -23.817294445904828\n",
      "epoch =  7 batch =  200 / 977 loss =  -23.814000096487177\n",
      "epoch =  7 batch =  225 / 977 loss =  -23.818837030798996\n",
      "epoch =  7 batch =  250 / 977 loss =  -23.824326670977232\n",
      "epoch =  7 batch =  275 / 977 loss =  -23.82231182982957\n",
      "epoch =  7 batch =  300 / 977 loss =  -23.824606245934376\n",
      "epoch =  7 batch =  325 / 977 loss =  -23.827461073003676\n",
      "epoch =  7 batch =  350 / 977 loss =  -23.83024636836473\n",
      "epoch =  7 batch =  375 / 977 loss =  -23.827523972125764\n",
      "epoch =  7 batch =  400 / 977 loss =  -23.824503239848074\n",
      "epoch =  7 batch =  425 / 977 loss =  -23.824039118950356\n",
      "epoch =  7 batch =  450 / 977 loss =  -23.823593922042\n",
      "epoch =  7 batch =  475 / 977 loss =  -23.82528151984976\n",
      "epoch =  7 batch =  500 / 977 loss =  -23.82481748234488\n",
      "epoch =  7 batch =  525 / 977 loss =  -23.822415877657694\n",
      "epoch =  7 batch =  550 / 977 loss =  -23.823163068878667\n",
      "epoch =  7 batch =  575 / 977 loss =  -23.822314553790605\n",
      "epoch =  7 batch =  600 / 977 loss =  -23.823487315122353\n",
      "epoch =  7 batch =  625 / 977 loss =  -23.823791092577036\n",
      "epoch =  7 batch =  650 / 977 loss =  -23.823615582491\n",
      "epoch =  7 batch =  675 / 977 loss =  -23.8232328708355\n",
      "epoch =  7 batch =  700 / 977 loss =  -23.82221520678291\n",
      "epoch =  7 batch =  725 / 977 loss =  -23.823683922612613\n",
      "epoch =  7 batch =  750 / 977 loss =  -23.821557340863205\n",
      "epoch =  7 batch =  775 / 977 loss =  -23.823087441552527\n",
      "epoch =  7 batch =  800 / 977 loss =  -23.822623792212536\n",
      "epoch =  7 batch =  825 / 977 loss =  -23.821938124465\n",
      "epoch =  7 batch =  850 / 977 loss =  -23.82219269973269\n",
      "epoch =  7 batch =  875 / 977 loss =  -23.82236158466773\n",
      "epoch =  7 batch =  900 / 977 loss =  -23.82309828746595\n",
      "epoch =  7 batch =  925 / 977 loss =  -23.82439620757462\n",
      "epoch =  7 batch =  950 / 977 loss =  -23.825838857143317\n",
      "epoch =  7 batch =  975 / 977 loss =  -23.826878618021464\n",
      "Validation loss =  -23.84425926208496\n",
      "Effective sample size =  0.0934774\n",
      "epoch =  8 batch =  0 / 977 loss =  -23.944812774658203\n",
      "epoch =  8 batch =  25 / 977 loss =  -23.806907727168156\n",
      "epoch =  8 batch =  50 / 977 loss =  -23.80165403029498\n",
      "epoch =  8 batch =  75 / 977 loss =  -23.81005467866596\n",
      "epoch =  8 batch =  100 / 977 loss =  -23.821465917152935\n",
      "epoch =  8 batch =  125 / 977 loss =  -23.835946673438663\n",
      "epoch =  8 batch =  150 / 977 loss =  -23.82661848510338\n",
      "epoch =  8 batch =  175 / 977 loss =  -23.824224136092447\n",
      "epoch =  8 batch =  200 / 977 loss =  -23.827408766865137\n",
      "epoch =  8 batch =  225 / 977 loss =  -23.826116587208436\n",
      "epoch =  8 batch =  250 / 977 loss =  -23.832596592694166\n",
      "epoch =  8 batch =  275 / 977 loss =  -23.831306022146475\n",
      "epoch =  8 batch =  300 / 977 loss =  -23.82853120822843\n",
      "epoch =  8 batch =  325 / 977 loss =  -23.829192963114547\n",
      "epoch =  8 batch =  350 / 977 loss =  -23.831048324237184\n",
      "epoch =  8 batch =  375 / 977 loss =  -23.833213024951043\n",
      "epoch =  8 batch =  400 / 977 loss =  -23.83411631500929\n",
      "epoch =  8 batch =  425 / 977 loss =  -23.831863076474185\n",
      "epoch =  8 batch =  450 / 977 loss =  -23.830074678239168\n",
      "epoch =  8 batch =  475 / 977 loss =  -23.83317903310311\n",
      "epoch =  8 batch =  500 / 977 loss =  -23.834409881256775\n",
      "epoch =  8 batch =  525 / 977 loss =  -23.835819527223535\n",
      "epoch =  8 batch =  550 / 977 loss =  -23.835025060414836\n",
      "epoch =  8 batch =  575 / 977 loss =  -23.83376792404387\n",
      "epoch =  8 batch =  600 / 977 loss =  -23.83272994576199\n",
      "epoch =  8 batch =  625 / 977 loss =  -23.83395212679245\n",
      "epoch =  8 batch =  650 / 977 loss =  -23.833683424098513\n",
      "epoch =  8 batch =  675 / 977 loss =  -23.83228562992705\n",
      "epoch =  8 batch =  700 / 977 loss =  -23.83332195635699\n",
      "epoch =  8 batch =  725 / 977 loss =  -23.835333811021705\n",
      "epoch =  8 batch =  750 / 977 loss =  -23.836581099366697\n",
      "epoch =  8 batch =  775 / 977 loss =  -23.836046503991195\n",
      "epoch =  8 batch =  800 / 977 loss =  -23.836595087610977\n",
      "epoch =  8 batch =  825 / 977 loss =  -23.837473670737797\n",
      "epoch =  8 batch =  850 / 977 loss =  -23.837552022429666\n",
      "epoch =  8 batch =  875 / 977 loss =  -23.837703517582863\n",
      "epoch =  8 batch =  900 / 977 loss =  -23.837776931356245\n",
      "epoch =  8 batch =  925 / 977 loss =  -23.838374323257874\n",
      "epoch =  8 batch =  950 / 977 loss =  -23.83925521561776\n",
      "epoch =  8 batch =  975 / 977 loss =  -23.84000232962311\n",
      "Validation loss =  -23.74376106262207\n",
      "Effective sample size =  0.0963106\n",
      "epoch =  9 batch =  0 / 977 loss =  -23.735979080200195\n",
      "epoch =  9 batch =  25 / 977 loss =  -23.80276239835299\n",
      "epoch =  9 batch =  50 / 977 loss =  -23.82471731597302\n",
      "epoch =  9 batch =  75 / 977 loss =  -23.841811682048593\n",
      "epoch =  9 batch =  100 / 977 loss =  -23.84755315875062\n",
      "epoch =  9 batch =  125 / 977 loss =  -23.85227345663403\n",
      "epoch =  9 batch =  150 / 977 loss =  -23.851276650334036\n",
      "epoch =  9 batch =  175 / 977 loss =  -23.847973194989297\n",
      "epoch =  9 batch =  200 / 977 loss =  -23.844204252632107\n",
      "epoch =  9 batch =  225 / 977 loss =  -23.840417321804356\n",
      "epoch =  9 batch =  250 / 977 loss =  -23.850542866376294\n",
      "epoch =  9 batch =  275 / 977 loss =  -23.85007362780364\n",
      "epoch =  9 batch =  300 / 977 loss =  -23.84831022344951\n",
      "epoch =  9 batch =  325 / 977 loss =  -23.835509036947617\n",
      "epoch =  9 batch =  350 / 977 loss =  -23.835423651583852\n",
      "epoch =  9 batch =  375 / 977 loss =  -23.83532008718937\n",
      "epoch =  9 batch =  400 / 977 loss =  -23.83646870848544\n",
      "epoch =  9 batch =  425 / 977 loss =  -23.834721139898882\n",
      "epoch =  9 batch =  450 / 977 loss =  -23.835594540953373\n",
      "epoch =  9 batch =  475 / 977 loss =  -23.83595188926248\n",
      "epoch =  9 batch =  500 / 977 loss =  -23.836477580422653\n",
      "epoch =  9 batch =  525 / 977 loss =  -23.83538878915881\n",
      "epoch =  9 batch =  550 / 977 loss =  -23.83787660546831\n",
      "epoch =  9 batch =  575 / 977 loss =  -23.83982059690689\n",
      "epoch =  9 batch =  600 / 977 loss =  -23.840533115304456\n",
      "epoch =  9 batch =  625 / 977 loss =  -23.839959915453644\n",
      "epoch =  9 batch =  650 / 977 loss =  -23.841095216812633\n",
      "epoch =  9 batch =  675 / 977 loss =  -23.841558730108503\n",
      "epoch =  9 batch =  700 / 977 loss =  -23.843087959561647\n",
      "epoch =  9 batch =  725 / 977 loss =  -23.843596553014336\n",
      "epoch =  9 batch =  750 / 977 loss =  -23.84484377427997\n",
      "epoch =  9 batch =  775 / 977 loss =  -23.84518758046259\n",
      "epoch =  9 batch =  800 / 977 loss =  -23.84711442011573\n",
      "epoch =  9 batch =  825 / 977 loss =  -23.847906597590047\n",
      "epoch =  9 batch =  850 / 977 loss =  -23.848318064114746\n",
      "epoch =  9 batch =  875 / 977 loss =  -23.84897903111428\n",
      "epoch =  9 batch =  900 / 977 loss =  -23.850188719974906\n",
      "epoch =  9 batch =  925 / 977 loss =  -23.851162127748168\n",
      "epoch =  9 batch =  950 / 977 loss =  -23.850657026850467\n",
      "epoch =  9 batch =  975 / 977 loss =  -23.850879780581742\n",
      "Validation loss =  -23.85906219482422\n",
      "Effective sample size =  0.0644671\n",
      "epoch =  10 batch =  0 / 977 loss =  -23.6494083404541\n",
      "epoch =  10 batch =  25 / 977 loss =  -23.871916624215935\n",
      "epoch =  10 batch =  50 / 977 loss =  -23.88925993676279\n",
      "epoch =  10 batch =  75 / 977 loss =  -23.871181914680882\n",
      "epoch =  10 batch =  100 / 977 loss =  -23.86520304538236\n",
      "epoch =  10 batch =  125 / 977 loss =  -23.866043136233376\n",
      "epoch =  10 batch =  150 / 977 loss =  -23.86005387716736\n",
      "epoch =  10 batch =  175 / 977 loss =  -23.85288202762605\n",
      "epoch =  10 batch =  200 / 977 loss =  -23.85236370029735\n",
      "epoch =  10 batch =  225 / 977 loss =  -23.85445167744055\n",
      "epoch =  10 batch =  250 / 977 loss =  -23.85189352757428\n",
      "epoch =  10 batch =  275 / 977 loss =  -23.856375949970197\n",
      "epoch =  10 batch =  300 / 977 loss =  -23.85597721365996\n",
      "epoch =  10 batch =  325 / 977 loss =  -23.859844418391152\n",
      "epoch =  10 batch =  350 / 977 loss =  -23.86120000659912\n",
      "epoch =  10 batch =  375 / 977 loss =  -23.86131400250376\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch =  10 batch =  400 / 977 loss =  -23.86231828152095\n",
      "epoch =  10 batch =  425 / 977 loss =  -23.86060215497802\n",
      "epoch =  10 batch =  450 / 977 loss =  -23.860523930145753\n",
      "epoch =  10 batch =  475 / 977 loss =  -23.85720710193411\n",
      "epoch =  10 batch =  500 / 977 loss =  -23.855270324828872\n",
      "epoch =  10 batch =  525 / 977 loss =  -23.856818888123964\n",
      "epoch =  10 batch =  550 / 977 loss =  -23.857507972232668\n",
      "epoch =  10 batch =  575 / 977 loss =  -23.85827586717077\n",
      "epoch =  10 batch =  600 / 977 loss =  -23.859772474317516\n",
      "epoch =  10 batch =  625 / 977 loss =  -23.859161462265853\n",
      "epoch =  10 batch =  650 / 977 loss =  -23.85861321784751\n",
      "epoch =  10 batch =  675 / 977 loss =  -23.859440890995\n",
      "epoch =  10 batch =  700 / 977 loss =  -23.85810646350986\n",
      "epoch =  10 batch =  725 / 977 loss =  -23.8600591023763\n",
      "epoch =  10 batch =  750 / 977 loss =  -23.860185006010866\n",
      "epoch =  10 batch =  775 / 977 loss =  -23.8602871747361\n",
      "epoch =  10 batch =  800 / 977 loss =  -23.861002732751967\n",
      "epoch =  10 batch =  825 / 977 loss =  -23.860824270918062\n",
      "epoch =  10 batch =  850 / 977 loss =  -23.85978765969551\n",
      "epoch =  10 batch =  875 / 977 loss =  -23.860776115225875\n",
      "epoch =  10 batch =  900 / 977 loss =  -23.862058957064985\n",
      "epoch =  10 batch =  925 / 977 loss =  -23.86403395238757\n",
      "epoch =  10 batch =  950 / 977 loss =  -23.863960685288742\n",
      "epoch =  10 batch =  975 / 977 loss =  -23.86341679682497\n",
      "Validation loss =  -23.886127471923828\n",
      "Effective sample size =  0.105973\n",
      "epoch =  11 batch =  0 / 977 loss =  -23.782855987548828\n",
      "epoch =  11 batch =  25 / 977 loss =  -23.82717330639179\n",
      "epoch =  11 batch =  50 / 977 loss =  -23.826564975813323\n",
      "epoch =  11 batch =  75 / 977 loss =  -23.850962387888057\n",
      "epoch =  11 batch =  100 / 977 loss =  -23.866812262204622\n",
      "epoch =  11 batch =  125 / 977 loss =  -23.86232286786277\n",
      "epoch =  11 batch =  150 / 977 loss =  -23.863759741877885\n",
      "epoch =  11 batch =  175 / 977 loss =  -23.87006005373869\n",
      "epoch =  11 batch =  200 / 977 loss =  -23.87193620027002\n",
      "epoch =  11 batch =  225 / 977 loss =  -23.874011157888233\n",
      "epoch =  11 batch =  250 / 977 loss =  -23.874709573874917\n",
      "epoch =  11 batch =  275 / 977 loss =  -23.875336875086255\n",
      "epoch =  11 batch =  300 / 977 loss =  -23.875560082470468\n",
      "epoch =  11 batch =  325 / 977 loss =  -23.87361998060731\n",
      "epoch =  11 batch =  350 / 977 loss =  -23.87228356603205\n",
      "epoch =  11 batch =  375 / 977 loss =  -23.871846954873277\n",
      "epoch =  11 batch =  400 / 977 loss =  -23.87435381311432\n",
      "epoch =  11 batch =  425 / 977 loss =  -23.87530174165825\n",
      "epoch =  11 batch =  450 / 977 loss =  -23.873117324253943\n",
      "epoch =  11 batch =  475 / 977 loss =  -23.87124054772514\n",
      "epoch =  11 batch =  500 / 977 loss =  -23.8701696985972\n",
      "epoch =  11 batch =  525 / 977 loss =  -23.867506959139174\n",
      "epoch =  11 batch =  550 / 977 loss =  -23.86839430821137\n",
      "epoch =  11 batch =  575 / 977 loss =  -23.867216176456896\n",
      "epoch =  11 batch =  600 / 977 loss =  -23.865607387015917\n",
      "epoch =  11 batch =  625 / 977 loss =  -23.863696655907205\n",
      "epoch =  11 batch =  650 / 977 loss =  -23.864179476431815\n",
      "epoch =  11 batch =  675 / 977 loss =  -23.864337785709555\n",
      "epoch =  11 batch =  700 / 977 loss =  -23.864184642144195\n",
      "epoch =  11 batch =  725 / 977 loss =  -23.864606568307607\n",
      "epoch =  11 batch =  750 / 977 loss =  -23.863451677060812\n",
      "epoch =  11 batch =  775 / 977 loss =  -23.861728011947335\n",
      "epoch =  11 batch =  800 / 977 loss =  -23.86344247691791\n",
      "epoch =  11 batch =  825 / 977 loss =  -23.86416377975059\n",
      "epoch =  11 batch =  850 / 977 loss =  -23.86577604856392\n",
      "epoch =  11 batch =  875 / 977 loss =  -23.865486486861712\n",
      "epoch =  11 batch =  900 / 977 loss =  -23.867681636662134\n",
      "epoch =  11 batch =  925 / 977 loss =  -23.868514382298528\n",
      "epoch =  11 batch =  950 / 977 loss =  -23.86874808422776\n",
      "epoch =  11 batch =  975 / 977 loss =  -23.86863562904422\n",
      "Validation loss =  -23.828588485717773\n",
      "Effective sample size =  0.105769\n",
      "epoch =  12 batch =  0 / 977 loss =  -23.95486831665039\n",
      "epoch =  12 batch =  25 / 977 loss =  -23.90359702477088\n",
      "epoch =  12 batch =  50 / 977 loss =  -23.899300481758864\n",
      "epoch =  12 batch =  75 / 977 loss =  -23.901715956236185\n",
      "epoch =  12 batch =  100 / 977 loss =  -23.893240579284065\n",
      "epoch =  12 batch =  125 / 977 loss =  -23.88389996119908\n",
      "epoch =  12 batch =  150 / 977 loss =  -23.872210496308785\n",
      "epoch =  12 batch =  175 / 977 loss =  -23.86768809231844\n",
      "epoch =  12 batch =  200 / 977 loss =  -23.866350069567922\n",
      "epoch =  12 batch =  225 / 977 loss =  -23.869417080837007\n",
      "epoch =  12 batch =  250 / 977 loss =  -23.869767755151262\n",
      "epoch =  12 batch =  275 / 977 loss =  -23.87029167534648\n",
      "epoch =  12 batch =  300 / 977 loss =  -23.870757885549548\n",
      "epoch =  12 batch =  325 / 977 loss =  -23.870097745415613\n",
      "epoch =  12 batch =  350 / 977 loss =  -23.870644707965024\n",
      "epoch =  12 batch =  375 / 977 loss =  -23.868207008280642\n",
      "epoch =  12 batch =  400 / 977 loss =  -23.869171670547438\n",
      "epoch =  12 batch =  425 / 977 loss =  -23.87000955214522\n",
      "epoch =  12 batch =  450 / 977 loss =  -23.874126408951238\n",
      "epoch =  12 batch =  475 / 977 loss =  -23.87619438892652\n",
      "epoch =  12 batch =  500 / 977 loss =  -23.877748953844012\n",
      "epoch =  12 batch =  525 / 977 loss =  -23.880013774103077\n",
      "epoch =  12 batch =  550 / 977 loss =  -23.880215615412713\n",
      "epoch =  12 batch =  575 / 977 loss =  -23.880901638004516\n",
      "epoch =  12 batch =  600 / 977 loss =  -23.879581270519388\n",
      "epoch =  12 batch =  625 / 977 loss =  -23.878823191974867\n",
      "epoch =  12 batch =  650 / 977 loss =  -23.877325626379147\n",
      "epoch =  12 batch =  675 / 977 loss =  -23.875493292272434\n",
      "epoch =  12 batch =  700 / 977 loss =  -23.875685644217793\n",
      "epoch =  12 batch =  725 / 977 loss =  -23.876426310578644\n",
      "epoch =  12 batch =  750 / 977 loss =  -23.87818590715308\n",
      "epoch =  12 batch =  775 / 977 loss =  -23.877864604143742\n",
      "epoch =  12 batch =  800 / 977 loss =  -23.878490988532544\n",
      "epoch =  12 batch =  825 / 977 loss =  -23.877963276232695\n",
      "epoch =  12 batch =  850 / 977 loss =  -23.878267882153224\n",
      "epoch =  12 batch =  875 / 977 loss =  -23.877042069282698\n",
      "epoch =  12 batch =  900 / 977 loss =  -23.878071707705406\n",
      "epoch =  12 batch =  925 / 977 loss =  -23.877308235827577\n",
      "epoch =  12 batch =  950 / 977 loss =  -23.87751612979154\n",
      "epoch =  12 batch =  975 / 977 loss =  -23.87813749665119\n",
      "Validation loss =  -23.875146865844727\n"
     ]
    }
   ],
   "source": [
    "data_size = train_samples.shape[0]\n",
    "n_batches = m.ceil(data_size/batch_size)\n",
    "\n",
    "data_size_validation = test_samples.shape[0]\n",
    "n_batches_validate = m.ceil(data_size_validation/batch_size)\n",
    "\n",
    "best_validation_loss = np.inf\n",
    "best_ess = 0\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    \n",
    "    permutation = torch.randperm(data_size, device=device)    \n",
    "\n",
    "    # Loop over batches\n",
    "    cum_loss = 0\n",
    "    for batch in range(n_batches):\n",
    "        # Set up the batch\n",
    "        batch_begin = batch*batch_size\n",
    "        batch_end   = min( (batch+1)*batch_size, data_size-1 )\n",
    "        indices = permutation[batch_begin:batch_end]\n",
    "        samples_batch = train_samples[indices]\n",
    "        \n",
    "        # Take a step\n",
    "        optimizer.zero_grad()\n",
    "        loss = -(flow.log_prob(inputs=samples_batch)).mean()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Compute cumulative loss\n",
    "        cum_loss = (cum_loss*batch + loss.item())/(batch+1)\n",
    "\n",
    "        if batch%25 == 0:\n",
    "            print(\"epoch = \", epoch, \"batch = \", batch, \"/\", n_batches, \"loss = \", cum_loss)\n",
    "    \n",
    "    writer.add_scalar(\"Loss_train\", cum_loss, epoch)\n",
    "    scheduler.step()\n",
    "\n",
    "\n",
    "    # ---------- Compute validation loss -----------\n",
    "    validation_loss = 0\n",
    "    for batch in range(n_batches_validate):\n",
    "        batch_begin = batch*batch_size\n",
    "        batch_end = min( (batch+1)*batch_size, data_size_validation-1 )\n",
    "        samples_batch = test_samples[batch_begin:batch_end]\n",
    "    \n",
    "        with torch.no_grad():\n",
    "            validation_loss = (validation_loss*batch - (flow.log_prob(samples_batch)).mean())/(batch+1)\n",
    "\n",
    "    print(\"Validation loss = \", validation_loss.item())\n",
    "    writer.add_scalar(\"Loss_test\", validation_loss.item(), epoch)\n",
    "\n",
    "    if validation_loss < best_validation_loss:\n",
    "        torch.save(flow, \"flow_model_unweighted_best_validation.pt\")\n",
    "        best_validation_loss = validation_loss\n",
    "\n",
    "    \n",
    "    # ---------- Compute effective sample size ----------\n",
    "    # generate samples and evaluate llhs\n",
    "    samples = None\n",
    "    llhs = None\n",
    "    with torch.no_grad():\n",
    "        for i in range(10):\n",
    "            s = flow.sample(int(n_sample/10))\n",
    "            l = flow.log_prob(s)\n",
    "            if samples is None:\n",
    "                samples, llhs = s.cpu().numpy(), l.cpu().numpy()\n",
    "            else:\n",
    "                samples = np.vstack((samples, s.cpu().numpy()))\n",
    "                llhs = np.vstack((llhs, l.cpu().numpy()))\n",
    "\n",
    "    # Store files\n",
    "    np.savetxt(\"/tmp/samples_file.csv\", samples, delimiter=',')\n",
    "    np.savetxt(\"/tmp/llhs_file.csv\", np.exp(llhs), delimiter=',')\n",
    "\n",
    "    # Run the evaluator\n",
    "    cmd = os.path.abspath(os.getcwd())+'/ME_VEGAS/compute_metrics_from_likelihoods /tmp/samples_file.csv /tmp/llhs_file.csv'\n",
    "    b = subprocess.run(cmd, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE).stdout\n",
    "    lines = b.decode('ascii').split(\"\\n\")\n",
    "\n",
    "    ess = float(lines[2].split(' ')[-1])\n",
    "    \n",
    "    print(\"Effective sample size = \", ess)\n",
    "    writer.add_scalar(\"Effective_sample_size\", ess, epoch)\n",
    "\n",
    "    if ess > best_ess:\n",
    "        torch.save(flow, \"flow_model_unweighted_best_ess.pt\")\n",
    "        best_ess = ess\n",
    "        \n",
    "torch.save(flow, \"flow_model_unweighted_final.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
