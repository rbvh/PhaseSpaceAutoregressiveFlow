{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math as m\n",
    "import numpy as np\n",
    "import random as r\n",
    "import matplotlib.pyplot as plt\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.optim.lr_scheduler import MultiStepLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nflows.flows.base import Flow\n",
    "from nflows.distributions.uniform import BoxUniform\n",
    "from nflows.transforms.base import CompositeTransform\n",
    "from nflows.transforms.autoregressive import MaskedPiecewiseRationalQuadraticAutoregressiveTransform\n",
    "from nflows.transforms.autoregressive import MaskedPiecewiseQuadraticAutoregressiveTransform\n",
    "from nflows.transforms.permutations import ReversePermutation\n",
    "from nflows.transforms.permutations import RandomPermutation\n",
    "from nflows.transforms.splines.rational_quadratic import rational_quadratic_spline\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import time\n",
    "import os\n",
    "from copy import deepcopy\n",
    "import math as m\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorboard writer for loss logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU/CPU selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "#device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_RQS_knots = 10   # Number of knots in RQS transform\n",
    "n_made_layers = 3  # Number of hidden layers in every made network\n",
    "n_made_units = 500 # Number of units in every layer of the made network\n",
    "n_flow_layers = 12 # Number of layers in the flow\n",
    "\n",
    "batch_size = 1024\n",
    "n_epochs = 800\n",
    "adam_lr = 0.001   # Learning rate for the ADAM optimizer (default: 0.001)\n",
    "\n",
    "n_train = int(1e6) # This is missing the required statistical factor to account for negative weights\n",
    "n_test = int(1e5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = np.genfromtxt(\"data/negative_weight_samples.csv\", delimiter=',')\n",
    "weights = np.genfromtxt(\"data/negative_weight_weights.csv\", delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the fraction of negative events and the required statistical factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraction of negative events 0.2394467380986031\n",
      "Statistical factor 3.6825358174692755\n"
     ]
    }
   ],
   "source": [
    "f = np.sum(weights < 0)/len(weights)\n",
    "c = (1-2*f)**-2\n",
    "print(\"Fraction of negative events\", f)\n",
    "print(\"Statistical factor\", c)\n",
    "if (n_train + n_test)*c > samples.shape[0]:\n",
    "    raise Exception(\"Not enough training data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalise weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = np.sign(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split to a train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_train_with_stats = int(n_train*c)\n",
    "n_test_with_stats = int(n_test*c)\n",
    "\n",
    "train_samples = torch.tensor(samples[:n_train_with_stats], dtype=torch.float32, device=device)\n",
    "train_weights = torch.tensor(weights[:n_train_with_stats], dtype=torch.float32, device=device)\n",
    "test_samples = torch.tensor(samples[n_train_with_stats:n_train_with_stats+n_test_with_stats], dtype=torch.float32, device=device)\n",
    "test_weights = torch.tensor(weights[n_train_with_stats:n_train_with_stats+n_test_with_stats], dtype=torch.float32, device=device)\n",
    "\n",
    "del samples\n",
    "del weights\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_dim = train_samples.shape[1]\n",
    "base_dist = BoxUniform(torch.zeros(event_dim), torch.ones(event_dim))\n",
    "\n",
    "transforms = []\n",
    "for _ in range(n_flow_layers):\n",
    "    transforms.append(RandomPermutation(features=event_dim))\n",
    "    transforms.append(MaskedPiecewiseRationalQuadraticAutoregressiveTransform(\n",
    "        features=event_dim, \n",
    "        hidden_features=n_made_units,\n",
    "        num_bins=n_RQS_knots,\n",
    "        num_blocks=n_made_layers-1,\n",
    "        tails=\"constrained\",\n",
    "        use_residual_blocks=False\n",
    "    ))\n",
    "transform = CompositeTransform(transforms)\n",
    "\n",
    "flow = Flow(transform, base_dist).to(device)\n",
    "optimizer = optim.Adam(flow.parameters(), lr=adam_lr)\n",
    "\n",
    "scheduler = MultiStepLR(optimizer, milestones=[350, 425, 500, 575, 650, 725, 800], gamma=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch =  0 batch =  0 / 3597 loss =  17.9576358795166\n",
      "epoch =  0 batch =  25 / 3597 loss =  0.5931739480449599\n",
      "epoch =  0 batch =  50 / 3597 loss =  -2.5938962186668437\n",
      "epoch =  0 batch =  75 / 3597 loss =  -4.261602783085485\n",
      "epoch =  0 batch =  100 / 3597 loss =  -5.302870060105135\n",
      "epoch =  0 batch =  125 / 3597 loss =  -6.050047131876151\n",
      "epoch =  0 batch =  150 / 3597 loss =  -6.653813500376726\n",
      "epoch =  0 batch =  175 / 3597 loss =  -7.145457922819663\n",
      "epoch =  0 batch =  200 / 3597 loss =  -7.599675016690843\n",
      "epoch =  0 batch =  225 / 3597 loss =  -7.969954705409772\n",
      "epoch =  0 batch =  250 / 3597 loss =  -8.289210155725007\n",
      "epoch =  0 batch =  275 / 3597 loss =  -8.554372438108146\n",
      "epoch =  0 batch =  300 / 3597 loss =  -8.79812773799778\n",
      "epoch =  0 batch =  325 / 3597 loss =  -9.013570887590847\n",
      "epoch =  0 batch =  350 / 3597 loss =  -9.203197745218917\n",
      "epoch =  0 batch =  375 / 3597 loss =  -9.354217412346545\n",
      "epoch =  0 batch =  400 / 3597 loss =  -9.499882419544862\n",
      "epoch =  0 batch =  425 / 3597 loss =  -9.648285406611055\n",
      "epoch =  0 batch =  450 / 3597 loss =  -9.78131883771483\n",
      "epoch =  0 batch =  475 / 3597 loss =  -9.889053687108916\n",
      "epoch =  0 batch =  500 / 3597 loss =  -9.994824323617294\n",
      "epoch =  0 batch =  525 / 3597 loss =  -10.093255079092861\n",
      "epoch =  0 batch =  550 / 3597 loss =  -10.181765940385159\n",
      "epoch =  0 batch =  575 / 3597 loss =  -10.255829747999085\n",
      "epoch =  0 batch =  600 / 3597 loss =  -10.3387317005142\n",
      "epoch =  0 batch =  625 / 3597 loss =  -10.421136418684789\n",
      "epoch =  0 batch =  650 / 3597 loss =  -10.491390094801938\n",
      "epoch =  0 batch =  675 / 3597 loss =  -10.570303002603831\n",
      "epoch =  0 batch =  700 / 3597 loss =  -10.637973023400493\n",
      "epoch =  0 batch =  725 / 3597 loss =  -10.70416821315679\n",
      "epoch =  0 batch =  750 / 3597 loss =  -10.767696606513665\n",
      "epoch =  0 batch =  775 / 3597 loss =  -10.81930202416615\n",
      "epoch =  0 batch =  800 / 3597 loss =  -10.879803104960965\n",
      "epoch =  0 batch =  825 / 3597 loss =  -10.930008230013797\n",
      "epoch =  0 batch =  850 / 3597 loss =  -10.982039086144205\n",
      "epoch =  0 batch =  875 / 3597 loss =  -11.03411098799273\n",
      "epoch =  0 batch =  900 / 3597 loss =  -11.082070150481876\n",
      "epoch =  0 batch =  925 / 3597 loss =  -11.1339521963093\n",
      "epoch =  0 batch =  950 / 3597 loss =  -11.171655199520847\n",
      "epoch =  0 batch =  975 / 3597 loss =  -11.2169968465221\n",
      "epoch =  0 batch =  1000 / 3597 loss =  -11.258431834670215\n",
      "epoch =  0 batch =  1025 / 3597 loss =  -11.300797568325528\n",
      "epoch =  0 batch =  1050 / 3597 loss =  -11.332674811288477\n",
      "epoch =  0 batch =  1075 / 3597 loss =  -11.371052595665578\n",
      "epoch =  0 batch =  1100 / 3597 loss =  -11.408878572319013\n",
      "epoch =  0 batch =  1125 / 3597 loss =  -11.446463445059255\n",
      "epoch =  0 batch =  1150 / 3597 loss =  -11.481241589844181\n",
      "epoch =  0 batch =  1175 / 3597 loss =  -11.515559266935915\n",
      "epoch =  0 batch =  1200 / 3597 loss =  -11.544871647801136\n",
      "epoch =  0 batch =  1225 / 3597 loss =  -11.574148286140092\n",
      "epoch =  0 batch =  1250 / 3597 loss =  -11.60245224298668\n",
      "epoch =  0 batch =  1275 / 3597 loss =  -11.633373721558202\n",
      "epoch =  0 batch =  1300 / 3597 loss =  -11.65929208244617\n",
      "epoch =  0 batch =  1325 / 3597 loss =  -11.684590534488283\n",
      "epoch =  0 batch =  1350 / 3597 loss =  -11.707498652693703\n",
      "epoch =  0 batch =  1375 / 3597 loss =  -11.731144058074113\n",
      "epoch =  0 batch =  1400 / 3597 loss =  -11.755856174228454\n",
      "epoch =  0 batch =  1425 / 3597 loss =  -11.775099957568203\n",
      "epoch =  0 batch =  1450 / 3597 loss =  -11.799328164436918\n",
      "epoch =  0 batch =  1475 / 3597 loss =  -11.819560892789108\n",
      "epoch =  0 batch =  1500 / 3597 loss =  -11.841957617657814\n",
      "epoch =  0 batch =  1525 / 3597 loss =  -11.859356211422707\n",
      "epoch =  0 batch =  1550 / 3597 loss =  -11.882622696608214\n",
      "epoch =  0 batch =  1575 / 3597 loss =  -11.903548481434512\n",
      "epoch =  0 batch =  1600 / 3597 loss =  -11.922152170095874\n",
      "epoch =  0 batch =  1625 / 3597 loss =  -11.941564298286433\n",
      "epoch =  0 batch =  1650 / 3597 loss =  -11.960960991170683\n",
      "epoch =  0 batch =  1675 / 3597 loss =  -11.978810236329187\n",
      "epoch =  0 batch =  1700 / 3597 loss =  -11.997672470587625\n",
      "epoch =  0 batch =  1725 / 3597 loss =  -12.01578972369502\n",
      "epoch =  0 batch =  1750 / 3597 loss =  -12.028600441063224\n",
      "epoch =  0 batch =  1775 / 3597 loss =  -12.044522004025817\n",
      "epoch =  0 batch =  1800 / 3597 loss =  -12.062631282398998\n",
      "epoch =  0 batch =  1825 / 3597 loss =  -12.07645699431608\n",
      "epoch =  0 batch =  1850 / 3597 loss =  -12.092449037216282\n",
      "epoch =  0 batch =  1875 / 3597 loss =  -12.110223834647112\n",
      "epoch =  0 batch =  1900 / 3597 loss =  -12.125699758600215\n",
      "epoch =  0 batch =  1925 / 3597 loss =  -12.142033247631105\n",
      "epoch =  0 batch =  1950 / 3597 loss =  -12.155944008336261\n",
      "epoch =  0 batch =  1975 / 3597 loss =  -12.17275309460879\n",
      "epoch =  0 batch =  2000 / 3597 loss =  -12.184312248940413\n",
      "epoch =  0 batch =  2025 / 3597 loss =  -12.201377454839893\n",
      "epoch =  0 batch =  2050 / 3597 loss =  -12.213329226323483\n",
      "epoch =  0 batch =  2075 / 3597 loss =  -12.224014616146084\n",
      "epoch =  0 batch =  2100 / 3597 loss =  -12.240357290451612\n",
      "epoch =  0 batch =  2125 / 3597 loss =  -12.254328603865906\n",
      "epoch =  0 batch =  2150 / 3597 loss =  -12.266965734804861\n",
      "epoch =  0 batch =  2175 / 3597 loss =  -12.278295286828381\n",
      "epoch =  0 batch =  2200 / 3597 loss =  -12.289522998126353\n",
      "epoch =  0 batch =  2225 / 3597 loss =  -12.300689570404932\n",
      "epoch =  0 batch =  2250 / 3597 loss =  -12.312773444774626\n",
      "epoch =  0 batch =  2275 / 3597 loss =  -12.325373181094449\n",
      "epoch =  0 batch =  2300 / 3597 loss =  -12.337056988020505\n",
      "epoch =  0 batch =  2325 / 3597 loss =  -12.352957668079195\n",
      "epoch =  0 batch =  2350 / 3597 loss =  -12.364395910256825\n",
      "epoch =  0 batch =  2375 / 3597 loss =  -12.378373605992506\n",
      "epoch =  0 batch =  2400 / 3597 loss =  -12.39156263181067\n",
      "epoch =  0 batch =  2425 / 3597 loss =  -12.404031538861354\n",
      "epoch =  0 batch =  2450 / 3597 loss =  -12.416501169306116\n",
      "epoch =  0 batch =  2475 / 3597 loss =  -12.423927343292508\n",
      "epoch =  0 batch =  2500 / 3597 loss =  -12.434084380503558\n",
      "epoch =  0 batch =  2525 / 3597 loss =  -12.445485829321855\n",
      "epoch =  0 batch =  2550 / 3597 loss =  -12.456194847302315\n",
      "epoch =  0 batch =  2575 / 3597 loss =  -12.465440139966951\n",
      "epoch =  0 batch =  2600 / 3597 loss =  -12.4765901528485\n",
      "epoch =  0 batch =  2625 / 3597 loss =  -12.49048260374665\n",
      "epoch =  0 batch =  2650 / 3597 loss =  -12.503107557613541\n",
      "epoch =  0 batch =  2675 / 3597 loss =  -12.514566849126446\n",
      "epoch =  0 batch =  2700 / 3597 loss =  -12.524361760786878\n",
      "epoch =  0 batch =  2725 / 3597 loss =  -12.533570246192907\n",
      "epoch =  0 batch =  2750 / 3597 loss =  -12.544097941605788\n",
      "epoch =  0 batch =  2775 / 3597 loss =  -12.554923811251081\n",
      "epoch =  0 batch =  2800 / 3597 loss =  -12.565557992578567\n",
      "epoch =  0 batch =  2825 / 3597 loss =  -12.576279836902565\n",
      "epoch =  0 batch =  2850 / 3597 loss =  -12.585550562414895\n",
      "epoch =  0 batch =  2875 / 3597 loss =  -12.596123224137258\n",
      "epoch =  0 batch =  2900 / 3597 loss =  -12.605741961054324\n",
      "epoch =  0 batch =  2925 / 3597 loss =  -12.617439056824955\n",
      "epoch =  0 batch =  2950 / 3597 loss =  -12.626814143818656\n",
      "epoch =  0 batch =  2975 / 3597 loss =  -12.635506254976347\n",
      "epoch =  0 batch =  3000 / 3597 loss =  -12.646121127059834\n",
      "epoch =  0 batch =  3025 / 3597 loss =  -12.655057913373215\n",
      "epoch =  0 batch =  3050 / 3597 loss =  -12.664714174914728\n",
      "epoch =  0 batch =  3075 / 3597 loss =  -12.673105208520493\n",
      "epoch =  0 batch =  3100 / 3597 loss =  -12.68088878885329\n",
      "epoch =  0 batch =  3125 / 3597 loss =  -12.689601224242338\n",
      "epoch =  0 batch =  3150 / 3597 loss =  -12.698594564224978\n",
      "epoch =  0 batch =  3175 / 3597 loss =  -12.708315355919051\n",
      "epoch =  0 batch =  3200 / 3597 loss =  -12.718470261161933\n",
      "epoch =  0 batch =  3225 / 3597 loss =  -12.72940141339979\n",
      "epoch =  0 batch =  3250 / 3597 loss =  -12.736933252882745\n",
      "epoch =  0 batch =  3275 / 3597 loss =  -12.744601345146853\n",
      "epoch =  0 batch =  3300 / 3597 loss =  -12.756331029465718\n",
      "epoch =  0 batch =  3325 / 3597 loss =  -12.764534794242168\n",
      "epoch =  0 batch =  3350 / 3597 loss =  -12.770821739513986\n",
      "epoch =  0 batch =  3375 / 3597 loss =  -12.777693716804734\n",
      "epoch =  0 batch =  3400 / 3597 loss =  -12.787417843324471\n",
      "epoch =  0 batch =  3425 / 3597 loss =  -12.796120337663474\n",
      "epoch =  0 batch =  3450 / 3597 loss =  -12.803277705142161\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch =  0 batch =  3475 / 3597 loss =  -12.81066526694199\n",
      "epoch =  0 batch =  3500 / 3597 loss =  -12.818650589678596\n",
      "epoch =  0 batch =  3525 / 3597 loss =  -12.82636924849963\n",
      "epoch =  0 batch =  3550 / 3597 loss =  -12.832992517962412\n",
      "epoch =  0 batch =  3575 / 3597 loss =  -12.841424104855525\n",
      "Validation loss =  -13.9771146774292\n",
      "epoch =  1 batch =  0 / 3597 loss =  -14.246454238891602\n",
      "epoch =  1 batch =  25 / 3597 loss =  -14.041108791644756\n",
      "epoch =  1 batch =  50 / 3597 loss =  -14.156505079830394\n",
      "epoch =  1 batch =  75 / 3597 loss =  -14.05435713968779\n",
      "epoch =  1 batch =  100 / 3597 loss =  -14.039949709826177\n",
      "epoch =  1 batch =  125 / 3597 loss =  -14.093002849155003\n",
      "epoch =  1 batch =  150 / 3597 loss =  -14.119642983998684\n",
      "epoch =  1 batch =  175 / 3597 loss =  -14.119377212090926\n",
      "epoch =  1 batch =  200 / 3597 loss =  -14.094803079443784\n",
      "epoch =  1 batch =  225 / 3597 loss =  -14.081807191393017\n",
      "epoch =  1 batch =  250 / 3597 loss =  -14.0563746676502\n",
      "epoch =  1 batch =  275 / 3597 loss =  -14.032986043156058\n",
      "epoch =  1 batch =  300 / 3597 loss =  -14.030655826048987\n",
      "epoch =  1 batch =  325 / 3597 loss =  -14.031450429577031\n",
      "epoch =  1 batch =  350 / 3597 loss =  -14.03436245605816\n",
      "epoch =  1 batch =  375 / 3597 loss =  -14.022044945270453\n",
      "epoch =  1 batch =  400 / 3597 loss =  -14.012598213709497\n",
      "epoch =  1 batch =  425 / 3597 loss =  -14.013076827\n",
      "epoch =  1 batch =  450 / 3597 loss =  -14.01595470276217\n",
      "epoch =  1 batch =  475 / 3597 loss =  -14.026279203030239\n",
      "epoch =  1 batch =  500 / 3597 loss =  -14.028836438755786\n",
      "epoch =  1 batch =  525 / 3597 loss =  -14.033324480963294\n",
      "epoch =  1 batch =  550 / 3597 loss =  -14.029311465697797\n",
      "epoch =  1 batch =  575 / 3597 loss =  -14.039209332731033\n",
      "epoch =  1 batch =  600 / 3597 loss =  -14.047035528300407\n",
      "epoch =  1 batch =  625 / 3597 loss =  -14.051015655834455\n",
      "epoch =  1 batch =  650 / 3597 loss =  -14.058412866841447\n",
      "epoch =  1 batch =  675 / 3597 loss =  -14.064103805101835\n",
      "epoch =  1 batch =  700 / 3597 loss =  -14.072409439359003\n",
      "epoch =  1 batch =  725 / 3597 loss =  -14.079655703762674\n",
      "epoch =  1 batch =  750 / 3597 loss =  -14.09221659963839\n",
      "epoch =  1 batch =  775 / 3597 loss =  -14.083301578600382\n",
      "epoch =  1 batch =  800 / 3597 loss =  -14.090364127569877\n",
      "epoch =  1 batch =  825 / 3597 loss =  -14.10165097580695\n",
      "epoch =  1 batch =  850 / 3597 loss =  -14.10618813869956\n",
      "epoch =  1 batch =  875 / 3597 loss =  -14.112831228944264\n",
      "epoch =  1 batch =  900 / 3597 loss =  -14.111942289142842\n",
      "epoch =  1 batch =  925 / 3597 loss =  -14.11701877585755\n",
      "epoch =  1 batch =  950 / 3597 loss =  -14.124563367584903\n",
      "epoch =  1 batch =  975 / 3597 loss =  -14.127058777652802\n",
      "epoch =  1 batch =  1000 / 3597 loss =  -14.13608386299827\n",
      "epoch =  1 batch =  1025 / 3597 loss =  -14.139196653347499\n",
      "epoch =  1 batch =  1050 / 3597 loss =  -14.144660544100542\n",
      "epoch =  1 batch =  1075 / 3597 loss =  -14.147908825856602\n",
      "epoch =  1 batch =  1100 / 3597 loss =  -14.147868000519049\n",
      "epoch =  1 batch =  1125 / 3597 loss =  -14.148904459091098\n",
      "epoch =  1 batch =  1150 / 3597 loss =  -14.149963572789643\n",
      "epoch =  1 batch =  1175 / 3597 loss =  -14.150091022050294\n",
      "epoch =  1 batch =  1200 / 3597 loss =  -14.150130543482486\n",
      "epoch =  1 batch =  1225 / 3597 loss =  -14.157918511557146\n",
      "epoch =  1 batch =  1250 / 3597 loss =  -14.16144636857042\n",
      "epoch =  1 batch =  1275 / 3597 loss =  -14.159714347516475\n",
      "epoch =  1 batch =  1300 / 3597 loss =  -14.161652082667539\n",
      "epoch =  1 batch =  1325 / 3597 loss =  -14.166349924527676\n",
      "epoch =  1 batch =  1350 / 3597 loss =  -14.173669308931357\n",
      "epoch =  1 batch =  1375 / 3597 loss =  -14.18020270037096\n",
      "epoch =  1 batch =  1400 / 3597 loss =  -14.180246605692714\n",
      "epoch =  1 batch =  1425 / 3597 loss =  -14.178867566802888\n",
      "epoch =  1 batch =  1450 / 3597 loss =  -14.183325817468324\n",
      "epoch =  1 batch =  1475 / 3597 loss =  -14.18718519895703\n",
      "epoch =  1 batch =  1500 / 3597 loss =  -14.18896033460501\n",
      "epoch =  1 batch =  1525 / 3597 loss =  -14.185904407251236\n",
      "epoch =  1 batch =  1550 / 3597 loss =  -14.19059584203802\n",
      "epoch =  1 batch =  1575 / 3597 loss =  -14.188289506181238\n",
      "epoch =  1 batch =  1600 / 3597 loss =  -14.19526902531773\n",
      "epoch =  1 batch =  1625 / 3597 loss =  -14.199652329288867\n",
      "epoch =  1 batch =  1650 / 3597 loss =  -14.202449215173283\n",
      "epoch =  1 batch =  1675 / 3597 loss =  -14.208422693830682\n",
      "epoch =  1 batch =  1700 / 3597 loss =  -14.213222686996321\n",
      "epoch =  1 batch =  1725 / 3597 loss =  -14.217271144530999\n",
      "epoch =  1 batch =  1750 / 3597 loss =  -14.220231654778807\n",
      "epoch =  1 batch =  1775 / 3597 loss =  -14.222742248225853\n",
      "epoch =  1 batch =  1800 / 3597 loss =  -14.217127350950687\n",
      "epoch =  1 batch =  1825 / 3597 loss =  -14.216482140540029\n",
      "epoch =  1 batch =  1850 / 3597 loss =  -14.216299104407176\n",
      "epoch =  1 batch =  1875 / 3597 loss =  -14.216795634105003\n",
      "epoch =  1 batch =  1900 / 3597 loss =  -14.222118799088188\n",
      "epoch =  1 batch =  1925 / 3597 loss =  -14.22185598850745\n",
      "epoch =  1 batch =  1950 / 3597 loss =  -14.224740329979014\n",
      "epoch =  1 batch =  1975 / 3597 loss =  -14.225120720110437\n",
      "epoch =  1 batch =  2000 / 3597 loss =  -14.228809806122173\n",
      "epoch =  1 batch =  2025 / 3597 loss =  -14.230245347319558\n",
      "epoch =  1 batch =  2050 / 3597 loss =  -14.231619931150792\n",
      "epoch =  1 batch =  2075 / 3597 loss =  -14.233357643116413\n",
      "epoch =  1 batch =  2100 / 3597 loss =  -14.236807041994334\n",
      "epoch =  1 batch =  2125 / 3597 loss =  -14.240257757963821\n",
      "epoch =  1 batch =  2150 / 3597 loss =  -14.242260742719532\n",
      "epoch =  1 batch =  2175 / 3597 loss =  -14.245964863721056\n",
      "epoch =  1 batch =  2200 / 3597 loss =  -14.250743158401976\n",
      "epoch =  1 batch =  2225 / 3597 loss =  -14.252705995177534\n",
      "epoch =  1 batch =  2250 / 3597 loss =  -14.255484722922079\n",
      "epoch =  1 batch =  2275 / 3597 loss =  -14.25527075011617\n",
      "epoch =  1 batch =  2300 / 3597 loss =  -14.256712062210687\n",
      "epoch =  1 batch =  2325 / 3597 loss =  -14.262428115178876\n",
      "epoch =  1 batch =  2350 / 3597 loss =  -14.263552928569215\n",
      "epoch =  1 batch =  2375 / 3597 loss =  -14.264706823560926\n",
      "epoch =  1 batch =  2400 / 3597 loss =  -14.267208161328247\n",
      "epoch =  1 batch =  2425 / 3597 loss =  -14.269112505602227\n",
      "epoch =  1 batch =  2450 / 3597 loss =  -14.272457965195592\n",
      "epoch =  1 batch =  2475 / 3597 loss =  -14.273986292963844\n",
      "epoch =  1 batch =  2500 / 3597 loss =  -14.276244125381464\n",
      "epoch =  1 batch =  2525 / 3597 loss =  -14.28051641793451\n",
      "epoch =  1 batch =  2550 / 3597 loss =  -14.282462810918613\n",
      "epoch =  1 batch =  2575 / 3597 loss =  -14.286843013319169\n",
      "epoch =  1 batch =  2600 / 3597 loss =  -14.28759756018592\n",
      "epoch =  1 batch =  2625 / 3597 loss =  -14.288122206903648\n",
      "epoch =  1 batch =  2650 / 3597 loss =  -14.29049760609112\n",
      "epoch =  1 batch =  2675 / 3597 loss =  -14.292094298364157\n",
      "epoch =  1 batch =  2700 / 3597 loss =  -14.294559662362374\n",
      "epoch =  1 batch =  2725 / 3597 loss =  -14.297914713861656\n",
      "epoch =  1 batch =  2750 / 3597 loss =  -14.29919261266777\n",
      "epoch =  1 batch =  2775 / 3597 loss =  -14.300932146973844\n",
      "epoch =  1 batch =  2800 / 3597 loss =  -14.302570069274575\n",
      "epoch =  1 batch =  2825 / 3597 loss =  -14.303931657085162\n",
      "epoch =  1 batch =  2850 / 3597 loss =  -14.305078959055258\n",
      "epoch =  1 batch =  2875 / 3597 loss =  -14.306832579810363\n",
      "epoch =  1 batch =  2900 / 3597 loss =  -14.309424248780518\n",
      "epoch =  1 batch =  2925 / 3597 loss =  -14.313676422781432\n",
      "epoch =  1 batch =  2950 / 3597 loss =  -14.31497757736201\n",
      "epoch =  1 batch =  2975 / 3597 loss =  -14.31552841426224\n",
      "epoch =  1 batch =  3000 / 3597 loss =  -14.318609140110746\n",
      "epoch =  1 batch =  3025 / 3597 loss =  -14.319438654464046\n",
      "epoch =  1 batch =  3050 / 3597 loss =  -14.320980521195523\n",
      "epoch =  1 batch =  3075 / 3597 loss =  -14.322247277000635\n",
      "epoch =  1 batch =  3100 / 3597 loss =  -14.321809382716982\n",
      "epoch =  1 batch =  3125 / 3597 loss =  -14.325760284601994\n",
      "epoch =  1 batch =  3150 / 3597 loss =  -14.3277667861861\n",
      "epoch =  1 batch =  3175 / 3597 loss =  -14.33046472853317\n",
      "epoch =  1 batch =  3200 / 3597 loss =  -14.334157724449017\n",
      "epoch =  1 batch =  3225 / 3597 loss =  -14.335244817905226\n",
      "epoch =  1 batch =  3250 / 3597 loss =  -14.334923209721621\n",
      "epoch =  1 batch =  3275 / 3597 loss =  -14.334885093318674\n",
      "epoch =  1 batch =  3300 / 3597 loss =  -14.335554125813852\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch =  1 batch =  3325 / 3597 loss =  -14.337573185930465\n",
      "epoch =  1 batch =  3350 / 3597 loss =  -14.339742073120554\n",
      "epoch =  1 batch =  3375 / 3597 loss =  -14.340022903765547\n",
      "epoch =  1 batch =  3400 / 3597 loss =  -14.341916379561251\n",
      "epoch =  1 batch =  3425 / 3597 loss =  -14.344772187994018\n",
      "epoch =  1 batch =  3450 / 3597 loss =  -14.346889278640681\n",
      "epoch =  1 batch =  3475 / 3597 loss =  -14.347250139480082\n",
      "epoch =  1 batch =  3500 / 3597 loss =  -14.348909794007394\n",
      "epoch =  1 batch =  3525 / 3597 loss =  -14.352779027892321\n",
      "epoch =  1 batch =  3550 / 3597 loss =  -14.355382529355143\n",
      "epoch =  1 batch =  3575 / 3597 loss =  -14.357113652314649\n",
      "Validation loss =  -14.616870880126953\n",
      "epoch =  2 batch =  0 / 3597 loss =  -14.837501525878906\n",
      "epoch =  2 batch =  25 / 3597 loss =  -14.700287635509785\n",
      "epoch =  2 batch =  50 / 3597 loss =  -14.615548208648084\n",
      "epoch =  2 batch =  75 / 3597 loss =  -14.615412787387246\n",
      "epoch =  2 batch =  100 / 3597 loss =  -14.663581687625092\n",
      "epoch =  2 batch =  125 / 3597 loss =  -14.64769064433991\n",
      "epoch =  2 batch =  150 / 3597 loss =  -14.616212933268768\n",
      "epoch =  2 batch =  175 / 3597 loss =  -14.613969531926243\n",
      "epoch =  2 batch =  200 / 3597 loss =  -14.618403738410912\n",
      "epoch =  2 batch =  225 / 3597 loss =  -14.603651380116961\n",
      "epoch =  2 batch =  250 / 3597 loss =  -14.575791184170788\n",
      "epoch =  2 batch =  275 / 3597 loss =  -14.583312476890674\n",
      "epoch =  2 batch =  300 / 3597 loss =  -14.571142060416085\n",
      "epoch =  2 batch =  325 / 3597 loss =  -14.58322255889331\n",
      "epoch =  2 batch =  350 / 3597 loss =  -14.599920207618649\n",
      "epoch =  2 batch =  375 / 3597 loss =  -14.60692912974256\n",
      "epoch =  2 batch =  400 / 3597 loss =  -14.605489176704996\n",
      "epoch =  2 batch =  425 / 3597 loss =  -14.612873211712904\n",
      "epoch =  2 batch =  450 / 3597 loss =  -14.612401198917905\n",
      "epoch =  2 batch =  475 / 3597 loss =  -14.621167259056028\n",
      "epoch =  2 batch =  500 / 3597 loss =  -14.616674969534198\n",
      "epoch =  2 batch =  525 / 3597 loss =  -14.617695048734715\n",
      "epoch =  2 batch =  550 / 3597 loss =  -14.622118807964014\n",
      "epoch =  2 batch =  575 / 3597 loss =  -14.627785709169176\n",
      "epoch =  2 batch =  600 / 3597 loss =  -14.631350068205009\n",
      "epoch =  2 batch =  625 / 3597 loss =  -14.62709304090506\n",
      "epoch =  2 batch =  650 / 3597 loss =  -14.625369691629015\n",
      "epoch =  2 batch =  675 / 3597 loss =  -14.634481489305665\n",
      "epoch =  2 batch =  700 / 3597 loss =  -14.642003131490972\n",
      "epoch =  2 batch =  725 / 3597 loss =  -14.638157592332067\n",
      "epoch =  2 batch =  750 / 3597 loss =  -14.641065070537055\n",
      "epoch =  2 batch =  775 / 3597 loss =  -14.636943565201513\n",
      "epoch =  2 batch =  800 / 3597 loss =  -14.641688694519347\n",
      "epoch =  2 batch =  825 / 3597 loss =  -14.646246908940645\n",
      "epoch =  2 batch =  850 / 3597 loss =  -14.65534910836315\n",
      "epoch =  2 batch =  875 / 3597 loss =  -14.65544750483613\n",
      "epoch =  2 batch =  900 / 3597 loss =  -14.657870859999239\n",
      "epoch =  2 batch =  925 / 3597 loss =  -14.657180590454496\n",
      "epoch =  2 batch =  950 / 3597 loss =  -14.65941142735045\n",
      "epoch =  2 batch =  975 / 3597 loss =  -14.662271266100836\n",
      "epoch =  2 batch =  1000 / 3597 loss =  -14.665876926837505\n",
      "epoch =  2 batch =  1025 / 3597 loss =  -14.67315897095738\n",
      "epoch =  2 batch =  1050 / 3597 loss =  -14.671608786033971\n",
      "epoch =  2 batch =  1075 / 3597 loss =  -14.674233288569964\n",
      "epoch =  2 batch =  1100 / 3597 loss =  -14.672092068747537\n",
      "epoch =  2 batch =  1125 / 3597 loss =  -14.672780540019108\n",
      "epoch =  2 batch =  1150 / 3597 loss =  -14.673196847287594\n",
      "epoch =  2 batch =  1175 / 3597 loss =  -14.679321212833424\n",
      "epoch =  2 batch =  1200 / 3597 loss =  -14.683905207644289\n",
      "epoch =  2 batch =  1225 / 3597 loss =  -14.67807913915562\n",
      "epoch =  2 batch =  1250 / 3597 loss =  -14.68033627831011\n",
      "epoch =  2 batch =  1275 / 3597 loss =  -14.684393015774807\n",
      "epoch =  2 batch =  1300 / 3597 loss =  -14.685805281156025\n",
      "epoch =  2 batch =  1325 / 3597 loss =  -14.688559302017874\n",
      "epoch =  2 batch =  1350 / 3597 loss =  -14.690244289259832\n",
      "epoch =  2 batch =  1375 / 3597 loss =  -14.685445808394006\n",
      "epoch =  2 batch =  1400 / 3597 loss =  -14.687931874919835\n",
      "epoch =  2 batch =  1425 / 3597 loss =  -14.690936321964767\n",
      "epoch =  2 batch =  1450 / 3597 loss =  -14.699196404050248\n",
      "epoch =  2 batch =  1475 / 3597 loss =  -14.709052465149377\n",
      "epoch =  2 batch =  1500 / 3597 loss =  -14.70878399347639\n",
      "epoch =  2 batch =  1525 / 3597 loss =  -14.706573537574053\n",
      "epoch =  2 batch =  1550 / 3597 loss =  -14.70719914525497\n",
      "epoch =  2 batch =  1575 / 3597 loss =  -14.708191891007008\n",
      "epoch =  2 batch =  1600 / 3597 loss =  -14.71459276567467\n",
      "epoch =  2 batch =  1625 / 3597 loss =  -14.715373204642992\n",
      "epoch =  2 batch =  1650 / 3597 loss =  -14.718342828432908\n",
      "epoch =  2 batch =  1675 / 3597 loss =  -14.718485003724014\n",
      "epoch =  2 batch =  1700 / 3597 loss =  -14.719867966442788\n",
      "epoch =  2 batch =  1725 / 3597 loss =  -14.720792590259535\n",
      "epoch =  2 batch =  1750 / 3597 loss =  -14.721871920138474\n",
      "epoch =  2 batch =  1775 / 3597 loss =  -14.7243144018156\n",
      "epoch =  2 batch =  1800 / 3597 loss =  -14.726090626608057\n",
      "epoch =  2 batch =  1825 / 3597 loss =  -14.728559209378625\n",
      "epoch =  2 batch =  1850 / 3597 loss =  -14.731375218210571\n",
      "epoch =  2 batch =  1875 / 3597 loss =  -14.733525813007148\n",
      "epoch =  2 batch =  1900 / 3597 loss =  -14.736259808608066\n",
      "epoch =  2 batch =  1925 / 3597 loss =  -14.737558489647977\n",
      "epoch =  2 batch =  1950 / 3597 loss =  -14.741702697143864\n",
      "epoch =  2 batch =  1975 / 3597 loss =  -14.742855913725938\n",
      "epoch =  2 batch =  2000 / 3597 loss =  -14.745248620120478\n",
      "epoch =  2 batch =  2025 / 3597 loss =  -14.747432320868741\n",
      "epoch =  2 batch =  2050 / 3597 loss =  -14.747740311252956\n",
      "epoch =  2 batch =  2075 / 3597 loss =  -14.749747008027825\n",
      "epoch =  2 batch =  2100 / 3597 loss =  -14.75065355014937\n",
      "epoch =  2 batch =  2125 / 3597 loss =  -14.750396601119808\n",
      "epoch =  2 batch =  2150 / 3597 loss =  -14.75365029729172\n",
      "epoch =  2 batch =  2175 / 3597 loss =  -14.753070967162358\n",
      "epoch =  2 batch =  2200 / 3597 loss =  -14.753739223974176\n",
      "epoch =  2 batch =  2225 / 3597 loss =  -14.754750257339547\n",
      "epoch =  2 batch =  2250 / 3597 loss =  -14.754593195887685\n",
      "epoch =  2 batch =  2275 / 3597 loss =  -14.755729928796027\n",
      "epoch =  2 batch =  2300 / 3597 loss =  -14.757329498566218\n",
      "epoch =  2 batch =  2325 / 3597 loss =  -14.758583248430352\n",
      "epoch =  2 batch =  2350 / 3597 loss =  -14.759071598758803\n",
      "epoch =  2 batch =  2375 / 3597 loss =  -14.75941111664178\n",
      "epoch =  2 batch =  2400 / 3597 loss =  -14.759555848426295\n",
      "epoch =  2 batch =  2425 / 3597 loss =  -14.760171319862485\n",
      "epoch =  2 batch =  2450 / 3597 loss =  -14.76017906830195\n",
      "epoch =  2 batch =  2475 / 3597 loss =  -14.760962882989443\n",
      "epoch =  2 batch =  2500 / 3597 loss =  -14.764543187851812\n",
      "epoch =  2 batch =  2525 / 3597 loss =  -14.766723521814777\n",
      "epoch =  2 batch =  2550 / 3597 loss =  -14.767649695808773\n",
      "epoch =  2 batch =  2575 / 3597 loss =  -14.767714978004834\n",
      "epoch =  2 batch =  2600 / 3597 loss =  -14.768064044246945\n",
      "epoch =  2 batch =  2625 / 3597 loss =  -14.770406049349248\n",
      "epoch =  2 batch =  2650 / 3597 loss =  -14.770357341327474\n",
      "epoch =  2 batch =  2675 / 3597 loss =  -14.767589853839846\n",
      "epoch =  2 batch =  2700 / 3597 loss =  -14.768602644148158\n",
      "epoch =  2 batch =  2725 / 3597 loss =  -14.769757915925036\n",
      "epoch =  2 batch =  2750 / 3597 loss =  -14.770892235462295\n",
      "epoch =  2 batch =  2775 / 3597 loss =  -14.776324455607522\n",
      "epoch =  2 batch =  2800 / 3597 loss =  -14.776950209024164\n",
      "epoch =  2 batch =  2825 / 3597 loss =  -14.77875106484858\n",
      "epoch =  2 batch =  2850 / 3597 loss =  -14.780385793781582\n",
      "epoch =  2 batch =  2875 / 3597 loss =  -14.78442833088701\n",
      "epoch =  2 batch =  2900 / 3597 loss =  -14.787802537775418\n",
      "epoch =  2 batch =  2925 / 3597 loss =  -14.789128301246315\n",
      "epoch =  2 batch =  2950 / 3597 loss =  -14.789607052882216\n",
      "epoch =  2 batch =  2975 / 3597 loss =  -14.790990574705985\n",
      "epoch =  2 batch =  3000 / 3597 loss =  -14.790406223933962\n",
      "epoch =  2 batch =  3025 / 3597 loss =  -14.791812155156913\n",
      "epoch =  2 batch =  3050 / 3597 loss =  -14.790388530217324\n",
      "epoch =  2 batch =  3075 / 3597 loss =  -14.791782605167484\n",
      "epoch =  2 batch =  3100 / 3597 loss =  -14.790746638714133\n",
      "epoch =  2 batch =  3125 / 3597 loss =  -14.790487165872058\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch =  2 batch =  3150 / 3597 loss =  -14.79252499937822\n",
      "epoch =  2 batch =  3175 / 3597 loss =  -14.792928848218558\n",
      "epoch =  2 batch =  3200 / 3597 loss =  -14.795544390751399\n",
      "epoch =  2 batch =  3225 / 3597 loss =  -14.796652232203806\n",
      "epoch =  2 batch =  3250 / 3597 loss =  -14.796315499138224\n",
      "epoch =  2 batch =  3275 / 3597 loss =  -14.79568148911072\n",
      "epoch =  2 batch =  3300 / 3597 loss =  -14.795369102029648\n",
      "epoch =  2 batch =  3325 / 3597 loss =  -14.798789903476736\n",
      "epoch =  2 batch =  3350 / 3597 loss =  -14.799766401360904\n",
      "epoch =  2 batch =  3375 / 3597 loss =  -14.799943755588261\n",
      "epoch =  2 batch =  3400 / 3597 loss =  -14.80244406823795\n",
      "epoch =  2 batch =  3425 / 3597 loss =  -14.801963307046083\n",
      "epoch =  2 batch =  3450 / 3597 loss =  -14.804576300358779\n",
      "epoch =  2 batch =  3475 / 3597 loss =  -14.804631808821982\n",
      "epoch =  2 batch =  3500 / 3597 loss =  -14.804732692885215\n",
      "epoch =  2 batch =  3525 / 3597 loss =  -14.80584778842504\n",
      "epoch =  2 batch =  3550 / 3597 loss =  -14.805039475649654\n",
      "epoch =  2 batch =  3575 / 3597 loss =  -14.80599101251137\n",
      "Validation loss =  -14.690820693969727\n",
      "epoch =  3 batch =  0 / 3597 loss =  -13.162487030029297\n",
      "epoch =  3 batch =  25 / 3597 loss =  -14.979309155390812\n",
      "epoch =  3 batch =  50 / 3597 loss =  -15.102051211338416\n",
      "epoch =  3 batch =  75 / 3597 loss =  -15.04965917687667\n",
      "epoch =  3 batch =  100 / 3597 loss =  -14.925652768352244\n",
      "epoch =  3 batch =  125 / 3597 loss =  -14.912107573615181\n",
      "epoch =  3 batch =  150 / 3597 loss =  -14.966348262812128\n",
      "epoch =  3 batch =  175 / 3597 loss =  -14.983613333918832\n",
      "epoch =  3 batch =  200 / 3597 loss =  -14.982662291076053\n",
      "epoch =  3 batch =  225 / 3597 loss =  -14.980749632404969\n",
      "epoch =  3 batch =  250 / 3597 loss =  -14.957452641065377\n",
      "epoch =  3 batch =  275 / 3597 loss =  -14.968625289806422\n",
      "epoch =  3 batch =  300 / 3597 loss =  -14.971593387895249\n",
      "epoch =  3 batch =  325 / 3597 loss =  -14.983686028814024\n",
      "epoch =  3 batch =  350 / 3597 loss =  -15.000157244864353\n",
      "epoch =  3 batch =  375 / 3597 loss =  -14.997889435037653\n",
      "epoch =  3 batch =  400 / 3597 loss =  -14.996737223313634\n",
      "epoch =  3 batch =  425 / 3597 loss =  -14.996278095693096\n",
      "epoch =  3 batch =  450 / 3597 loss =  -14.995018182995578\n",
      "epoch =  3 batch =  475 / 3597 loss =  -14.996383865340418\n",
      "epoch =  3 batch =  500 / 3597 loss =  -14.990549708078959\n",
      "epoch =  3 batch =  525 / 3597 loss =  -15.002411550442076\n",
      "epoch =  3 batch =  550 / 3597 loss =  -15.02114534983834\n",
      "epoch =  3 batch =  575 / 3597 loss =  -15.012695136997435\n",
      "epoch =  3 batch =  600 / 3597 loss =  -15.016557423723318\n",
      "epoch =  3 batch =  625 / 3597 loss =  -15.006150757542814\n",
      "epoch =  3 batch =  650 / 3597 loss =  -14.999783411919612\n",
      "epoch =  3 batch =  675 / 3597 loss =  -15.003557246112258\n",
      "epoch =  3 batch =  700 / 3597 loss =  -14.996553736644533\n",
      "epoch =  3 batch =  725 / 3597 loss =  -14.992893041658007\n",
      "epoch =  3 batch =  750 / 3597 loss =  -15.008646754228005\n",
      "epoch =  3 batch =  775 / 3597 loss =  -15.01360207243064\n",
      "epoch =  3 batch =  800 / 3597 loss =  -15.008128973428676\n",
      "epoch =  3 batch =  825 / 3597 loss =  -15.004961298972585\n",
      "epoch =  3 batch =  850 / 3597 loss =  -15.008304521984275\n",
      "epoch =  3 batch =  875 / 3597 loss =  -15.016995222056837\n",
      "epoch =  3 batch =  900 / 3597 loss =  -15.011155237500596\n",
      "epoch =  3 batch =  925 / 3597 loss =  -15.008504774863983\n",
      "epoch =  3 batch =  950 / 3597 loss =  -14.999336667868116\n",
      "epoch =  3 batch =  975 / 3597 loss =  -15.000647568311848\n",
      "epoch =  3 batch =  1000 / 3597 loss =  -15.003761314369225\n",
      "epoch =  3 batch =  1025 / 3597 loss =  -15.007242143270332\n",
      "epoch =  3 batch =  1050 / 3597 loss =  -15.012035373502636\n",
      "epoch =  3 batch =  1075 / 3597 loss =  -15.011976558479676\n",
      "epoch =  3 batch =  1100 / 3597 loss =  -15.01133706026138\n",
      "epoch =  3 batch =  1125 / 3597 loss =  -15.010083554269578\n",
      "epoch =  3 batch =  1150 / 3597 loss =  -15.013640679658547\n",
      "epoch =  3 batch =  1175 / 3597 loss =  -15.023224440561671\n",
      "epoch =  3 batch =  1200 / 3597 loss =  -15.02770751679966\n",
      "epoch =  3 batch =  1225 / 3597 loss =  -15.025489121821343\n",
      "epoch =  3 batch =  1250 / 3597 loss =  -15.022732530375846\n",
      "epoch =  3 batch =  1275 / 3597 loss =  -15.019528594510309\n",
      "epoch =  3 batch =  1300 / 3597 loss =  -15.022062784703671\n",
      "epoch =  3 batch =  1325 / 3597 loss =  -15.023038172973587\n",
      "epoch =  3 batch =  1350 / 3597 loss =  -15.020510302924121\n",
      "epoch =  3 batch =  1375 / 3597 loss =  -15.014047102872716\n",
      "epoch =  3 batch =  1400 / 3597 loss =  -15.018482645267593\n",
      "epoch =  3 batch =  1425 / 3597 loss =  -15.015036162955564\n",
      "epoch =  3 batch =  1450 / 3597 loss =  -15.015978727071225\n",
      "epoch =  3 batch =  1475 / 3597 loss =  -15.008443726433647\n",
      "epoch =  3 batch =  1500 / 3597 loss =  -15.008804037918813\n",
      "epoch =  3 batch =  1525 / 3597 loss =  -15.012028099200048\n",
      "epoch =  3 batch =  1550 / 3597 loss =  -15.014809899911198\n",
      "epoch =  3 batch =  1575 / 3597 loss =  -15.008561635985592\n",
      "epoch =  3 batch =  1600 / 3597 loss =  -15.008969233082206\n",
      "epoch =  3 batch =  1625 / 3597 loss =  -15.00847056049849\n",
      "epoch =  3 batch =  1650 / 3597 loss =  -15.010315175925797\n",
      "epoch =  3 batch =  1675 / 3597 loss =  -15.011564745254335\n",
      "epoch =  3 batch =  1700 / 3597 loss =  -15.014218467743799\n",
      "epoch =  3 batch =  1725 / 3597 loss =  -15.015652389128542\n",
      "epoch =  3 batch =  1750 / 3597 loss =  -15.014278983743036\n",
      "epoch =  3 batch =  1775 / 3597 loss =  -15.01826388127095\n",
      "epoch =  3 batch =  1800 / 3597 loss =  -15.01989254218085\n",
      "epoch =  3 batch =  1825 / 3597 loss =  -15.02342374222955\n",
      "epoch =  3 batch =  1850 / 3597 loss =  -15.022303421519242\n",
      "epoch =  3 batch =  1875 / 3597 loss =  -15.019834062946376\n",
      "epoch =  3 batch =  1900 / 3597 loss =  -15.019700901186008\n",
      "epoch =  3 batch =  1925 / 3597 loss =  -15.020008613511163\n",
      "epoch =  3 batch =  1950 / 3597 loss =  -15.02378027723851\n",
      "epoch =  3 batch =  1975 / 3597 loss =  -15.026648079335448\n",
      "epoch =  3 batch =  2000 / 3597 loss =  -15.020955203950912\n",
      "epoch =  3 batch =  2025 / 3597 loss =  -15.020213740952276\n",
      "epoch =  3 batch =  2050 / 3597 loss =  -15.024982594676509\n",
      "epoch =  3 batch =  2075 / 3597 loss =  -15.023274184651457\n",
      "epoch =  3 batch =  2100 / 3597 loss =  -15.02513757584947\n",
      "epoch =  3 batch =  2125 / 3597 loss =  -15.027370309784853\n",
      "epoch =  3 batch =  2150 / 3597 loss =  -15.027576659790919\n",
      "epoch =  3 batch =  2175 / 3597 loss =  -15.030096431865411\n",
      "epoch =  3 batch =  2200 / 3597 loss =  -15.030775245240145\n",
      "epoch =  3 batch =  2225 / 3597 loss =  -15.029516652802144\n",
      "epoch =  3 batch =  2250 / 3597 loss =  -15.027302244195722\n",
      "epoch =  3 batch =  2275 / 3597 loss =  -15.027745246468193\n",
      "epoch =  3 batch =  2300 / 3597 loss =  -15.026985778128878\n",
      "epoch =  3 batch =  2325 / 3597 loss =  -15.026763264515845\n",
      "epoch =  3 batch =  2350 / 3597 loss =  -15.025574740527894\n",
      "epoch =  3 batch =  2375 / 3597 loss =  -15.01984353900357\n",
      "epoch =  3 batch =  2400 / 3597 loss =  -15.018612763525198\n",
      "epoch =  3 batch =  2425 / 3597 loss =  -15.01885362941179\n",
      "epoch =  3 batch =  2450 / 3597 loss =  -15.02242661962116\n",
      "epoch =  3 batch =  2475 / 3597 loss =  -15.021035598437505\n",
      "epoch =  3 batch =  2500 / 3597 loss =  -15.019414619939988\n",
      "epoch =  3 batch =  2525 / 3597 loss =  -15.022625390443174\n",
      "epoch =  3 batch =  2550 / 3597 loss =  -15.023282064170942\n",
      "epoch =  3 batch =  2575 / 3597 loss =  -15.019248599591462\n",
      "epoch =  3 batch =  2600 / 3597 loss =  -15.021809144553567\n",
      "epoch =  3 batch =  2625 / 3597 loss =  -15.02093969876768\n",
      "epoch =  3 batch =  2650 / 3597 loss =  -15.02190746931884\n",
      "epoch =  3 batch =  2675 / 3597 loss =  -15.023441305431371\n",
      "epoch =  3 batch =  2700 / 3597 loss =  -15.022581761433257\n",
      "epoch =  3 batch =  2725 / 3597 loss =  -15.022760904806113\n",
      "epoch =  3 batch =  2750 / 3597 loss =  -15.024567145427675\n",
      "epoch =  3 batch =  2775 / 3597 loss =  -15.025922806530934\n",
      "epoch =  3 batch =  2800 / 3597 loss =  -15.027417899625124\n",
      "epoch =  3 batch =  2825 / 3597 loss =  -15.02679519390098\n",
      "epoch =  3 batch =  2850 / 3597 loss =  -15.024484130634587\n",
      "epoch =  3 batch =  2875 / 3597 loss =  -15.020891694929736\n",
      "epoch =  3 batch =  2900 / 3597 loss =  -15.018885630897225\n",
      "epoch =  3 batch =  2925 / 3597 loss =  -15.020532050690093\n",
      "epoch =  3 batch =  2950 / 3597 loss =  -15.021625514920789\n",
      "epoch =  3 batch =  2975 / 3597 loss =  -15.02108988326083\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch =  3 batch =  3000 / 3597 loss =  -15.02278028715058\n",
      "epoch =  3 batch =  3025 / 3597 loss =  -15.023341060709024\n",
      "epoch =  3 batch =  3050 / 3597 loss =  -15.023287990998925\n",
      "epoch =  3 batch =  3075 / 3597 loss =  -15.022860536959763\n",
      "epoch =  3 batch =  3100 / 3597 loss =  -15.021656931311574\n",
      "epoch =  3 batch =  3125 / 3597 loss =  -15.02323330081737\n",
      "epoch =  3 batch =  3150 / 3597 loss =  -15.024923563987178\n",
      "epoch =  3 batch =  3175 / 3597 loss =  -15.026135816982471\n",
      "epoch =  3 batch =  3200 / 3597 loss =  -15.028353724469248\n",
      "epoch =  3 batch =  3225 / 3597 loss =  -15.028823765035158\n",
      "epoch =  3 batch =  3250 / 3597 loss =  -15.031098364316952\n",
      "epoch =  3 batch =  3275 / 3597 loss =  -15.029220966483502\n",
      "epoch =  3 batch =  3300 / 3597 loss =  -15.030485417546016\n",
      "epoch =  3 batch =  3325 / 3597 loss =  -15.028140841660123\n",
      "epoch =  3 batch =  3350 / 3597 loss =  -15.029541417471654\n",
      "epoch =  3 batch =  3375 / 3597 loss =  -15.027470055632117\n",
      "epoch =  3 batch =  3400 / 3597 loss =  -15.026917695929043\n",
      "epoch =  3 batch =  3425 / 3597 loss =  -15.027313011122668\n",
      "epoch =  3 batch =  3450 / 3597 loss =  -15.025076076625846\n",
      "epoch =  3 batch =  3475 / 3597 loss =  -15.025240914045186\n",
      "epoch =  3 batch =  3500 / 3597 loss =  -15.022388821089482\n",
      "epoch =  3 batch =  3525 / 3597 loss =  -15.023304758326141\n",
      "epoch =  3 batch =  3550 / 3597 loss =  -15.022787690599078\n",
      "epoch =  3 batch =  3575 / 3597 loss =  -15.022528253679042\n",
      "Validation loss =  -14.708380699157715\n",
      "epoch =  4 batch =  0 / 3597 loss =  -15.518122673034668\n",
      "epoch =  4 batch =  25 / 3597 loss =  -15.191219513232891\n",
      "epoch =  4 batch =  50 / 3597 loss =  -15.110577901204428\n",
      "epoch =  4 batch =  75 / 3597 loss =  -15.150950205953498\n",
      "epoch =  4 batch =  100 / 3597 loss =  -15.136331756516258\n",
      "epoch =  4 batch =  125 / 3597 loss =  -15.109612517886692\n",
      "epoch =  4 batch =  150 / 3597 loss =  -15.131894149527644\n",
      "epoch =  4 batch =  175 / 3597 loss =  -15.09249034794894\n",
      "epoch =  4 batch =  200 / 3597 loss =  -15.140791328392218\n",
      "epoch =  4 batch =  225 / 3597 loss =  -15.15259767211644\n",
      "epoch =  4 batch =  250 / 3597 loss =  -15.145285507597297\n",
      "epoch =  4 batch =  275 / 3597 loss =  -15.146843827289084\n",
      "epoch =  4 batch =  300 / 3597 loss =  -15.154648334084952\n",
      "epoch =  4 batch =  325 / 3597 loss =  -15.142735975651654\n",
      "epoch =  4 batch =  350 / 3597 loss =  -15.158150795178535\n",
      "epoch =  4 batch =  375 / 3597 loss =  -15.139168018990375\n",
      "epoch =  4 batch =  400 / 3597 loss =  -15.147004650715283\n",
      "epoch =  4 batch =  425 / 3597 loss =  -15.160498169106496\n",
      "epoch =  4 batch =  450 / 3597 loss =  -15.147742797953063\n",
      "epoch =  4 batch =  475 / 3597 loss =  -15.133657924267425\n",
      "epoch =  4 batch =  500 / 3597 loss =  -15.139221880488291\n",
      "epoch =  4 batch =  525 / 3597 loss =  -15.139852023396656\n",
      "epoch =  4 batch =  550 / 3597 loss =  -15.149222528004174\n",
      "epoch =  4 batch =  575 / 3597 loss =  -15.154343090123604\n",
      "epoch =  4 batch =  600 / 3597 loss =  -15.153032034685134\n",
      "epoch =  4 batch =  625 / 3597 loss =  -15.148688500681628\n",
      "epoch =  4 batch =  650 / 3597 loss =  -15.146138227846585\n",
      "epoch =  4 batch =  675 / 3597 loss =  -15.140049003285066\n",
      "epoch =  4 batch =  700 / 3597 loss =  -15.140646831115204\n",
      "epoch =  4 batch =  725 / 3597 loss =  -15.144681188357437\n",
      "epoch =  4 batch =  750 / 3597 loss =  -15.146132549179221\n",
      "epoch =  4 batch =  775 / 3597 loss =  -15.141706453156228\n",
      "epoch =  4 batch =  800 / 3597 loss =  -15.143898174557348\n",
      "epoch =  4 batch =  825 / 3597 loss =  -15.141969588420583\n",
      "epoch =  4 batch =  850 / 3597 loss =  -15.14204636920073\n",
      "epoch =  4 batch =  875 / 3597 loss =  -15.135247861957987\n",
      "epoch =  4 batch =  900 / 3597 loss =  -15.139807164470577\n",
      "epoch =  4 batch =  925 / 3597 loss =  -15.132765211760356\n",
      "epoch =  4 batch =  950 / 3597 loss =  -15.133892934781146\n",
      "epoch =  4 batch =  975 / 3597 loss =  -15.136655324795209\n",
      "epoch =  4 batch =  1000 / 3597 loss =  -15.134846688269619\n",
      "epoch =  4 batch =  1025 / 3597 loss =  -15.135880777013234\n",
      "epoch =  4 batch =  1050 / 3597 loss =  -15.142727691258397\n",
      "epoch =  4 batch =  1075 / 3597 loss =  -15.141460665982896\n",
      "epoch =  4 batch =  1100 / 3597 loss =  -15.143793113874805\n",
      "epoch =  4 batch =  1125 / 3597 loss =  -15.142874931992688\n",
      "epoch =  4 batch =  1150 / 3597 loss =  -15.150410508819501\n",
      "epoch =  4 batch =  1175 / 3597 loss =  -15.149471100495786\n",
      "epoch =  4 batch =  1200 / 3597 loss =  -15.146538680439487\n",
      "epoch =  4 batch =  1225 / 3597 loss =  -15.146014333354707\n",
      "epoch =  4 batch =  1250 / 3597 loss =  -15.136353358566808\n",
      "epoch =  4 batch =  1275 / 3597 loss =  -15.132271646332217\n",
      "epoch =  4 batch =  1300 / 3597 loss =  -15.134222239553699\n",
      "epoch =  4 batch =  1325 / 3597 loss =  -15.131326312932494\n",
      "epoch =  4 batch =  1350 / 3597 loss =  -15.127997183076193\n",
      "epoch =  4 batch =  1375 / 3597 loss =  -15.129153370857239\n",
      "epoch =  4 batch =  1400 / 3597 loss =  -15.123389625957742\n",
      "epoch =  4 batch =  1425 / 3597 loss =  -15.123694039327399\n",
      "epoch =  4 batch =  1450 / 3597 loss =  -15.122850552170462\n",
      "epoch =  4 batch =  1475 / 3597 loss =  -15.125850773116115\n",
      "epoch =  4 batch =  1500 / 3597 loss =  -15.126120650553846\n",
      "epoch =  4 batch =  1525 / 3597 loss =  -15.13048595400969\n",
      "epoch =  4 batch =  1550 / 3597 loss =  -15.130021036862559\n",
      "epoch =  4 batch =  1575 / 3597 loss =  -15.12916378442406\n",
      "epoch =  4 batch =  1600 / 3597 loss =  -15.130989416623994\n",
      "epoch =  4 batch =  1625 / 3597 loss =  -15.133318134486162\n",
      "epoch =  4 batch =  1650 / 3597 loss =  -15.134106664929082\n",
      "epoch =  4 batch =  1675 / 3597 loss =  -15.1314920235363\n",
      "epoch =  4 batch =  1700 / 3597 loss =  -15.131841565355842\n",
      "epoch =  4 batch =  1725 / 3597 loss =  -15.128995601989994\n",
      "epoch =  4 batch =  1750 / 3597 loss =  -15.131123531892735\n",
      "epoch =  4 batch =  1775 / 3597 loss =  -15.132702239998826\n",
      "epoch =  4 batch =  1800 / 3597 loss =  -15.133096499551607\n",
      "epoch =  4 batch =  1825 / 3597 loss =  -15.136039778280102\n",
      "epoch =  4 batch =  1850 / 3597 loss =  -15.132751058849497\n",
      "epoch =  4 batch =  1875 / 3597 loss =  -15.132369319004798\n",
      "epoch =  4 batch =  1900 / 3597 loss =  -15.13594616644637\n",
      "epoch =  4 batch =  1925 / 3597 loss =  -15.134403858600747\n",
      "epoch =  4 batch =  1950 / 3597 loss =  -15.135823862788495\n",
      "epoch =  4 batch =  1975 / 3597 loss =  -15.134181342144243\n",
      "epoch =  4 batch =  2000 / 3597 loss =  -15.135507533575284\n",
      "epoch =  4 batch =  2025 / 3597 loss =  -15.14036146815414\n",
      "epoch =  4 batch =  2050 / 3597 loss =  -15.14251292408646\n",
      "epoch =  4 batch =  2075 / 3597 loss =  -15.143069256707193\n",
      "epoch =  4 batch =  2100 / 3597 loss =  -15.144167402141267\n",
      "epoch =  4 batch =  2125 / 3597 loss =  -15.14463161726886\n",
      "epoch =  4 batch =  2150 / 3597 loss =  -15.145703056810731\n",
      "epoch =  4 batch =  2175 / 3597 loss =  -15.1458431898671\n",
      "epoch =  4 batch =  2200 / 3597 loss =  -15.148201205848506\n",
      "epoch =  4 batch =  2225 / 3597 loss =  -15.146713174578311\n",
      "epoch =  4 batch =  2250 / 3597 loss =  -15.148170998233095\n",
      "epoch =  4 batch =  2275 / 3597 loss =  -15.150614689439793\n",
      "epoch =  4 batch =  2300 / 3597 loss =  -15.15216188376906\n",
      "epoch =  4 batch =  2325 / 3597 loss =  -15.153958369408405\n",
      "epoch =  4 batch =  2350 / 3597 loss =  -15.156697171437184\n",
      "epoch =  4 batch =  2375 / 3597 loss =  -15.158356974421926\n",
      "epoch =  4 batch =  2400 / 3597 loss =  -15.158976672441447\n",
      "epoch =  4 batch =  2425 / 3597 loss =  -15.159696589593342\n",
      "epoch =  4 batch =  2450 / 3597 loss =  -15.162599828573011\n",
      "epoch =  4 batch =  2475 / 3597 loss =  -15.16116975698024\n",
      "epoch =  4 batch =  2500 / 3597 loss =  -15.161046359120533\n",
      "epoch =  4 batch =  2525 / 3597 loss =  -15.159321587895551\n",
      "epoch =  4 batch =  2550 / 3597 loss =  -15.161149765173155\n",
      "epoch =  4 batch =  2575 / 3597 loss =  -15.163540289638943\n",
      "epoch =  4 batch =  2600 / 3597 loss =  -15.164566950081218\n",
      "epoch =  4 batch =  2625 / 3597 loss =  -15.167404202042146\n",
      "epoch =  4 batch =  2650 / 3597 loss =  -15.167387593606422\n",
      "epoch =  4 batch =  2675 / 3597 loss =  -15.167824361712762\n",
      "epoch =  4 batch =  2700 / 3597 loss =  -15.165779715421152\n",
      "epoch =  4 batch =  2725 / 3597 loss =  -15.165480608460836\n",
      "epoch =  4 batch =  2750 / 3597 loss =  -15.163855746112185\n",
      "epoch =  4 batch =  2775 / 3597 loss =  -15.165457565777581\n",
      "epoch =  4 batch =  2800 / 3597 loss =  -15.166560213210877\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch =  4 batch =  2825 / 3597 loss =  -15.165194915020962\n",
      "epoch =  4 batch =  2850 / 3597 loss =  -15.164841786053085\n",
      "epoch =  4 batch =  2875 / 3597 loss =  -15.16409544686117\n",
      "epoch =  4 batch =  2900 / 3597 loss =  -15.163910172471336\n",
      "epoch =  4 batch =  2925 / 3597 loss =  -15.164854743589867\n",
      "epoch =  4 batch =  2950 / 3597 loss =  -15.16470019658191\n",
      "epoch =  4 batch =  2975 / 3597 loss =  -15.16631504156256\n",
      "epoch =  4 batch =  3000 / 3597 loss =  -15.165048338659043\n",
      "epoch =  4 batch =  3025 / 3597 loss =  -15.166337831084961\n",
      "epoch =  4 batch =  3050 / 3597 loss =  -15.167202263103471\n",
      "epoch =  4 batch =  3075 / 3597 loss =  -15.1675673833284\n",
      "epoch =  4 batch =  3100 / 3597 loss =  -15.16865845581517\n",
      "epoch =  4 batch =  3125 / 3597 loss =  -15.16949273406582\n",
      "epoch =  4 batch =  3150 / 3597 loss =  -15.169659325524911\n",
      "epoch =  4 batch =  3175 / 3597 loss =  -15.168034217219507\n",
      "epoch =  4 batch =  3200 / 3597 loss =  -15.167977552047484\n",
      "epoch =  4 batch =  3225 / 3597 loss =  -15.166608906501725\n",
      "epoch =  4 batch =  3250 / 3597 loss =  -15.169032790630787\n",
      "epoch =  4 batch =  3275 / 3597 loss =  -15.16782163234566\n",
      "epoch =  4 batch =  3300 / 3597 loss =  -15.168720687096567\n",
      "epoch =  4 batch =  3325 / 3597 loss =  -15.170427243822822\n",
      "epoch =  4 batch =  3350 / 3597 loss =  -15.171425602251789\n",
      "epoch =  4 batch =  3375 / 3597 loss =  -15.171999084158529\n",
      "epoch =  4 batch =  3400 / 3597 loss =  -15.172348864532083\n",
      "epoch =  4 batch =  3425 / 3597 loss =  -15.17162444392492\n",
      "epoch =  4 batch =  3450 / 3597 loss =  -15.174223988825117\n",
      "epoch =  4 batch =  3475 / 3597 loss =  -15.174758854889072\n",
      "epoch =  4 batch =  3500 / 3597 loss =  -15.175648997355037\n",
      "epoch =  4 batch =  3525 / 3597 loss =  -15.175047570443327\n",
      "epoch =  4 batch =  3550 / 3597 loss =  -15.175926564344717\n",
      "epoch =  4 batch =  3575 / 3597 loss =  -15.177653238543993\n",
      "Validation loss =  -14.993119239807129\n",
      "epoch =  5 batch =  0 / 3597 loss =  -15.305953979492188\n",
      "epoch =  5 batch =  25 / 3597 loss =  -15.250695008497972\n",
      "epoch =  5 batch =  50 / 3597 loss =  -15.347125389996696\n",
      "epoch =  5 batch =  75 / 3597 loss =  -15.332711997785067\n",
      "epoch =  5 batch =  100 / 3597 loss =  -15.378446815037492\n",
      "epoch =  5 batch =  125 / 3597 loss =  -15.409072134229872\n",
      "epoch =  5 batch =  150 / 3597 loss =  -15.392007114081983\n",
      "epoch =  5 batch =  175 / 3597 loss =  -15.3869373310696\n",
      "epoch =  5 batch =  200 / 3597 loss =  -15.361066158731186\n",
      "epoch =  5 batch =  225 / 3597 loss =  -15.333900363044402\n",
      "epoch =  5 batch =  250 / 3597 loss =  -15.337038921644963\n",
      "epoch =  5 batch =  275 / 3597 loss =  -15.337007291075112\n",
      "epoch =  5 batch =  300 / 3597 loss =  -15.34607630314621\n",
      "epoch =  5 batch =  325 / 3597 loss =  -15.309533025589458\n",
      "epoch =  5 batch =  350 / 3597 loss =  -15.304019995904037\n",
      "epoch =  5 batch =  375 / 3597 loss =  -15.293390385648037\n",
      "epoch =  5 batch =  400 / 3597 loss =  -15.290897509700937\n",
      "epoch =  5 batch =  425 / 3597 loss =  -15.299345898516302\n",
      "epoch =  5 batch =  450 / 3597 loss =  -15.302318907101244\n",
      "epoch =  5 batch =  475 / 3597 loss =  -15.308105432686686\n",
      "epoch =  5 batch =  500 / 3597 loss =  -15.294810913755985\n",
      "epoch =  5 batch =  525 / 3597 loss =  -15.289511270849424\n",
      "epoch =  5 batch =  550 / 3597 loss =  -15.294613770694351\n",
      "epoch =  5 batch =  575 / 3597 loss =  -15.293263433708084\n",
      "epoch =  5 batch =  600 / 3597 loss =  -15.294272205397213\n",
      "epoch =  5 batch =  625 / 3597 loss =  -15.290738290110335\n",
      "epoch =  5 batch =  650 / 3597 loss =  -15.294203963330997\n",
      "epoch =  5 batch =  675 / 3597 loss =  -15.29737094027051\n",
      "epoch =  5 batch =  700 / 3597 loss =  -15.3042795192158\n",
      "epoch =  5 batch =  725 / 3597 loss =  -15.298989632241325\n",
      "epoch =  5 batch =  750 / 3597 loss =  -15.29735416356479\n",
      "epoch =  5 batch =  775 / 3597 loss =  -15.299956338921772\n",
      "epoch =  5 batch =  800 / 3597 loss =  -15.302072994122643\n",
      "epoch =  5 batch =  825 / 3597 loss =  -15.293094137390359\n",
      "epoch =  5 batch =  850 / 3597 loss =  -15.284210125511878\n",
      "epoch =  5 batch =  875 / 3597 loss =  -15.285976224838327\n",
      "epoch =  5 batch =  900 / 3597 loss =  -15.275874880918785\n",
      "epoch =  5 batch =  925 / 3597 loss =  -15.269504183569428\n",
      "epoch =  5 batch =  950 / 3597 loss =  -15.263016751888047\n",
      "epoch =  5 batch =  975 / 3597 loss =  -15.267105775778411\n",
      "epoch =  5 batch =  1000 / 3597 loss =  -15.266481825402686\n",
      "epoch =  5 batch =  1025 / 3597 loss =  -15.269391530206097\n",
      "epoch =  5 batch =  1050 / 3597 loss =  -15.267918597619724\n",
      "epoch =  5 batch =  1075 / 3597 loss =  -15.278005558318812\n",
      "epoch =  5 batch =  1100 / 3597 loss =  -15.27076710883755\n",
      "epoch =  5 batch =  1125 / 3597 loss =  -15.273901206773724\n",
      "epoch =  5 batch =  1150 / 3597 loss =  -15.270682567725695\n",
      "epoch =  5 batch =  1175 / 3597 loss =  -15.271247204469178\n",
      "epoch =  5 batch =  1200 / 3597 loss =  -15.275271196547996\n",
      "epoch =  5 batch =  1225 / 3597 loss =  -15.27567553948034\n",
      "epoch =  5 batch =  1250 / 3597 loss =  -15.281426093561189\n",
      "epoch =  5 batch =  1275 / 3597 loss =  -15.282306317625377\n",
      "epoch =  5 batch =  1300 / 3597 loss =  -15.280827569191867\n",
      "epoch =  5 batch =  1325 / 3597 loss =  -15.27731522679509\n",
      "epoch =  5 batch =  1350 / 3597 loss =  -15.284685547840677\n",
      "epoch =  5 batch =  1375 / 3597 loss =  -15.282423958528875\n",
      "epoch =  5 batch =  1400 / 3597 loss =  -15.280083328889663\n",
      "epoch =  5 batch =  1425 / 3597 loss =  -15.27818417315062\n",
      "epoch =  5 batch =  1450 / 3597 loss =  -15.275602715989791\n",
      "epoch =  5 batch =  1475 / 3597 loss =  -15.27318148884347\n",
      "epoch =  5 batch =  1500 / 3597 loss =  -15.271379865383325\n",
      "epoch =  5 batch =  1525 / 3597 loss =  -15.272111150884069\n",
      "epoch =  5 batch =  1550 / 3597 loss =  -15.27065046520713\n",
      "epoch =  5 batch =  1575 / 3597 loss =  -15.27519599193244\n",
      "epoch =  5 batch =  1600 / 3597 loss =  -15.279345568383508\n",
      "epoch =  5 batch =  1625 / 3597 loss =  -15.280729436933044\n",
      "epoch =  5 batch =  1650 / 3597 loss =  -15.282229361716075\n",
      "epoch =  5 batch =  1675 / 3597 loss =  -15.279968368125134\n",
      "epoch =  5 batch =  1700 / 3597 loss =  -15.27716580648271\n",
      "epoch =  5 batch =  1725 / 3597 loss =  -15.273682793764225\n",
      "epoch =  5 batch =  1750 / 3597 loss =  -15.277448889461674\n",
      "epoch =  5 batch =  1775 / 3597 loss =  -15.27626277143891\n",
      "epoch =  5 batch =  1800 / 3597 loss =  -15.275306364352806\n",
      "epoch =  5 batch =  1825 / 3597 loss =  -15.274632899941388\n",
      "epoch =  5 batch =  1850 / 3597 loss =  -15.273172913339577\n",
      "epoch =  5 batch =  1875 / 3597 loss =  -15.274240638147287\n",
      "epoch =  5 batch =  1900 / 3597 loss =  -15.275719089297358\n",
      "epoch =  5 batch =  1925 / 3597 loss =  -15.276202743050963\n",
      "epoch =  5 batch =  1950 / 3597 loss =  -15.275088787812079\n",
      "epoch =  5 batch =  1975 / 3597 loss =  -15.276471489354186\n",
      "epoch =  5 batch =  2000 / 3597 loss =  -15.274881469196586\n",
      "epoch =  5 batch =  2025 / 3597 loss =  -15.270384888776082\n",
      "epoch =  5 batch =  2050 / 3597 loss =  -15.268897848440812\n",
      "epoch =  5 batch =  2075 / 3597 loss =  -15.27042562424103\n",
      "epoch =  5 batch =  2100 / 3597 loss =  -15.271687415030842\n",
      "epoch =  5 batch =  2125 / 3597 loss =  -15.270998882552082\n",
      "epoch =  5 batch =  2150 / 3597 loss =  -15.275128822557205\n",
      "epoch =  5 batch =  2175 / 3597 loss =  -15.276330511359603\n",
      "epoch =  5 batch =  2200 / 3597 loss =  -15.279254335319381\n",
      "epoch =  5 batch =  2225 / 3597 loss =  -15.27714318535077\n",
      "epoch =  5 batch =  2250 / 3597 loss =  -15.273644453681662\n",
      "epoch =  5 batch =  2275 / 3597 loss =  -15.275494896883702\n",
      "epoch =  5 batch =  2300 / 3597 loss =  -15.277166855640898\n",
      "epoch =  5 batch =  2325 / 3597 loss =  -15.278107463954749\n",
      "epoch =  5 batch =  2350 / 3597 loss =  -15.276728331104634\n",
      "epoch =  5 batch =  2375 / 3597 loss =  -15.273671116893135\n",
      "epoch =  5 batch =  2400 / 3597 loss =  -15.278318249846635\n",
      "epoch =  5 batch =  2425 / 3597 loss =  -15.276841741893668\n",
      "epoch =  5 batch =  2450 / 3597 loss =  -15.27227836509278\n",
      "epoch =  5 batch =  2475 / 3597 loss =  -15.268465393001696\n",
      "epoch =  5 batch =  2500 / 3597 loss =  -15.271635696536203\n",
      "epoch =  5 batch =  2525 / 3597 loss =  -15.26870880293072\n",
      "epoch =  5 batch =  2550 / 3597 loss =  -15.27011638396116\n",
      "epoch =  5 batch =  2575 / 3597 loss =  -15.270561848367961\n",
      "epoch =  5 batch =  2600 / 3597 loss =  -15.270099118873274\n",
      "epoch =  5 batch =  2625 / 3597 loss =  -15.271006333945998\n",
      "epoch =  5 batch =  2650 / 3597 loss =  -15.269677590622354\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch =  5 batch =  2675 / 3597 loss =  -15.272952343494543\n",
      "epoch =  5 batch =  2700 / 3597 loss =  -15.274478148990362\n",
      "epoch =  5 batch =  2725 / 3597 loss =  -15.274069173145362\n",
      "epoch =  5 batch =  2750 / 3597 loss =  -15.2782363368138\n",
      "epoch =  5 batch =  2775 / 3597 loss =  -15.278668407060913\n",
      "epoch =  5 batch =  2800 / 3597 loss =  -15.279261132811953\n",
      "epoch =  5 batch =  2825 / 3597 loss =  -15.279348164860101\n",
      "epoch =  5 batch =  2850 / 3597 loss =  -15.27671886151065\n",
      "epoch =  5 batch =  2875 / 3597 loss =  -15.277596800648949\n",
      "epoch =  5 batch =  2900 / 3597 loss =  -15.276391437324067\n",
      "epoch =  5 batch =  2925 / 3597 loss =  -15.27610117918159\n",
      "epoch =  5 batch =  2950 / 3597 loss =  -15.275830533859162\n",
      "epoch =  5 batch =  2975 / 3597 loss =  -15.277163187021849\n",
      "epoch =  5 batch =  3000 / 3597 loss =  -15.279022233321719\n",
      "epoch =  5 batch =  3025 / 3597 loss =  -15.281352892508192\n",
      "epoch =  5 batch =  3050 / 3597 loss =  -15.282058812094217\n",
      "epoch =  5 batch =  3075 / 3597 loss =  -15.280612349045136\n",
      "epoch =  5 batch =  3100 / 3597 loss =  -15.281094677176869\n",
      "epoch =  5 batch =  3125 / 3597 loss =  -15.279886437621697\n",
      "epoch =  5 batch =  3150 / 3597 loss =  -15.28162344021859\n",
      "epoch =  5 batch =  3175 / 3597 loss =  -15.282266892474002\n",
      "epoch =  5 batch =  3200 / 3597 loss =  -15.282801715704247\n",
      "epoch =  5 batch =  3225 / 3597 loss =  -15.284433680000468\n",
      "epoch =  5 batch =  3250 / 3597 loss =  -15.283964750547474\n",
      "epoch =  5 batch =  3275 / 3597 loss =  -15.284098258094179\n",
      "epoch =  5 batch =  3300 / 3597 loss =  -15.282123295836865\n",
      "epoch =  5 batch =  3325 / 3597 loss =  -15.283871640086673\n",
      "epoch =  5 batch =  3350 / 3597 loss =  -15.281915536890168\n",
      "epoch =  5 batch =  3375 / 3597 loss =  -15.281908112397124\n",
      "epoch =  5 batch =  3400 / 3597 loss =  -15.284285607319722\n",
      "epoch =  5 batch =  3425 / 3597 loss =  -15.286431225989897\n",
      "epoch =  5 batch =  3450 / 3597 loss =  -15.284540556092704\n",
      "epoch =  5 batch =  3475 / 3597 loss =  -15.285036504337235\n",
      "epoch =  5 batch =  3500 / 3597 loss =  -15.286172751595856\n",
      "epoch =  5 batch =  3525 / 3597 loss =  -15.286428542686197\n",
      "epoch =  5 batch =  3550 / 3597 loss =  -15.285277066651076\n",
      "epoch =  5 batch =  3575 / 3597 loss =  -15.285134974208718\n",
      "Validation loss =  -15.216343879699707\n",
      "epoch =  6 batch =  0 / 3597 loss =  -14.846200942993164\n",
      "epoch =  6 batch =  25 / 3597 loss =  -15.383491772871752\n",
      "epoch =  6 batch =  50 / 3597 loss =  -15.346273515738693\n",
      "epoch =  6 batch =  75 / 3597 loss =  -15.230457042392931\n",
      "epoch =  6 batch =  100 / 3597 loss =  -15.291823387145996\n",
      "epoch =  6 batch =  125 / 3597 loss =  -15.29454085183522\n",
      "epoch =  6 batch =  150 / 3597 loss =  -15.309570097765386\n",
      "epoch =  6 batch =  175 / 3597 loss =  -15.278438595208256\n",
      "epoch =  6 batch =  200 / 3597 loss =  -15.30074419904111\n",
      "epoch =  6 batch =  225 / 3597 loss =  -15.311179169511373\n",
      "epoch =  6 batch =  250 / 3597 loss =  -15.335570426576165\n",
      "epoch =  6 batch =  275 / 3597 loss =  -15.30550441534623\n",
      "epoch =  6 batch =  300 / 3597 loss =  -15.320445713410741\n",
      "epoch =  6 batch =  325 / 3597 loss =  -15.314364681945989\n",
      "epoch =  6 batch =  350 / 3597 loss =  -15.320414605643334\n",
      "epoch =  6 batch =  375 / 3597 loss =  -15.314958407523784\n",
      "epoch =  6 batch =  400 / 3597 loss =  -15.312138243506377\n",
      "epoch =  6 batch =  425 / 3597 loss =  -15.303557335490911\n",
      "epoch =  6 batch =  450 / 3597 loss =  -15.293249696955712\n",
      "epoch =  6 batch =  475 / 3597 loss =  -15.30444274830217\n",
      "epoch =  6 batch =  500 / 3597 loss =  -15.27185477372891\n",
      "epoch =  6 batch =  525 / 3597 loss =  -15.26857852935791\n",
      "epoch =  6 batch =  550 / 3597 loss =  -15.270907699737272\n",
      "epoch =  6 batch =  575 / 3597 loss =  -15.268356208999952\n",
      "epoch =  6 batch =  600 / 3597 loss =  -15.275025374084066\n",
      "epoch =  6 batch =  625 / 3597 loss =  -15.273216236894504\n",
      "epoch =  6 batch =  650 / 3597 loss =  -15.282045168078257\n",
      "epoch =  6 batch =  675 / 3597 loss =  -15.286155606162618\n",
      "epoch =  6 batch =  700 / 3597 loss =  -15.290680001023492\n",
      "epoch =  6 batch =  725 / 3597 loss =  -15.28648746768962\n",
      "epoch =  6 batch =  750 / 3597 loss =  -15.289156048974089\n",
      "epoch =  6 batch =  775 / 3597 loss =  -15.288001081378189\n",
      "epoch =  6 batch =  800 / 3597 loss =  -15.30094552248456\n",
      "epoch =  6 batch =  825 / 3597 loss =  -15.309884856457282\n",
      "epoch =  6 batch =  850 / 3597 loss =  -15.314700382156461\n",
      "epoch =  6 batch =  875 / 3597 loss =  -15.313579903345675\n",
      "epoch =  6 batch =  900 / 3597 loss =  -15.314645342768628\n",
      "epoch =  6 batch =  925 / 3597 loss =  -15.314478611585645\n",
      "epoch =  6 batch =  950 / 3597 loss =  -15.314697039992275\n",
      "epoch =  6 batch =  975 / 3597 loss =  -15.311055866421245\n",
      "epoch =  6 batch =  1000 / 3597 loss =  -15.312072265160072\n",
      "epoch =  6 batch =  1025 / 3597 loss =  -15.3197581586782\n",
      "epoch =  6 batch =  1050 / 3597 loss =  -15.32282885543286\n",
      "epoch =  6 batch =  1075 / 3597 loss =  -15.323939927005414\n",
      "epoch =  6 batch =  1100 / 3597 loss =  -15.326415747972534\n",
      "epoch =  6 batch =  1125 / 3597 loss =  -15.330011925942944\n",
      "epoch =  6 batch =  1150 / 3597 loss =  -15.335630851036356\n",
      "epoch =  6 batch =  1175 / 3597 loss =  -15.330839577175322\n",
      "epoch =  6 batch =  1200 / 3597 loss =  -15.337255153131922\n",
      "epoch =  6 batch =  1225 / 3597 loss =  -15.339803361970487\n",
      "epoch =  6 batch =  1250 / 3597 loss =  -15.338923975718107\n",
      "epoch =  6 batch =  1275 / 3597 loss =  -15.341440508731853\n",
      "epoch =  6 batch =  1300 / 3597 loss =  -15.340386859093329\n",
      "epoch =  6 batch =  1325 / 3597 loss =  -15.34272766544808\n",
      "epoch =  6 batch =  1350 / 3597 loss =  -15.344933856424802\n",
      "epoch =  6 batch =  1375 / 3597 loss =  -15.343969489252844\n",
      "epoch =  6 batch =  1400 / 3597 loss =  -15.344778830795779\n",
      "epoch =  6 batch =  1425 / 3597 loss =  -15.345667285303916\n",
      "epoch =  6 batch =  1450 / 3597 loss =  -15.35156789867735\n",
      "epoch =  6 batch =  1475 / 3597 loss =  -15.350117774513679\n",
      "epoch =  6 batch =  1500 / 3597 loss =  -15.35388675298316\n",
      "epoch =  6 batch =  1525 / 3597 loss =  -15.34898839490598\n",
      "epoch =  6 batch =  1550 / 3597 loss =  -15.34855514737885\n"
     ]
    }
   ],
   "source": [
    "data_size = train_samples.shape[0]\n",
    "n_batches = m.ceil(data_size/batch_size)\n",
    "\n",
    "data_size_validation = test_samples.shape[0]\n",
    "n_batches_validate = m.ceil(data_size_validation/batch_size)\n",
    "\n",
    "best_loss = np.inf\n",
    "for epoch in range(n_epochs):\n",
    "    \n",
    "    permutation = torch.randperm(data_size, device=device)    \n",
    "\n",
    "    # Loop over batches\n",
    "    cum_loss = 0\n",
    "    for batch in range(n_batches):\n",
    "        # Set up the batch\n",
    "        batch_begin = batch*batch_size\n",
    "        batch_end   = min( (batch+1)*batch_size, data_size-1 )\n",
    "        indices = permutation[batch_begin:batch_end]\n",
    "        samples_batch = train_samples[indices]\n",
    "        weights_batch = train_weights[indices]\n",
    "        \n",
    "        # Take a step\n",
    "        optimizer.zero_grad()\n",
    "        loss = -(flow.log_prob(inputs=samples_batch)*weights_batch).mean()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Compute cumulative loss\n",
    "        cum_loss = (cum_loss*batch + loss.item())/(batch+1)\n",
    "\n",
    "        if batch%25 == 0:\n",
    "            print(\"epoch = \", epoch, \"batch = \", batch, \"/\", n_batches, \"loss = \", cum_loss)\n",
    "    \n",
    "    scheduler.step()\n",
    "    \n",
    "    # Compute validation loss\n",
    "    validation_loss = 0\n",
    "    for batch in range(n_batches_validate):\n",
    "        batch_begin = batch*batch_size\n",
    "        batch_end = min( (batch+1)*batch_size, data_size_validation-1 )\n",
    "        samples_batch = test_samples[batch_begin:batch_end]\n",
    "        weights_batch = test_weights[batch_begin:batch_end]\n",
    "    \n",
    "        with torch.no_grad():\n",
    "            validation_loss = (validation_loss*batch - (flow.log_prob(samples_batch)*weights_batch).mean())/(batch+1)\n",
    "    \n",
    "    print(\"Validation loss = \", validation_loss.item())\n",
    "    \n",
    "    writer.add_scalar(\"Loss_train\", cum_loss, epoch)\n",
    "    writer.add_scalar(\"Loss_test\", validation_loss, epoch)\n",
    "    \n",
    "    if validation_loss < best_loss:\n",
    "        torch.save(flow, \"best_flow_model.pt\")\n",
    "        best_loss = validation_loss\n",
    "\n",
    "torch.save(flow, \"final_flow_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
